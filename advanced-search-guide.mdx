---
title: "Advanced Search Guide"
description: "Master Firecrawl's search API with advanced techniques, operators, and optimization strategies."
og:title: "Advanced Search Guide | Firecrawl"
og:description: "Master Firecrawl's search API with advanced techniques, operators, and optimization strategies."
---

This guide covers advanced usage of Firecrawl's `/search` endpoint, including query operators, filtering strategies, content scraping, and cost optimization.

## Overview

The search endpoint combines web search with Firecrawl's scraping capabilities:

- **Search only**: Get URLs, titles, and descriptions (default)
- **Search + scrape**: Get full page content in markdown, HTML, or other formats
- **Multi-source**: Search web, news, and images simultaneously
- **Category filtering**: Target GitHub, research papers, or PDFs specifically

## Query Operators

Firecrawl supports powerful query operators to refine your searches:

| Operator | Description | Example |
|----------|-------------|---------|
| `""` | Exact phrase match | `"machine learning"` |
| `-` | Exclude term | `python -beginner` |
| `site:` | Limit to domain | `site:github.com` |
| `filetype:` | Filter by file type | `filetype:pdf` |
| `inurl:` | Word in URL | `inurl:api` |
| `allinurl:` | Multiple words in URL | `allinurl:docs api` |
| `intitle:` | Word in title | `intitle:tutorial` |
| `allintitle:` | Multiple words in title | `allintitle:python web scraping` |
| `related:` | Related to domain | `related:firecrawl.dev` |
| `imagesize:` | Exact image dimensions | `imagesize:1920x1080` |
| `larger:` | Minimum image dimensions | `larger:2560x1440` |

### Combining Operators

Chain operators for precise results:

```bash
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "site:github.com \"web scraping\" python -selenium filetype:md",
    "limit": 10
  }'
```

## Multi-Source Search

Search across different content types using the `sources` parameter:

### Web + News + Images

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

results = firecrawl.search(
    "artificial intelligence",
    sources=["web", "news", "images"],
    limit=10
)

# Access different result types
web_results = results.data.get("web", [])
news_results = results.data.get("news", [])
image_results = results.data.get("images", [])
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR_API_KEY" });

const results = await firecrawl.search("artificial intelligence", {
  sources: [{ type: "web" }, { type: "news" }, { type: "images" }],
  limit: 10
});

const { web, news, images } = results.data;
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "artificial intelligence",
    "sources": [
      { "type": "web" },
      { "type": "news" },
      { "type": "images" }
    ],
    "limit": 10
  }'
```

</CodeGroup>

### HD Image Search

Find high-resolution images using size operators:

```bash
# Exact resolution
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "mountain landscape imagesize:3840x2160",
    "sources": [{ "type": "images" }],
    "limit": 10
  }'

# Minimum resolution
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "abstract wallpaper larger:2560x1440",
    "sources": [{ "type": "images" }],
    "limit": 10
  }'
```

**Common HD resolutions:**
- `imagesize:1920x1080` - Full HD (1080p)
- `imagesize:2560x1440` - QHD (1440p)
- `imagesize:3840x2160` - 4K UHD
- `larger:1920x1080` - HD and above

## Category Filtering

Target specific content types with the `categories` parameter:

| Category | Description | Example Sites |
|----------|-------------|---------------|
| `github` | Code repositories, issues, docs | github.com |
| `research` | Academic papers | arXiv, Nature, IEEE, PubMed |
| `pdf` | PDF documents | Any PDF files |

### GitHub-Focused Search

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

results = firecrawl.search(
    "web scraping python async",
    categories=["github"],
    limit=15,
    scrape_options={"formats": ["markdown"]}
)

for result in results.data.get("web", []):
    print(f"[{result.get('category')}] {result['url']}")
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR_API_KEY" });

const results = await firecrawl.search("web scraping python async", {
  categories: ["github"],
  limit: 15,
  scrapeOptions: { formats: ["markdown"] }
});

results.data.web?.forEach(result => {
  console.log(`[${result.category}] ${result.url}`);
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "web scraping python async",
    "categories": ["github"],
    "limit": 15,
    "scrapeOptions": {
      "formats": ["markdown"]
    }
  }'
```

</CodeGroup>

### Research Paper Search

```bash
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "transformer architecture attention mechanism",
    "categories": ["research"],
    "limit": 10
  }'
```

### Mixed Category Search

```bash
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "large language models",
    "categories": ["github", "research", "pdf"],
    "limit": 20
  }'
```

## Geo-Targeted Search

### Location Parameter

Use natural language location strings:

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

# Country-level
results = firecrawl.search(
    "best restaurants",
    location="Germany",
    limit=10
)

# City-level
results = firecrawl.search(
    "coworking spaces",
    location="San Francisco,California,United States",
    limit=10
)
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR_API_KEY" });

// Country-level
const results = await firecrawl.search("best restaurants", {
  location: "Germany",
  limit: 10
});

// City-level
const results2 = await firecrawl.search("coworking spaces", {
  location: "San Francisco,California,United States",
  limit: 10
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "best restaurants",
    "location": "Germany",
    "limit": 10
  }'
```

</CodeGroup>

### Country Parameter (ISO Codes)

```bash
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "technology news",
    "country": "JP",
    "limit": 10
  }'
```

Common country codes: `US`, `DE`, `FR`, `JP`, `UK`, `CA`, `AU`, `BR`

See the [complete list of supported locations](https://firecrawl.dev/search_locations.json).

## Time-Based Search

Filter results by publication date using the `tbs` parameter:

### Predefined Time Ranges

| Value | Description |
|-------|-------------|
| `qdr:h` | Past hour |
| `qdr:d` | Past 24 hours |
| `qdr:w` | Past week |
| `qdr:m` | Past month |
| `qdr:y` | Past year |

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

# Results from the past week
results = firecrawl.search(
    "openai announcements",
    tbs="qdr:w",
    limit=10
)
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR_API_KEY" });

// Results from the past week
const results = await firecrawl.search("openai announcements", {
  tbs: "qdr:w",
  limit: 10
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "openai announcements",
    "tbs": "qdr:w",
    "limit": 10
  }'
```

</CodeGroup>

### Custom Date Ranges

Use the format `cdr:1,cd_min:MM/DD/YYYY,cd_max:MM/DD/YYYY`:

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

# Results from Q4 2024
results = firecrawl.search(
    "firecrawl updates",
    tbs="cdr:1,cd_min:10/1/2024,cd_max:12/31/2024",
    limit=10
)
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "firecrawl updates",
    "tbs": "cdr:1,cd_min:10/1/2024,cd_max:12/31/2024",
    "limit": 10
  }'
```

## Content Scraping with Search

Add `scrapeOptions` to retrieve full page content for each result:

### Basic Content Scraping

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

results = firecrawl.search(
    "web scraping tutorial",
    limit=5,
    scrape_options={
        "formats": ["markdown", "links"]
    }
)

for result in results.data.get("web", []):
    print(f"URL: {result['url']}")
    print(f"Content: {result.get('markdown', 'N/A')[:500]}...")
    print(f"Links: {len(result.get('links', []))}")
    print("---")
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR_API_KEY" });

const results = await firecrawl.search("web scraping tutorial", {
  limit: 5,
  scrapeOptions: {
    formats: ["markdown", "links"]
  }
});

results.data.web?.forEach(result => {
  console.log(`URL: ${result.url}`);
  console.log(`Content: ${result.markdown?.substring(0, 500)}...`);
  console.log(`Links: ${result.links?.length || 0}`);
  console.log("---");
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "web scraping tutorial",
    "limit": 5,
    "scrapeOptions": {
      "formats": ["markdown", "links"]
    }
  }'
```

</CodeGroup>

### Available Formats

| Format | Description |
|--------|-------------|
| `markdown` | Clean markdown content |
| `html` | Cleaned HTML |
| `rawHtml` | Original HTML |
| `links` | Array of links on page |
| `summary` | AI-generated summary |
| `screenshot` | Page screenshot (object format) |

### Advanced Scrape Options

```bash
curl -X POST https://api.firecrawl.dev/v2/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "pricing page SaaS",
    "limit": 5,
    "scrapeOptions": {
      "formats": [
        "markdown",
        "links",
        { "type": "screenshot", "fullPage": false, "quality": 80 }
      ],
      "onlyMainContent": true,
      "includeTags": [".pricing", ".plans", "table"],
      "excludeTags": ["#footer", "#header", ".cookie-banner"],
      "waitFor": 2000
    }
  }'
```

### Scrape Options Reference

| Option | Type | Description |
|--------|------|-------------|
| `formats` | array | Output formats to include |
| `onlyMainContent` | boolean | Extract main content only (default: `true`) |
| `includeTags` | array | HTML tags/classes/ids to include |
| `excludeTags` | array | HTML tags/classes/ids to exclude |
| `waitFor` | integer | Extra wait time in ms |
| `maxAge` | integer | Max cache age in ms |
| `timeout` | integer | Request timeout in ms |

## Response Structure

### Search-Only Response

```json
{
  "success": true,
  "data": {
    "web": [
      {
        "url": "https://example.com/article",
        "title": "Article Title",
        "description": "Article description...",
        "category": "github"
      }
    ],
    "news": [...],
    "images": [...]
  },
  "id": "search-job-id",
  "creditsUsed": 2
}
```

### Search + Scrape Response

```json
{
  "success": true,
  "data": {
    "web": [
      {
        "url": "https://example.com/article",
        "title": "Article Title",
        "description": "Article description...",
        "markdown": "# Article Title\n\nFull article content...",
        "links": ["https://example.com/link1", "https://example.com/link2"],
        "metadata": {
          "title": "Article Title",
          "description": "Article description...",
          "sourceURL": "https://example.com/article",
          "statusCode": 200
        }
      }
    ]
  },
  "id": "search-job-id",
  "creditsUsed": 7
}
```

## Cost Optimization

### Pricing Breakdown

- **Search only**: 2 credits per 10 results
- **With scraping**: +1 credit per page scraped
- **PDF parsing**: +1 credit per PDF page
- **Enhanced proxy**: +4 credits per page
- **JSON extraction**: +4 credits per page

### Optimization Strategies

**1. Limit results appropriately:**

```python
# Only request what you need
results = firecrawl.search("query", limit=5)  # Instead of limit=100
```

**2. Skip PDF parsing if not needed:**

```python
results = firecrawl.search(
    "query",
    limit=10,
    scrape_options={
        "formats": ["markdown"],
        "parsers": []  # Skip PDF parsing
    }
)
```

**3. Use basic proxy when possible:**

```python
results = firecrawl.search(
    "query",
    limit=10,
    scrape_options={
        "formats": ["markdown"],
        "proxy": "basic"  # Or "auto" for automatic selection
    }
)
```

**4. Search without scraping first:**

```python
# Step 1: Search to find relevant URLs
search_results = firecrawl.search("query", limit=20)

# Step 2: Filter and scrape only the most relevant
relevant_urls = [r['url'] for r in search_results.data['web'][:5]]
for url in relevant_urls:
    content = firecrawl.scrape(url, {"formats": ["markdown"]})
```

## Complete Example: Research Aggregator

```python
from firecrawl import Firecrawl
from datetime import datetime

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

def research_topic(topic: str, max_results: int = 10):
    """Search multiple sources for research on a topic."""

    # Search academic sources
    academic = firecrawl.search(
        topic,
        categories=["research"],
        tbs="qdr:y",  # Past year
        limit=max_results,
        scrape_options={"formats": ["markdown", "summary"]}
    )

    # Search GitHub for implementations
    code = firecrawl.search(
        f"{topic} implementation",
        categories=["github"],
        limit=max_results // 2
    )

    # Search recent news
    news = firecrawl.search(
        topic,
        sources=["news"],
        tbs="qdr:m",  # Past month
        limit=max_results // 2
    )

    return {
        "academic": academic.data.get("web", []),
        "code": code.data.get("web", []),
        "news": news.data.get("news", []),
        "total_credits": (
            academic.credits_used +
            code.credits_used +
            news.credits_used
        )
    }

# Usage
results = research_topic("transformer attention mechanisms")
print(f"Found {len(results['academic'])} papers")
print(f"Found {len(results['code'])} code repos")
print(f"Found {len(results['news'])} news articles")
print(f"Total credits used: {results['total_credits']}")
```

## Error Handling

```python
from firecrawl import Firecrawl
from firecrawl.exceptions import FirecrawlError

firecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")

try:
    results = firecrawl.search(
        "query",
        limit=10,
        timeout=30000
    )
except FirecrawlError as e:
    if e.status_code == 402:
        print("Insufficient credits")
    elif e.status_code == 408:
        print("Request timeout - try reducing limit or timeout")
    elif e.status_code == 429:
        print("Rate limited - slow down requests")
    else:
        print(f"Error: {e.message}")
```

## API Reference

For complete parameter documentation, see the [Search Endpoint API Reference](/api-reference/endpoint/search).
