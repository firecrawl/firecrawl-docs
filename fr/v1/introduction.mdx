---
title: Démarrage rapide
description: "Firecrawl vous permet de convertir des sites web entiers en Markdown prêt pour les LLM"
og:title: "Démarrage rapide | Firecrawl"
og:description: "Firecrawl vous permet de convertir des sites web entiers en Markdown prêt pour les LLM"
---

import InstallationPython from "/snippets/fr/v1/installation/python.mdx";
import InstallationNode from "/snippets/fr/v1/installation/js.mdx";
import InstallationGo from "/snippets/fr/v1/installation/go.mdx";
import InstallationRust from "/snippets/fr/v1/installation/rust.mdx";
import ScrapePython from "/snippets/fr/v1/scrape/base/python.mdx";
import ScrapeNode from "/snippets/fr/v1/scrape/base/js.mdx";
import ScrapeGo from "/snippets/fr/v1/scrape/base/go.mdx";
import ScrapeRust from "/snippets/fr/v1/scrape/base/rust.mdx";
import ScrapeCURL from "/snippets/fr/v1/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/fr/v1/scrape/base/output.mdx";
import CrawlPython from "/snippets/fr/v1/crawl/base/python.mdx";
import CrawlNode from "/snippets/fr/v1/crawl/base/js.mdx";
import CrawlGo from "/snippets/fr/v1/crawl/base/go.mdx";
import CrawlRust from "/snippets/fr/v1/crawl/base/rust.mdx";
import CrawlCURL from "/snippets/fr/v1/crawl/base/curl.mdx";
import CrawlAsyncOutput from "/snippets/fr/v1/crawl-async/base/output.mdx";
import CheckCrawlJobPython from "/snippets/fr/v1/crawl-status/short/python.mdx";
import CheckCrawlJobNode from "/snippets/fr/v1/crawl-status/short/js.mdx";
import CheckCrawlJobGo from "/snippets/fr/v1/crawl-status/short/go.mdx";
import CheckCrawlJobRust from "/snippets/fr/v1/crawl-status/short/rust.mdx";
import CheckCrawlJobCURL from "/snippets/fr/v1/crawl-status/short/curl.mdx";
import CheckCrawlJobOutputScraping from "/snippets/fr/v1/crawl-status/base/output-scraping.mdx";
import CheckCrawlJobOutputCompleted from "/snippets/fr/v1/crawl-status/base/output-completed.mdx";
import ExtractCURL from "/snippets/fr/v1/llm-extract/base/curl.mdx";
import ExtractPython from "/snippets/fr/v1/llm-extract/base/python.mdx";
import ExtractNode from "/snippets/fr/v1/llm-extract/base/js.mdx";
import ExtractOutput from "/snippets/fr/v1/llm-extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/fr/v1/llm-extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/fr/v1/llm-extract/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/fr/v1/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/fr/v1/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/fr/v1/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/fr/v1/scrape/actions/output.mdx";

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.png" alt="Visuel principal — clair" />

<div id="welcome-to-firecrawl">
  ## Bienvenue sur Firecrawl
</div>

[Firecrawl](https://firecrawl.dev?ref=github) est un service d’API qui prend une URL, l’explore et la convertit en Markdown propre. Nous explorons toutes les sous-pages accessibles et vous fournissons un Markdown propre pour chacune. Aucun sitemap nécessaire.

<div id="how-to-use-it">
  ## Comment l’utiliser ?
</div>

Nous proposons une API simple à utiliser avec notre version hébergée. Vous trouverez l’aire de test et la documentation [ici](https://firecrawl.dev/playground). Vous pouvez également auto‑héberger le backend si vous le souhaitez.

Consultez les ressources suivantes pour bien démarrer :

* [x] **API** : [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs** : [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
* [x] **Frameworks LLM** : [LangChain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [LangChain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low‑code** : [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **Autres** : [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] Vous souhaitez un SDK ou une intégration ? Dites‑le‑nous en ouvrant un ticket.

**Auto‑hébergement :** Pour l’auto‑hébergement, consultez le guide [ici](/fr/contributing/self-host).

<div id="api-key">
  ### Clé d’API
</div>

Pour utiliser l’API, vous devez vous inscrire sur [Firecrawl](https://firecrawl.dev) et obtenir une clé d’API.

<div id="features">
  ### Fonctionnalités
</div>

* [**Scrape**](#scraping) : extrait le contenu d’une URL dans un format prêt pour les LLM (markdown, résumé, données structurées via [mode JSON](#json-mode), capture d’écran, HTML)
* [**Crawl**](#crawling) : explore plusieurs URLs à partir d’une page et renvoie le contenu dans un format prêt pour les LLM
* [**Map**](/fr/features/map) : fournissez un site web et obtenez toutes ses URLs — extrêmement rapide
* [**Search**](/fr/features/search) : recherchez sur le web et récupérez le contenu complet des résultats
* [**Extract**](/fr/features/extract) : obtenez des données structurées à partir d’une page, de plusieurs pages ou de sites entiers avec l’IA.

<div id="powerful-capabilities">
  ### Capacités avancées
</div>

* **formats prêts pour les LLM** : markdown, résumé, données structurées, capture d’écran, HTML, liens, métadonnées
* **Les sujets complexes** : proxys, mécanismes anti-bot, contenu dynamique (rendu JS), analyse de sortie, orchestration
* **Personnalisation** : exclure des balises, explorer derrière des murs d’auth avec des en-têtes personnalisés, profondeur d’exploration maximale, etc.
* **Analyse des médias** : PDF, DOCX, images
* **Fiabilité avant tout** : conçu pour obtenir les données dont vous avez besoin, quoi qu’il en coûte
* **actions** : clic, défilement, saisie, attente et plus encore avant d’extraire les données

Vous trouverez toutes les capacités de Firecrawl et leur utilisation dans notre [documentation](https://docs.firecrawl.dev/api-reference/v2-introduction)

<div id="installing-firecrawl">
  ## Installer Firecrawl
</div>

<CodeGroup>
  <InstallationPython />

  <InstallationNode />

  <InstallationGo />

  <InstallationRust />
</CodeGroup>

<div id="scraping">
  ## Scraping
</div>

Pour extraire le contenu d’une seule URL, utilisez la méthode `scrape_url`. Elle prend l’URL en paramètre et retourne les données extraites sous forme de dictionnaire.

<CodeGroup>
  <ScrapePython />

  <ScrapeNode />

  <ScrapeGo />

  <ScrapeRust />

  <ScrapeCURL />
</CodeGroup>

### Réponse

Les SDK renverront directement l’objet de données. cURL renverra la charge utile exactement telle qu’indiquée ci-dessous.

<ScrapeResponse />

<div id="crawling">
  ## Exploration
</div>

La fonctionnalité d’exploration vous permet de découvrir et d’extraire automatiquement du contenu à partir d’une URL et de toutes ses sous-pages accessibles. Avec nos SDK, appelez simplement la méthode d’exploration : elle soumettra une tâche d’exploration, attendra son achèvement, puis renverra les résultats complets pour l’ensemble du site.

<div id="usage">
  ### Utilisation
</div>

<CodeGroup>
  <CrawlPython />

  <CrawlNode />

  <CrawlGo />

  <CrawlRust />

  <CrawlCURL />
</CodeGroup>

Si vous utilisez directement notre API, cURL ou les fonctions `start crawl` dans les SDK, un `ID` sera renvoyé, que vous pourrez utiliser pour vérifier l’état du crawl.

<CrawlAsyncOutput />

<div id="check-crawl-job">
  ### Vérifier une tâche de crawl
</div>

Permet de vérifier l’état d’une tâche de crawl et d’en récupérer le résultat.

<CodeGroup>
  <CheckCrawlJobPython />

  <CheckCrawlJobNode />

  <CheckCrawlJobGo />

  <CheckCrawlJobRust />

  <CheckCrawlJobCURL />
</CodeGroup>

<div id="response">
  #### Réponse
</div>

La réponse varie selon l’état du crawl. Pour les réponses incomplètes ou volumineuses dépassant 10 Mo, un paramètre d’URL `next` est fourni. Vous devez appeler cette URL pour récupérer les 10 Mo de données suivants. Si le paramètre `next` est absent, cela indique la fin des données du crawl.

<CodeGroup>
  <CheckCrawlJobOutputScraping />

  <CheckCrawlJobOutputCompleted />
</CodeGroup>

<div id="json-mode">
  ## mode JSON
</div>

Avec le mode JSON, vous pouvez facilement extraire des données structurées à partir de n’importe quelle URL. Nous prenons en charge les schémas Pydantic pour vous simplifier la tâche. Voici comment l’utiliser :

<CodeGroup>
  <ExtractPython />

  <ExtractNode />

  <ExtractCURL />
</CodeGroup>

Résultat :

<ExtractOutput />

<div id="extracting-without-schema">
  ### Extraction sans schéma
</div>

Vous pouvez désormais extraire sans schéma en transmettant simplement un `prompt` au point de terminaison. Le LLM choisit la structure des données.

<CodeGroup>
  <ExtractNoSchemaCURL />
</CodeGroup>

Résultat :

<ExtractNoSchemaOutput />

<div id="interacting-with-the-page-with-actions">
  ## Interagir avec la page à l’aide des actions
</div>

Firecrawl vous permet d’exécuter diverses actions sur une page web avant d’en extraire le contenu. C’est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre les pages ou accéder à du contenu nécessitant une interaction de l’utilisateur.

Voici un exemple d’utilisation des actions pour accéder à google.com, rechercher Firecrawl, cliquer sur le premier résultat et prendre une capture d’écran.

Il est important d’utiliser presque toujours l’action `wait` avant et/ou après d’autres actions afin de laisser suffisamment de temps au chargement de la page.

<div id="example">
  ### Exemple
</div>

<CodeGroup>
  <ScrapeActionsPython />

  <ScrapeActionsNode />

  <ScrapeActionsCURL />
</CodeGroup>

<div id="output">
  ### Résultat
</div>

<CodeGroup>
  <ScrapeActionsOutput />
</CodeGroup>

<div id="open-source-vs-cloud">
  ## Open Source vs Cloud
</div>

Firecrawl est open source et disponible sous la [licence AGPL-3.0](https://github.com/mendableai/firecrawl/blob/main/LICENSE).

Pour offrir le meilleur produit possible, nous proposons une version hébergée de Firecrawl en complément de notre offre open source. La solution cloud nous permet d’innover en continu et de maintenir un service de haute qualité et pérenne pour tous les utilisateurs.

Firecrawl Cloud est disponible sur [firecrawl.dev](https://firecrawl.dev) et propose un ensemble de fonctionnalités non disponibles dans la version open source :

![Firecrawl Cloud vs Open Source](./images/open-source-cloud.png)

<div id="contributing">
  ## Contribution
</div>

Nous apprécions vos contributions ! Veuillez lire notre [guide de contribution](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) avant de soumettre une pull request.