---
title: "Mode furtif"
description: "Utilisez des proxys furtifs pour les sites dotés de solutions anti-bots avancées"
og:title: "Mode furtif | Firecrawl"
og:description: "Utilisez des proxys furtifs pour les sites dotés de solutions anti-bots avancées"
---

import ProxyPython from "/snippets/fr/v1/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/fr/v1/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/fr/v1/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/fr/v1/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/fr/v1/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/fr/v1/scrape/proxy-retry/curl.mdx";

Firecrawl propose différents types de proxy pour vous aider à extraire des données depuis des sites web offrant des niveaux variables de protection anti‑bot. Le type de proxy peut être défini via le paramètre `proxy`.


<div id="proxy-types">
  ### Types de proxy
</div>

Firecrawl prend en charge trois types de proxy :

- **basic** : Proxys pour l’extraction de sites avec peu ou pas de solutions anti-bot. Rapides et généralement efficaces.
- **stealth** : Proxys furtifs pour l’extraction de sites avec des solutions anti-bot avancées. Plus lents, mais plus fiables sur certains sites.
- **auto** : Firecrawl réessaiera automatiquement l’extraction avec des proxys furtifs si le proxy basic échoue. Si le nouvel essai en stealth réussit, 5 crédits seront facturés pour l’extraction. Si la première tentative en basic réussit, seul le coût standard sera facturé.

Si vous ne spécifiez pas de proxy, Firecrawl utilisera basic par défaut.

<div id="using-stealth-mode">
  ### Utiliser le mode furtif
</div>

Pour le scraping de sites web dotés d’une protection anti-bot avancée, vous pouvez utiliser le mode proxy furtif afin d’augmenter votre taux de réussite.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Remarque :** À partir du 8 mai, les requêtes via le proxy furtif coûtent 5 crédits chacune.

<div id="using-stealth-as-a-retry-mechanism">
  ## Utiliser Stealth comme mécanisme de reprise
</div>

Un schéma courant consiste à d’abord tenter le scraping avec les paramètres de proxy par défaut, puis à réessayer avec le mode stealth si vous rencontrez des codes d’erreur spécifiques (401, 403 ou 500) dans le champ `metadata.statusCode` de la réponse. Ces codes d’état peuvent indiquer que le site bloque votre requête.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Cette approche vous permet d’optimiser votre utilisation des crédits en n’activant le mode stealth que lorsque c’est nécessaire.