---
title: Démarrage rapide
description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
og:title: "Démarrage rapide | Firecrawl"
og:description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
---

import InstallationPython from "/snippets/v2/installation/python.mdx";
import InstallationNode from "/snippets/v2/installation/js.mdx";
import ScrapePython from "/snippets/v2/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v2/scrape/base/js.mdx";
import ScrapeCURL from "/snippets/v2/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v2/scrape/base/output.mdx";
import CrawlPython from "/snippets/v2/crawl/base/python.mdx";
import CrawlNode from "/snippets/v2/crawl/base/js.mdx";
import CrawlCURL from "/snippets/v2/crawl/base/curl.mdx";
import CrawlAsyncOutput from "/snippets/v2/start-crawl/base/output.mdx";
import GetCrawlJobPython from "/snippets/v2/crawl-status/short/python.mdx";
import GetCrawlJobNode from "/snippets/v2/crawl-status/short/js.mdx";
import GetCrawlJobCURL from "/snippets/v2/crawl-status/short/curl.mdx";
import GetCrawlJobOutputScraping from "/snippets/v2/crawl-status/base/output-scraping.mdx";
import GetCrawlJobOutputCompleted from "/snippets/v2/crawl-status/base/output-completed.mdx";
import ScrapeJsonCURL from "/snippets/v2/scrape/json/base/curl.mdx";
import ScrapeJsonPython from "/snippets/v2/scrape/json/base/python.mdx";
import ScrapeJsonNode from "/snippets/v2/scrape/json/base/js.mdx";
import ScrapeJsonOutput from "/snippets/v2/scrape/json/base/output.mdx";
import ScrapeJsonNoSchemaCURL from "/snippets/v2/scrape/json/no-schema/curl.mdx";
import ScrapeJsonNoSchemaPython from "/snippets/v2/scrape/json/no-schema/python.mdx";
import ScrapeJsonNoSchemaNode from "/snippets/v2/scrape/json/no-schema/js.mdx";
import ScrapeJsonNoSchemaOutput from "/snippets/v2/scrape/json/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/v2/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/v2/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/v2/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/v2/scrape/actions/output.mdx";
import SearchPython from "/snippets/v2/search/base/python.mdx";
import SearchNode from "/snippets/v2/search/base/js.mdx";
import SearchCURL from "/snippets/v2/search/base/curl.mdx";
import SearchResponse from "/snippets/v2/search/base/output.mdx";

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.png" alt="Héros clair" />


## Bienvenue dans Firecrawl

[Firecrawl](https://firecrawl.dev?ref=github) est un service d’API qui prend une URL, la crawle et la convertit en Markdown propre. Nous explorons toutes les sous-pages accessibles et vous fournissons un Markdown propre pour chacune. Aucun sitemap nécessaire.

## Comment l’utiliser ?

Nous proposons une API simple d’utilisation avec notre version hébergée. Vous trouverez l’aire de test (playground) et la documentation [ici](https://firecrawl.dev/playground). Vous pouvez aussi auto-héberger le backend si vous le souhaitez.

Consultez les ressources suivantes pour démarrer :

- **API** : [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
- **SDKs** : [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node)
- **Frameworks LLM** : [LangChain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [LangChain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
- **Frameworks low-code** : [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
- **SDKs communautaires** : [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust) (v1)
- **Autres** : [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
- **Auto-hébergement :** Pour l’auto-hébergement, consultez le guide [ici](/contributing/self-host).

Vous souhaitez un SDK ou une intégration ? Faites-le-nous savoir en ouvrant une [issue](https://github.com/firecrawl/firecrawl/issues).

### Clé API

Pour utiliser l’API, vous devez créer un compte sur [Firecrawl](https://firecrawl.dev) et récupérer une clé API.

### Fonctionnalités

- [**Scrape**](#scraping) : récupère une URL et renvoie son contenu dans un format prêt pour les LLM (markdown, résumé, données structurées via le [mode JSON](#json-mode), capture d’écran, HTML)
- [**Crawl**](#crawling) : explore toutes les URL d’une page web et renvoie le contenu dans un format prêt pour les LLM
- [**Map**](/features/map) : indiquez un site web et obtenez toutes les URL du site — extrêmement rapide
- [**Search**](/features/search) : recherchez sur le web et obtenez le contenu complet des résultats
- [**Extract**](/features/extract) : extrayez des données structurées à partir d’une page, de plusieurs pages ou de sites entiers avec l’IA.

### Capacités avancées

- **formats prêts pour les LLM** : markdown, résumé, données structurées, capture d’écran, HTML, liens, métadonnées, images
- **Le difficile** : proxys, mécanismes anti-bot, contenu dynamique (rendu JS), analyse du résultat, orchestration
- **Ultra-rapide** : obtenez des résultats en quelques secondes — conçu pour la vitesse et les cas d’usage à haut débit.
- **Personnalisation** : exclure des balises, explorer derrière des murs d’authentification avec des en-têtes personnalisés, définir une profondeur d’exploration maximale, etc.
- **Analyse des médias** : PDF, DOCX, images.
- **Fiabilité avant tout** : conçu pour obtenir les données dont vous avez besoin — quoi qu’il en coûte.
- **Actions** : cliquer, faire défiler, saisir, attendre et plus encore avant d’extraire les données

Vous trouverez l’ensemble des capacités de Firecrawl et leur utilisation dans notre [documentation](https://docs.firecrawl.dev/api-reference/v2-introduction)

## Installer Firecrawl

<CodeGroup>

  <InstallationPython />

  <InstallationNode />

</CodeGroup>

## Scraping

Pour récupérer le contenu d’une seule URL, utilisez la méthode `scrape`. Elle prend l’URL en paramètre et renvoie les données récupérées sous forme de dictionnaire.

<CodeGroup>

  <ScrapePython />

  <ScrapeNode />

  <ScrapeCURL />

</CodeGroup>

### Réponse

Les SDK renvoient directement l’objet de données. cURL renvoie la charge utile exactement comme indiqué ci-dessous.

<ScrapeResponse />

## Exploration

La fonctionnalité d’exploration permet de découvrir et d’extraire automatiquement le contenu d’une URL et de toutes ses sous-pages accessibles. Avec nos SDK, appelez simplement la méthode d’exploration : elle soumet un travail d’exploration, attend son achèvement et renvoie les résultats complets pour l’ensemble du site.

### Utilisation

<CodeGroup>

<CrawlPython />
<CrawlNode />
<CrawlCURL />

</CodeGroup>

Si vous utilisez directement notre API, cURL ou les fonctions `start crawl` dans les SDK, un `ID` sera renvoyé que vous pourrez utiliser pour vérifier l’état du crawl.

<CrawlAsyncOutput />

### Obtenir l’état d’un crawl

Permet de vérifier l’état d’un job de crawl et de récupérer son résultat.

<CodeGroup>

<GetCrawlJobPython />
<GetCrawlJobNode />
<GetCrawlJobCURL />

</CodeGroup>

#### Réponse

La réponse varie selon l’état du crawl. Pour les réponses incomplètes ou volumineuses dépassant 10 Mo, un paramètre d’URL `next` est fourni. Vous devez requêter cette URL pour récupérer les 10 Mo suivants de données. Si le paramètre `next` est absent, cela indique la fin des données du crawl.

<CodeGroup>
  <GetCrawlJobOutputScraping />
  <GetCrawlJobOutputCompleted />
</CodeGroup>

## Mode JSON

Avec le mode JSON, vous pouvez facilement extraire des données structurées à partir de n'importe quelle URL. Nous prenons en charge les schémas Pydantic pour vous simplifier la tâche. Voici comment l'utiliser :

<CodeGroup>

<ScrapeJsonPython />
<ScrapeJsonNode />
<ScrapeJsonCURL />

</CodeGroup>

Résultat :

<ScrapeJsonOutput />

## Recherche

L’API de recherche de Firecrawl vous permet d’effectuer des recherches sur le web et, en option, de scraper les résultats en une seule opération.

- Choisissez des formats de sortie spécifiques (Markdown, HTML, liens, captures d’écran)
- Choisissez des sources spécifiques (web, actualités, images)
- Recherchez sur le web avec des paramètres personnalisables (localisation, etc.)

Pour plus de détails, consultez la [référence de l’API du point de terminaison /search](/api-reference/endpoint/search).

<CodeGroup>

<SearchPython />
<SearchNode />
<SearchCURL />

</CodeGroup>

### Réponse

Les SDK renverront directement l’objet de données. cURL renverra la charge utile complète.

<SearchResponse />

### Extraction sans schéma

Vous pouvez désormais extraire sans schéma en transmettant simplement un `prompt` au point de terminaison. Le LLM détermine la structure des données.

<CodeGroup>
  <ScrapeJsonNoSchemaPython />
  <ScrapeJsonNoSchemaNode />
  <ScrapeJsonNoSchemaCURL />
</CodeGroup>

Résultat :

<ScrapeJsonNoSchemaOutput />

## Interagir avec une page à l’aide des actions

Firecrawl vous permet d’exécuter diverses actions sur une page web avant d’en extraire le contenu. C’est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre des pages ou accéder à du contenu nécessitant une interaction de l’utilisateur.

Voici un exemple montrant comment utiliser des actions pour se rendre sur google.com, rechercher Firecrawl, cliquer sur le premier résultat et prendre une capture d’écran.

Il est recommandé d’utiliser presque systématiquement l’action `wait` avant et/ou après les autres actions afin de laisser à la page le temps de se charger.

### Exemple

<CodeGroup>

<ScrapeActionsPython />
<ScrapeActionsNode /> 
<ScrapeActionsCURL />

</CodeGroup>

### Résultat

<CodeGroup>

<ScrapeActionsOutput />

</CodeGroup>

## Open Source vs Cloud

Firecrawl est open source et disponible sous la [licence AGPL-3.0](https://github.com/mendableai/firecrawl/blob/main/LICENSE).

Pour offrir le meilleur produit possible, nous proposons une version hébergée de Firecrawl en plus de notre offre open source. La solution cloud nous permet d’innover en continu et de maintenir un service de haute qualité, pérenne, pour tous les utilisateurs.

Firecrawl Cloud est disponible sur [firecrawl.dev](https://firecrawl.dev) et propose un ensemble de fonctionnalités non disponibles dans la version open source :

![Firecrawl Cloud vs Open Source](./images/open-source-cloud.png)

## Contributions

Nous apprécions vos contributions ! Veuillez lire notre [guide de contribution](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) avant de proposer une pull request.