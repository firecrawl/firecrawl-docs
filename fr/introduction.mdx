---
title: Démarrage rapide
description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
og:title: "Démarrage rapide | Firecrawl"
og:description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
---

import InstallationPython from "/snippets/fr/v2/installation/python.mdx";
import InstallationNode from "/snippets/fr/v2/installation/js.mdx";
import ScrapePython from "/snippets/v2/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v2/scrape/base/js.mdx";
import ScrapeCURL from "/snippets/v2/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v2/scrape/base/output.mdx";
import CrawlPython from "/snippets/fr/v2/crawl/base/python.mdx";
import CrawlNode from "/snippets/fr/v2/crawl/base/js.mdx";
import CrawlCURL from "/snippets/fr/v2/crawl/base/curl.mdx";
import CrawlAsyncOutput from "/snippets/v2/start-crawl/base/output.mdx";
import GetCrawlJobPython from "/snippets/fr/v2/crawl-status/short/python.mdx";
import GetCrawlJobNode from "/snippets/fr/v2/crawl-status/short/js.mdx";
import GetCrawlJobCURL from "/snippets/fr/v2/crawl-status/short/curl.mdx";
import GetCrawlJobOutputScraping from "/snippets/fr/v2/crawl-status/base/output-scraping.mdx";
import GetCrawlJobOutputCompleted from "/snippets/fr/v2/crawl-status/base/output-completed.mdx";
import ScrapeJsonCURL from "/snippets/v2/scrape/json/base/curl.mdx";
import ScrapeJsonPython from "/snippets/v2/scrape/json/base/python.mdx";
import ScrapeJsonNode from "/snippets/v2/scrape/json/base/js.mdx";
import ScrapeJsonOutput from "/snippets/v2/scrape/json/base/output.mdx";
import ScrapeJsonNoSchemaCURL from "/snippets/v2/scrape/json/no-schema/curl.mdx";
import ScrapeJsonNoSchemaPython from "/snippets/v2/scrape/json/no-schema/python.mdx";
import ScrapeJsonNoSchemaNode from "/snippets/v2/scrape/json/no-schema/js.mdx";
import ScrapeJsonNoSchemaOutput from "/snippets/v2/scrape/json/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/v2/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/v2/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/v2/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/v2/scrape/actions/output.mdx";
import SearchPython from "/snippets/v2/search/base/python.mdx";
import SearchNode from "/snippets/v2/search/base/js.mdx";
import SearchCURL from "/snippets/v2/search/base/curl.mdx";
import SearchResponse from "/snippets/v2/search/base/output.mdx";

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.png" alt="Héros clair" />

<div id="welcome-to-firecrawl">
  ## Bienvenue dans Firecrawl
</div>

[Firecrawl](https://firecrawl.dev?ref=github) est un service d’API qui prend une URL, la crawle et la convertit en Markdown propre. Nous explorons toutes les sous-pages accessibles et vous fournissons un Markdown propre pour chacune. Aucun sitemap nécessaire.

<div id="how-to-use-it">
  ## Comment l’utiliser ?
</div>

Nous proposons une API simple d’utilisation avec notre version hébergée. Vous trouverez l’espace de test et la documentation [ici](https://firecrawl.dev/playground). Vous pouvez également auto-héberger le backend si vous le souhaitez.

Consultez les ressources suivantes pour démarrer :

* [x] **API** : [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs** : [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node)
* [x] **Frameworks LLM** : [LangChain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [LangChain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low-code** : [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **SDKs de la communauté** : [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust) (v1)
* [x] **Autres** : [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] Vous souhaitez un SDK ou une intégration ? Dites-le-nous en ouvrant un ticket.

**Self-host :** Pour l’auto‑hébergement, consultez le guide [ici](/fr/contributing/self-host).

<div id="api-key">
  ### Clé API
</div>

Pour utiliser l’API, vous devez créer un compte sur [Firecrawl](https://firecrawl.dev) et récupérer une clé API.

<div id="features">
  ### Fonctionnalités
</div>

* [**Scrape**](#scraping) : récupère une URL et renvoie son contenu dans un format prêt pour les LLM (markdown, résumé, données structurées via le [mode JSON](#json-mode), capture d’écran, HTML)
* [**Crawl**](#crawling) : explore toutes les URL d’une page web et renvoie le contenu dans un format prêt pour les LLM
* [**Map**](/fr/features/map) : indiquez un site web et obtenez toutes les URL du site — extrêmement rapide
* [**Search**](/fr/features/search) : recherchez sur le web et obtenez le contenu complet des résultats
* [**Extract**](/fr/features/extract) : extrayez des données structurées à partir d’une page, de plusieurs pages ou de sites entiers avec l’IA.

<div id="powerful-capabilities">
  ### Capacités avancées
</div>

* **Formats prêts pour les LLM** : Markdown, résumé, données structurées, capture d’écran, HTML, liens, métadonnées
* **Les cas difficiles** : proxys, mécanismes anti-bot, contenu dynamique (rendu JS), analyse de sortie, orchestration
* **Ultra-rapide** : obtenez des résultats en quelques secondes — conçu pour la vitesse et les cas d’usage à haut débit.
* **Personnalisation** : exclure des balises, explorer derrière des murs d’authentification avec des en-têtes personnalisés, profondeur d’exploration maximale, etc.
* **Analyse des médias** : PDF, DOCX, images.
* **Fiabilité avant tout** : conçu pour obtenir les données dont vous avez besoin — quelle que soit la difficulté.
* **Actions** : cliquer, faire défiler, saisir, attendre et plus encore avant d’extraire des données

Vous trouverez l’ensemble des capacités de Firecrawl et leur utilisation dans notre [documentation](https://docs.firecrawl.dev/api-reference/v2-introduction)

<div id="installing-firecrawl">
  ## Installer Firecrawl
</div>

<CodeGroup>
  <InstallationPython />

  <InstallationNode />
</CodeGroup>

<div id="scraping">
  ## Scraping
</div>

Pour récupérer le contenu d’une seule URL, utilisez la méthode `scrape`. Elle prend l’URL en paramètre et renvoie les données récupérées sous forme de dictionnaire.

<CodeGroup>
  <ScrapePython />

  <ScrapeNode />

  <ScrapeCURL />
</CodeGroup>

<div id="response">
  ### Réponse
</div>

Les SDK renvoient directement l’objet de données. cURL renvoie la charge utile exactement comme indiqué ci-dessous.

<ScrapeResponse />

<div id="crawling">
  ## Exploration
</div>

La fonctionnalité d’exploration permet de découvrir et d’extraire automatiquement le contenu d’une URL et de toutes ses sous-pages accessibles. Avec nos SDK, appelez simplement la méthode d’exploration : elle soumet un travail d’exploration, attend son achèvement et renvoie les résultats complets pour l’ensemble du site.

<div id="usage">
  ### Utilisation
</div>

<CodeGroup>
  <CrawlPython />

  <CrawlNode />

  <CrawlCURL />
</CodeGroup>

Si vous utilisez directement notre API, cURL ou les fonctions `start crawl` dans les SDK, un `ID` sera renvoyé que vous pourrez utiliser pour vérifier l’état du crawl.

<CrawlAsyncOutput />

<div id="get-crawl-status">
  ### Obtenir l’état d’un crawl
</div>

Permet de vérifier l’état d’un job de crawl et de récupérer son résultat.

<CodeGroup>
  <GetCrawlJobPython />

  <GetCrawlJobNode />

  <GetCrawlJobCURL />
</CodeGroup>

<div id="response">
  #### Réponse
</div>

La réponse varie selon l’état du crawl. Pour les réponses incomplètes ou volumineuses dépassant 10 Mo, un paramètre d’URL `next` est fourni. Vous devez requêter cette URL pour récupérer les 10 Mo suivants de données. Si le paramètre `next` est absent, cela indique la fin des données du crawl.

<CodeGroup>
  <GetCrawlJobOutputScraping />

  <GetCrawlJobOutputCompleted />
</CodeGroup>

<div id="json-mode">
  ## Mode JSON
</div>

Avec le mode JSON, vous pouvez facilement extraire des données structurées à partir de n&#39;importe quelle URL. Nous prenons en charge les schémas Pydantic pour vous simplifier la tâche. Voici comment l&#39;utiliser :

<CodeGroup>
  <ScrapeJsonPython />

  <ScrapeJsonNode />

  <ScrapeJsonCURL />
</CodeGroup>

Résultat :

<ScrapeJsonOutput />

<div id="search">
  ## Recherche
</div>

L’API de recherche de Firecrawl vous permet d’effectuer des recherches sur le web et, en option, de scraper les résultats en une seule opération.

* Choisissez des formats de sortie spécifiques (Markdown, HTML, liens, captures d’écran)
* Choisissez des sources spécifiques (web, actualités, images)
* Recherchez sur le web avec des paramètres personnalisables (localisation, etc.)

Pour plus de détails, consultez la [référence de l’API du point de terminaison /search](/fr/api-reference/endpoint/search).

<CodeGroup>
  <SearchPython />

  <SearchNode />

  <SearchCURL />
</CodeGroup>

<div id="response">
  ### Réponse
</div>

Les SDK renverront directement l’objet de données. cURL renverra la charge utile complète.

<SearchResponse />

<div id="extracting-without-schema">
  ### Extraction sans schéma
</div>

Vous pouvez désormais extraire sans schéma en transmettant simplement un `prompt` au point de terminaison. Le LLM détermine la structure des données.

<CodeGroup>
  <ScrapeJsonNoSchemaPython />

  <ScrapeJsonNoSchemaNode />

  <ScrapeJsonNoSchemaCURL />
</CodeGroup>

Résultat :

<ScrapeJsonNoSchemaOutput />

<div id="interacting-with-the-page-with-actions">
  ## Interagir avec une page à l’aide des actions
</div>

Firecrawl vous permet d’exécuter diverses actions sur une page web avant d’en extraire le contenu. C’est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre des pages ou accéder à du contenu nécessitant une interaction de l’utilisateur.

Voici un exemple montrant comment utiliser des actions pour se rendre sur google.com, rechercher Firecrawl, cliquer sur le premier résultat et prendre une capture d’écran.

Il est recommandé d’utiliser presque systématiquement l’action `wait` avant et/ou après les autres actions afin de laisser à la page le temps de se charger.

<div id="example">
  ### Exemple
</div>

<CodeGroup>
  <ScrapeActionsPython />

  <ScrapeActionsNode />

  <ScrapeActionsCURL />
</CodeGroup>

<div id="output">
  ### Résultat
</div>

<CodeGroup>
  <ScrapeActionsOutput />
</CodeGroup>

<div id="open-source-vs-cloud">
  ## Open Source vs Cloud
</div>

Firecrawl est open source et disponible sous la [licence AGPL-3.0](https://github.com/mendableai/firecrawl/blob/main/LICENSE).

Pour offrir le meilleur produit possible, nous proposons une version hébergée de Firecrawl en plus de notre offre open source. La solution cloud nous permet d’innover en continu et de maintenir un service de haute qualité, pérenne, pour tous les utilisateurs.

Firecrawl Cloud est disponible sur [firecrawl.dev](https://firecrawl.dev) et propose un ensemble de fonctionnalités non disponibles dans la version open source :

![Firecrawl Cloud vs Open Source](./images/open-source-cloud.png)

<div id="contributing">
  ## Contributions
</div>

Nous apprécions vos contributions ! Veuillez lire notre [guide de contribution](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) avant de proposer une pull request.