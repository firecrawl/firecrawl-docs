---
title: "Exploiter l’extraction par LLM pour les insights clients"
description: "Exploiter l’extraction par LLM pour obtenir des insights et générer des leads avec Make et Firecrawl."
og:title: "Exploiter l’extraction par LLM pour les insights clients | Firecrawl"
og:description: "Exploiter l’extraction par LLM pour obtenir des insights et générer des leads avec Make et Firecrawl."
---

> Remarque : cet exemple utilise la [version v0 de l’API Firecrawl](/fr/v0/introduction). Vous pouvez installer la version 0.0.20 du SDK Python ou la 0.0.36 du SDK Node.

<div id="introduction">
  ### Introduction
</div>

Comprendre nos clients — non seulement qui ils sont, mais surtout ce qu’ils font — est essentiel pour adapter efficacement nos produits et services. Dans un modèle en libre-service, de très nombreux clients arrivent avec peu ou pas d’informations disponibles à leur sujet. Le fait de chercher proactivement à comprendre qui ils sont a longtemps été chronophage, nécessitant une collecte manuelle de données et des analyses pour dégager des informations exploitables.

Cependant, grâce à la puissance des LLM et à leurs capacités avancées d’extraction de données, nous avons automatisé ce processus. En utilisant des LLM pour extraire et analyser les données clients, nous avons considérablement réduit notre charge de travail, ce qui nous permet de comprendre et de servir notre clientèle plus efficacement que jamais.

Si vous avez des connaissances techniques limitées, vous pouvez créer une automatisation qui récupère des informations ciblées sur vos clients afin d’orienter le produit et de générer des leads. Voici comment le faire vous-même avec [Make](https://make.com/) et [Firecrawl](https://www.firecrawl.dev/).

***

<div id="overview-of-the-tools">
  ### Aperçu des outils
</div>

**Firecrawl**

Firecrawl est une plateforme de scraping, de recherche et d’extraction. Elle vous permet de récupérer des données du web et de les convertir en markdown lisible par les LLM ou en données structurées.

Lorsque nous voulons obtenir des informations sur nos clients, nous pouvons utiliser la fonctionnalité d’extraction LLM de Firecrawl pour préciser exactement les informations à extraire de leurs sites web.

**Make.com (anciennement Integromat)**

Make est une plateforme d’automatisation qui permet de créer des workflows personnalisés pour connecter diverses applications et services, sans compétences techniques poussées. Elle propose une interface visuelle où l’on peut glisser-déposer des éléments pour concevoir ses automatisations.

Nous pouvons utiliser Make pour relier une feuille de calcul contenant des données utilisateurs à Firecrawl, ce qui nous permet d’effectuer l’extraction avec un peu de JSON seulement.

<div id="preparing-our-data">
  ### Configuration du scénario
</div>

* Guide pas à pas pour configurer le processus d’extraction de données.
* **Connexion de Google Sheets à Make.com**
  * Comment les données utilisateurs sont initialement collectées et stockées.
* **Configuration de la requête HTTP dans Make.com**
  * Description de la configuration des requêtes API vers Firecrawl.
  * Objectif de ces requêtes (p. ex., extraction d’informations sur l’entreprise).

### Préparer nos données

Avant de commencer, nous voulons nous assurer que nos données sont prêtes pour Firecrawl. Dans ce cas, j’ai créé une feuille de calcul simple avec des utilisateurs importés depuis notre base de données. Nous voulons prendre les domaines d’adresse e‑mail de nos utilisateurs et les transformer en liens au format https:// :

![](https://i.imgur.com/gssynZa.png)

Nous voulons également ajouter quelques attributs que nous souhaitons connaître sur ces entreprises. Pour ma part, je veux comprendre un peu l’entreprise, son secteur et sa clientèle. Je les ai définis dans des colonnes comme suit :
company&#95;description
company&#95;type
who&#95;they&#95;serve

Maintenant que nos données sont prêtes, nous pouvons commencer à configurer notre automatisation dans Make !

## Mise en place de notre automatisation

Pour démarrer notre automatisation, il suffit de suivre un processus en trois étapes dans Make. Ici, nous allons sélectionner trois applications dans notre scénario :

Google Sheets - Obtenir les valeurs d’une plage
HTTP - Effectuer une requête d’authentification avec clé API
Google Sheets - Mettre à jour une ligne

Nous allons également ajouter l’outil de contrôle de flux « Ignorer » au cas où nous rencontrerions des erreurs. Cela permettra à l’automatisation de continuer.

![](https://i.imgur.com/MdCWv30.png)

Cette automatisation nous permettra d’extraire un ensemble de liens depuis notre feuille de calcul, de les envoyer à Firecrawl pour l’extraction de données, puis de renseigner de nouveau notre feuille de calcul avec les informations souhaitées.

Commençons par configurer notre première application. Notre objectif est d’exporter toutes les URL afin de pouvoir les envoyer à Firecrawl pour extraction. Voici la configuration pour récupérer ces URL :

![](https://i.imgur.com/WHa91kY.png)

**Important* - assurez-vous de commencer à extraire les données à partir de la deuxième ligne. Si vous incluez l’en-tête, vous finirez par rencontrer une erreur.

***

Super ! Maintenant que tout est configuré, préparons notre requête HTTP. Pour cela, rendez-vous sur https://firecrawl.dev pour vous inscrire et obtenir votre clé API (vous pouvez commencer gratuitement !). Une fois inscrit, allez sur https://firecrawl.dev/account pour consulter votre clé API.

Nous allons utiliser le point de terminaison /scrape de Firecrawl. Ce point de terminaison nous permettra de récupérer des informations à partir d’une URL unique, de les convertir en markdown propre, puis de les utiliser pour extraire les données dont nous avons besoin. Je renseignerai toutes les conditions nécessaires dans notre action Make « HTTP request » en m’appuyant sur la référence de l’API dans leur documentation.

Dans Make, je configure maintenant l’appel à l’API en m’appuyant sur la documentation de Firecrawl. Nous utiliserons POST comme méthode HTTP et définirons deux en-têtes.

```
En-tête 1 :
Nom : Authorization
Valeur : Bearer votre clé d’API

En-tête 2 :
Nom : Content-Type
Valeur : application/json
```

![](https://i.imgur.com/LJ8g142.png)
Nous voulons également définir le corps de la requête et les types de contenu. Voici ce que nous allons faire :

```
Type de corps : Raw
Type de contenu : JSON (application/json)
```

Nous cliquerons également sur « oui » pour parser notre réponse. Cela la convertira automatiquement au format JSON.

Le contenu de la requête constitue le cœur de ce que nous voulons accomplir. Voici le contenu de la requête que nous utiliserons pour ce cas d’usage :

```
{
  "url": "1. url(B)"

"pageOptions": {
    "onlyMainContent": true
  },
  "extractorOptions": {
    "mode": "llm-extraction",
    "extractionPrompt": "Extrait la description de l’entreprise (en une phrase expliquant ce que fait l’entreprise), le secteur de l’entreprise (logiciel, services, IA, etc.) — cela devrait idéalement être une simple étiquette avec quelques mots-clés — et à qui elle s’adresse (qui sont ses clients). S’il n’y a pas d’information claire pour répondre à la question, écrire « no info »."
    "extractionSchema": {
      "type": "object",
      "properties": {
        "company_description": {
          "type": "string"
        },
        "company_industry": {
          "type": "string"
        },
        "who_they_serve": {
          "type": "string"
        }
      },
      "required": [
        "company_description",
        "company_industry",
        "who_they_serve"
      ]
    }
  }
}
```

![](https://i.imgur.com/DrMc1g2.png)

**Remarque :* le champ vert dans la capture d’écran est un élément dynamique que vous pouvez sélectionner dans l’interface de Make. Au lieu de `url (B)`, le bloc peut être la première URL de vos données.

![](https://i.imgur.com/D4HCBNe.png)

Parfait ! Nous avons maintenant configuré notre requête HTTP. Testons-la pour vérifier que tout fonctionne comme prévu. Cliquez sur « Run once » dans Make et nous devrions récupérer des données.

![](https://i.imgur.com/QuQZs0U.png)

Lorsque nous exécutons, vérifions notre première opération. Dans la sortie, nous devrions obtenir un « status code: 200 », ce qui signifie que notre requête à l’API a réussi. Dans la sortie, cliquez sur data pour vérifier que nous avons bien obtenu les données nécessaires.

![](https://i.imgur.com/pm614VA.png)

Notre résultat semble concluant ! Dans llm&#95;extraction, nous voyons les trois attributs de données que nous voulions extraire du site web.

**Remarque* : si vous rencontrez une erreur `500` lors de la première opération, puis des réponses `200` pour les suivantes, c’est peut-être parce que l’opération est exécutée sur la première ligne de vos données (la ligne d’en-tête). Cela posera des problèmes lors de la réimportation des données dans les feuilles ! Veillez à commencer à partir de la deuxième ligne, comme indiqué précédemment.

Maintenant que nous savons que la requête HTTP fonctionne correctement, il ne nous reste plus qu’à récupérer le JSON renvoyé par Firecrawl et à le réintégrer dans notre feuille de calcul.

***

Nous devons maintenant reprendre les données extraites et les remettre dans notre feuille de calcul. Pour ce faire, nous allons utiliser le JSON renvoyé par notre requête HTTP et renseigner le texte dans les tableaux concernés.

Commençons par connecter la même Google Sheet et définir le critère « Row Number ». Ici, nous allons simplement utiliser l’interface de Make pour choisir « row number ».

![](https://i.imgur.com/BYpPabk.png)

Il ne reste plus qu’à indiquer quelles données extraites par le LLM vont dans quelle colonne. Ici, nous pouvons simplement utiliser l’interface de Make pour configurer cela.

![](https://i.imgur.com/219tft2.png)

C’est tout, il est temps de tester notre automatisation !

***

Cliquons sur « Run once » dans l’interface de Make et vérifions que tout s’exécute correctement. L’automatisation devrait commencer à parcourir les liens un par un et à alimenter notre feuille de calcul en temps réel.

![](https://i.imgur.com/vU1CJlt.png)

C’est gagné ! Avec Make et Firecrawl, nous avons pu extraire des informations précises sur nos clients sans avoir à visiter manuellement chacun de leurs sites web.

À la lecture des données, nous commençons à mieux comprendre nos clients. Cependant, nous ne sommes pas limités à ces caractéristiques spécifiques. Si nous le souhaitons, nous pouvons personnaliser notre JSON et notre prompt d’extraction pour obtenir d’autres informations sur ces entreprises.

<div id="going-a-step-further">
  ### Cas d’usage
</div>

L’extraction via LLM nous permet d’obtenir rapidement des informations spécifiques sur le web, pertinentes pour notre activité. Nous pouvons utiliser ces automatisations pour réaliser une variété de tâches.

**Produit :**
Particulièrement pour les entreprises en libre-service, nous pouvons comprendre les tendances des secteurs qui utilisent notre produit. Quels sont les 2 ou 3 principaux secteurs qui utilisent notre technologie et à quelles fins ? Cela nous permettra de prendre de meilleures décisions produit en hiérarchisant les bons clients sur lesquels nous concentrer.

**Développement commercial :**
En comprenant qui sont nos utilisateurs, nous pouvons rechercher des entreprises similaires qui pourraient également bénéficier de notre produit. En menant une automatisation comparable, nous pouvons extraire des signaux positifs chez des prospects susceptibles de tirer parti de notre produit.

Nous pouvons aussi utiliser ces données pour générer de meilleurs e-mails de prospection, plus adaptés à chaque prospect.

**Études de marché :**
Les cabinets d’études de marché passent énormément de temps à effectuer des recherches secondaires, surtout dans des secteurs de niche. Nous pouvons accélérer la collecte de données en automatisant l’extraction et l’organisation de données provenant de sources diverses. Cette automatisation améliore l’efficacité et s’adapte à la croissance des besoins en données, ce qui en fait un outil précieux pour la prise de décision stratégique dans des secteurs en rapide évolution.

### Aller plus loin

Ce n’était qu’un exemple simple montrant comment utiliser des LLM pour extraire des données pertinentes de sites web à partir d’une feuille de calcul statique. Vous pouvez aller plus loin en le connectant dynamiquement à vos inscriptions. Vous pouvez aussi le relier à d’autres outils pour accélérer encore votre productivité, par exemple en utilisant le contenu extrait pour générer des messages de prospection plus personnalisés.

Si vous avez trouvé cela utile, n’hésitez pas à me le dire ! J’aimerais avoir vos retours ou découvrir ce que vous construisez. Vous pouvez me joindre à eric@mendable.ai. Bonne chance et bonne création !