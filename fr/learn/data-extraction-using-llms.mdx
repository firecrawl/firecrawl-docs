---
title: "Extraire des données de sites web avec des LLM"
description: "Découvrez comment utiliser Firecrawl et Groq pour extraire des données structurées d’une page web en quelques lignes de code."
"og:image": "/images/og.png"
"twitter:image": "/images/og.png"
og:title: "Extraire des données de sites web avec des LLM | Firecrawl"
og:description: "Découvrez comment utiliser Firecrawl et Groq pour extraire des données structurées d’une page web en quelques lignes de code."
---

> Remarque : cet exemple utilise la [version v0 de l’API Firecrawl](/fr/v0/introduction). Vous pouvez installer la version 0.0.20 du SDK Python ou la 0.0.36 du SDK Node.

<div id="setup">
  ## Configuration
</div>

Installez les dépendances Python requises, notamment groq et firecrawl-py.

```bash
pip install groq firecrawl-py
```

<div id="getting-your-groq-and-firecrawl-api-keys">
  ## Obtenir vos clés d’API Groq et Firecrawl
</div>

Pour utiliser Groq et Firecrawl, vous devez obtenir vos clés d’API. Vous pouvez récupérer votre clé d’API Groq sur [groq.com](https://groq.com) et votre clé d’API Firecrawl sur [firecrawl.dev](https://firecrawl.dev).

<div id="load-website-with-firecrawl">
  ## Charger un site web avec Firecrawl
</div>

Pour récupérer toutes les données d’une page web et garantir un format propre, nous utiliserons [Firecrawl](https://firecrawl.dev). Il contourne les sites bloqués par JavaScript, extrait le contenu principal et produit un format lisible par les LLM pour une meilleure précision.

Voici comment nous allons scraper l’URL d’un site avec Firecrawl. Nous définirons également `pageOptions` pour n’extraire que le contenu principal (`onlyMainContent: true`) de la page — en excluant la navigation, le pied de page, etc.

```python
from firecrawl import FirecrawlApp  # Import de FireCrawlLoader

url = "https://about.fb.com/news/2024/04/introducing-our-open-mixed-reality-ecosystem/"

firecrawl = FirecrawlApp(
    api_key="fc-YOUR_FIRECRAWL_API_KEY",
)
page_content = firecrawl.scrape_url(url=url,  # URL cible à crawler
    params={
        "pageOptions":{
            "onlyMainContent": True # Ignorer la navigation, le pied de page, etc.
        }
    })
print(page_content)
```

Parfait, nous disposons maintenant de données propres issues du site web, prêtes à être envoyées au LLM pour l’extraction.

<div id="extraction-and-generation">
  ## Extraction et génération
</div>

Maintenant que nous disposons des données du site web, utilisons Groq pour extraire les informations dont nous avons besoin. Nous allons utiliser le modèle Groq Llama 3 en mode JSON et sélectionner certains champs à partir du contenu de la page.

Nous utilisons le modèle Llama 3 8B pour cet exemple. N’hésitez pas à recourir à des modèles plus grands pour obtenir de meilleurs résultats.

```python
import json
from groq import Groq

client = Groq(
    api_key="gsk_YOUR_GROQ_API_KEY",  # Remarque : remplacez « API_KEY » par votre clé API Groq réelle
)

# Ici, nous définissons les champs à extraire du contenu de la page
extract = ["summary","date","companies_building_with_quest","title_of_the_article","people_testimonials"]

completion = client.chat.completions.create(
    model="llama3-8b-8192",
    messages=[
        {
            "role": "system",
            "content": "Vous êtes un conseiller juridique qui extrait des informations de documents au format JSON."
        },
        {
            "role": "user",
            # Ici, nous passons le contenu de la page et les champs à extraire
            "content": f"Extrayez les informations suivantes à partir de la documentation fournie :\nContenu de la page :\n\n{page_content}\n\nInformations à extraire : {extract}"
        }
    ],
    temperature=0,
    max_tokens=1024,
    top_p=1,
    stream=False,
    stop=None,
    # Nous définissons le format de la réponse sur un objet JSON
    response_format={"type": "json_object"}
)


# Afficher la réponse JSON avec une mise en forme lisible
dataExtracted = json.dumps(str(completion.choices[0].message.content), indent=4)

print(dataExtracted)
```

<div id="and-voila">
  ## Et voilà !
</div>

Vous avez maintenant créé un bot d’extraction de données avec Groq et Firecrawl. Vous pouvez désormais l’utiliser pour extraire des données structurées de n’importe quel site web.

Si vous avez des questions ou besoin d’aide, n’hésitez pas à nous contacter via [Firecrawl](https://firecrawl.dev).