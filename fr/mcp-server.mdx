---
title: Serveur MCP Firecrawl
description: "Utilisez lâ€™API Firecrawl via le Model Context Protocol"
og:title: "Serveur MCP Firecrawl"
og:description: "Les serveurs MCP Firecrawl vous permettent dâ€™utiliser lâ€™API Firecrawl via le Model Context Protocol"
sidebarTitle: "Serveur MCP"
---

Une implÃ©mentation de serveur Model Context Protocol (MCP) intÃ©grant [Firecrawl](https://github.com/mendableai/firecrawl) pour des fonctionnalitÃ©s de web scraping. Notre serveur MCP est open source et disponible sur [GitHub](https://github.com/mendableai/firecrawl-mcp-server).

<div id="features">
  ## FonctionnalitÃ©s
</div>

- Scraping, crawling et dÃ©couverte du web
- Recherche et extraction de contenu
- Recherche approfondie et scraping par lots
- Prise en charge du cloud et de lâ€™autoâ€‘hÃ©bergement
- Prise en charge des SSE

<div id="installation">
  ## Installation
</div>

Vous pouvez utiliser notre URL hÃ©bergÃ©e ou exÃ©cuter le serveur en local. RÃ©cupÃ©rez votre clÃ© API sur [https://firecrawl.dev/app/api-keys](https://www.firecrawl.dev/app/api-keys)

<div id="remote-hosted-url">
  ### URL hÃ©bergÃ©e Ã  distance
</div>

```bash
https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/sse
```


<div id="running-with-npx">
  ### ExÃ©cuter avec npx
</div>

```bash
env FIRECRAWL_API_KEY=fc-VOTRE_CLÃ‰_API npx -y firecrawl-mcp
```


<div id="manual-installation">
  ### Installation manuelle
</div>

```bash
npm install -g firecrawl-mcp
```


<div id="running-on-cursor">
  ### Utilisation avec Cursor
</div>

<a href="cursor://anysphere.cursor-deeplink/mcp/install?name=firecrawl&config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyIteSIsImZpcmVjcmF3bC1tY3AiXSwiZW52Ijp7IkZJUkVDUkFXTF9BUElfS0VZIjoiWU9VUi1BUEktS0VZIn19"><img src="https://cursor.com/deeplink/mcp-install-dark.png" alt="Ajouter le serveur MCP Firecrawl Ã  Cursor" style={{ maxHeight: 32 }} /></a>

<div id="manual-installation">
  #### Installation manuelle
</div>

Configuration de Cursor ðŸ–¥ï¸
Remarque : nÃ©cessite Cursor version 0.45.6+
Pour des instructions de configuration Ã  jour, consultez la documentation officielle de Cursor sur la configuration des serveurs MCP :
[Guide de configuration du serveur MCP de Cursor](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)

Pour configurer Firecrawl MCP dans Cursor **v0.48.6**

1. Ouvrez les paramÃ¨tres de Cursor
2. Allez dans Features > MCP Servers
3. Cliquez sur "+ Add new global MCP server"
4. Saisissez le code suivant :
   ```json
   {
     "mcpServers": {
       "firecrawl-mcp": {
         "command": "npx",
         "args": ["-y", "firecrawl-mcp"],
         "env": {
           "FIRECRAWL_API_KEY": "YOUR-API-KEY"
         }
       }
     }
   }
   ```

Pour configurer Firecrawl MCP dans Cursor **v0.45.6**

1. Ouvrez les paramÃ¨tres de Cursor
2. Allez dans Features > MCP Servers
3. Cliquez sur "+ Add New MCP Server"
4. Renseignez les Ã©lÃ©ments suivants :
   - Name: "firecrawl-mcp" (ou le nom de votre choix)
   - Type: "command"
   - Command: `env FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp`

> Si vous utilisez Windows et rencontrez des problÃ¨mes, essayez `cmd /c "set FIRECRAWL_API_KEY=your-api-key && npx -y firecrawl-mcp"`

Remplacez `your-api-key` par votre clÃ© API Firecrawl. Si vous n'en avez pas encore, crÃ©ez un compte et rÃ©cupÃ©rez-la via https://www.firecrawl.dev/app/api-keys

AprÃ¨s lâ€™ajout, actualisez la liste des serveurs MCP pour voir les nouveaux outils. Le Composer Agent utilisera automatiquement Firecrawl MCP lorsque câ€™est pertinent, mais vous pouvez aussi le demander explicitement en dÃ©crivant vos besoins en web scraping. AccÃ©dez au Composer via Command+L (Mac), sÃ©lectionnez Â« Agent Â» Ã  cÃ´tÃ© du bouton dâ€™envoi, puis saisissez votre requÃªte.

<div id="running-on-windsurf">
  ### ExÃ©cuter sur Windsurf
</div>

Ajoutez ceci Ã  votre `./codeium/windsurf/model_config.json` :

```json
{
  "mcpServers": {
    "mcp-server-firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "VOTRE_API_KEY"
      }
    }
  }
}
```


<div id="running-with-sse-mode">
  ### ExÃ©cution en mode SSE
</div>

Pour exÃ©cuter le serveur en local avec les Server-Sent Events (SSE) plutÃ´t que le transport stdio par dÃ©fautÂ :

```bash
env SSE_LOCAL=true FIRECRAWL_API_KEY=fc-VOTRE_CLÃ‰_API npx -y firecrawl-mcp
```

Utilisez lâ€™URLÂ : http://localhost:3000/v2/sse ou https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/sse


<div id="installing-via-smithery-legacy">
  ### Installation via Smithery (ancien)
</div>

Pour installer automatiquement Firecrawl pour Claude Desktop via [Smithery](https://smithery.ai/server/@mendableai/mcp-server-firecrawl)Â :

```bash
npx -y @smithery/cli install @mendableai/mcp-server-firecrawl --client claude
```


<div id="running-on-vs-code">
  ### ExÃ©cution dans VS Code
</div>

Pour une installation en un clic, cliquez sur lâ€™un des boutons ci-dessousâ€¦

[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square\&logo=visualstudiocode\&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square\&logo=visualstudiocode\&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D\&quality=insiders)

Pour une installation manuelle, ajoutez le bloc JSON suivant Ã  votre fichier ParamÃ¨tres utilisateur (JSON) dans VS Code. Pour ce faire, appuyez sur `Ctrl + Shift + P` et tapez `Preferences: Open User Settings (JSON)`.

```json
{
  "mcp": {
    "inputs": [
      {
        "type": "promptString",
        "id": "apiKey",
        "description": "ClÃ© dâ€™API Firecrawl",
        "password": true
      }
    ],
    "servers": {
      "firecrawl": {
        "command": "npx",
        "args": ["-y", "firecrawl-mcp"],
        "env": {
          "FIRECRAWL_API_KEY": "${input:apiKey}"
        }
      }
    }
  }
}
```

Vous pouvez Ã©galement lâ€™ajouter Ã  un fichier nommÃ© `.vscode/mcp.json` dans votre espace de travail. Cela vous permettra de partager la configuration avec dâ€™autresÂ :

```json
{
  "inputs": [
    {
      "type": "promptString",
      "id": "apiKey",
      "description": "ClÃ© dâ€™API Firecrawl"
      "password": true
    }
  ],
  "servers": {
    "firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "${input:apiKey}"
      }
    }
  }
}
```


<div id="running-on-claude-desktop">
  ### ExÃ©cution sur Claude Desktop
</div>

Ajoutez ceci au fichier de configuration de ClaudeÂ :

```json
{
  "mcpServers": {
    "firecrawl": {
      "url": "https://mcp.firecrawl.dev/{YOUR_API_KEY}/v2/sse"
    }
  }
}
```


<div id="running-on-claude-code">
  ### ExÃ©cution avec Claude Code
</div>

Ajoutez le serveur MCP de Firecrawl Ã  lâ€™aide de la CLI de Claude Code :

```bash
claude mcp add firecrawl -e FIRECRAWL_API_KEY=your-api-key -- npx -y firecrawl-mcp
```


<div id="configuration">
  ## Configuration
</div>

<div id="environment-variables">
  ### Variables dâ€™environnement
</div>

<div id="required-for-cloud-api">
  #### Requis pour lâ€™API Cloud
</div>

- `FIRECRAWL_API_KEY` : votre clÃ© API Firecrawl
  - Requise lors de lâ€™utilisation de lâ€™API cloud (par dÃ©faut)
  - Facultative lors de lâ€™utilisation dâ€™une instance auto-hÃ©bergÃ©e avec `FIRECRAWL_API_URL`
- `FIRECRAWL_API_URL` (facultatif) : point de terminaison API personnalisÃ© pour les instances auto-hÃ©bergÃ©es
  - Exemple : `https://firecrawl.your-domain.com`
  - Si elle nâ€™est pas renseignÃ©e, lâ€™API cloud sera utilisÃ©e (nÃ©cessite une clÃ© API)

<div id="optional-configuration">
  #### Configuration facultative
</div>

<div id="retry-configuration">
  ##### Configuration des relances
</div>

- `FIRECRAWL_RETRY_MAX_ATTEMPTS`: Nombre maximal de tentatives de relance (par dÃ©faut : 3)
- `FIRECRAWL_RETRY_INITIAL_DELAY`: DÃ©lai initial en millisecondes avant la premiÃ¨re relance (par dÃ©faut : 1000)
- `FIRECRAWL_RETRY_MAX_DELAY`: DÃ©lai maximal en millisecondes entre les relances (par dÃ©faut : 10000)
- `FIRECRAWL_RETRY_BACKOFF_FACTOR`: Facteur de backoff exponentiel (par dÃ©faut : 2)

<div id="credit-usage-monitoring">
  ##### Surveillance de lâ€™utilisation des crÃ©dits
</div>

- `FIRECRAWL_CREDIT_WARNING_THRESHOLD`: Seuil dâ€™avertissement pour lâ€™utilisation des crÃ©dits (par dÃ©fautÂ : 1000)
- `FIRECRAWL_CREDIT_CRITICAL_THRESHOLD`: Seuil critique pour lâ€™utilisation des crÃ©dits (par dÃ©fautÂ : 100)

<div id="configuration-examples">
  ### Exemples de configuration
</div>

Pour lâ€™utilisation de lâ€™API cloud avec des tentatives de reprise personnalisÃ©es et le suivi des crÃ©ditsÂ :

```bash
# Requis pour lâ€™API cloud
export FIRECRAWL_API_KEY=your-api-key

# ParamÃ¨tres de nouvelle tentative (facultatif)
export FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Augmenter le nombre maximal de tentatives
export FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Commencer avec un dÃ©lai de 2 s
export FIRECRAWL_RETRY_MAX_DELAY=30000       # DÃ©lai maximal de 30 s
export FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # Backoff plus agressif

# Surveillance des crÃ©dits (facultatif)
export FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Avertissement Ã  2000 crÃ©dits
export FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Seuil critique Ã  500 crÃ©dits
```

Pour une instance autoâ€‘hÃ©bergÃ©eÂ :

```bash
# Requis pour lâ€™autoâ€‘hÃ©bergement
export FIRECRAWL_API_URL=https://firecrawl.your-domain.com

# Authentification facultative pour lâ€™autoâ€‘hÃ©bergement
export FIRECRAWL_API_KEY=your-api-key  # Si votre instance requiert une authentification

# Configuration personnalisÃ©e des tentatives
export FIRECRAWL_RETRY_MAX_ATTEMPTS=10
export FIRECRAWL_RETRY_INITIAL_DELAY=500     # DÃ©marrer avec des tentatives plus rapides
```


<div id="custom-configuration-with-claude-desktop">
  ### Configuration personnalisÃ©e avec Claude Desktop
</div>

Ajoutez ceci Ã  votre fichier `claude_desktop_config.json` :

```json
{
  "mcpServers": {
    "mcp-server-firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "VOTRE_CLEF_API_ICI",

        "FIRECRAWL_RETRY_MAX_ATTEMPTS": "5",
        "FIRECRAWL_RETRY_INITIAL_DELAY": "2000",
        "FIRECRAWL_RETRY_MAX_DELAY": "30000",
        "FIRECRAWL_RETRY_BACKOFF_FACTOR": "3",

        "FIRECRAWL_CREDIT_WARNING_THRESHOLD": "2000",
        "FIRECRAWL_CREDIT_CRITICAL_THRESHOLD": "500"
      }
    }
  }
}
```


<div id="system-configuration">
  ### Configuration du systÃ¨me
</div>

Le serveur propose plusieurs paramÃ¨tres configurables pouvant Ãªtre dÃ©finis via des variables dâ€™environnement. Voici les valeurs par dÃ©faut si rien nâ€™est spÃ©cifiÃ©Â :

```typescript
const CONFIG = {
  retry: {
    maxAttempts: 3, // Nombre de tentatives de rÃ©essai pour les requÃªtes limitÃ©es par le dÃ©bit
    initialDelay: 1000, // DÃ©lai initial avant le premier rÃ©essai (en millisecondes)
    maxDelay: 10000, // DÃ©lai maximal entre les rÃ©essais (en millisecondes)
    backoffFactor: 2, // Multiplicateur pour lâ€™exponentiel de backoff
  },
  credit: {
    warningThreshold: 1000, // Avertir lorsque lâ€™utilisation des crÃ©dits atteint ce seuil
    criticalThreshold: 100, // Alerte critique lorsque lâ€™utilisation des crÃ©dits atteint ce seuil
  },
};
```

Ces paramÃ¨tres contrÃ´lent :

1. **Comportement de relance**

   * Relance automatiquement les requÃªtes Ã©chouÃ©es en raison des limites de dÃ©bit
   * Utilise un retour arriÃ¨re exponentiel (exponential backoff) pour Ã©viter de surcharger lâ€™API
   * Exemple : avec les paramÃ¨tres par dÃ©faut, les relances seront tentÃ©es aux moments suivants :
     * 1re relance : dÃ©lai de 1 seconde
     * 2e relance : dÃ©lai de 2 secondes
     * 3e relance : dÃ©lai de 4 secondes (plafonnÃ© par maxDelay)

2. **Suivi de lâ€™utilisation des crÃ©dits**
   * Suit la consommation de crÃ©dits pour lâ€™utilisation de lâ€™API cloud
   * Ã‰met des avertissements Ã  des seuils dÃ©finis
   * Aide Ã  prÃ©venir les interruptions de service imprÃ©vues
   * Exemple : avec les paramÃ¨tres par dÃ©faut :
     * Avertissement Ã  1â€¯000 crÃ©dits restants
     * Alerte critique Ã  100 crÃ©dits restants


<div id="rate-limiting-and-batch-processing">
  ### Limitation de dÃ©bit et traitement par lots
</div>

Le serveur utilise les fonctionnalitÃ©s intÃ©grÃ©es de Firecrawl pour la limitation de dÃ©bit et le traitement par lotsÂ :

- Gestion automatique des limites de dÃ©bit avec backoff exponentiel
- Traitement parallÃ¨le efficace pour les opÃ©rations par lots
- Mise en file dâ€™attente et limitation intelligente des requÃªtes
- RÃ©essais automatiques en cas dâ€™erreurs transitoires

<div id="available-tools">
  ## Outils disponibles
</div>

<div id="1-scrape-tool-firecrawl_scrape">
  ### 1. Outil dâ€™extraction (`firecrawl_scrape`)
</div>

Extraire le contenu dâ€™une URL unique avec des options avancÃ©es.

```json
{
  "name": "firecrawl_scrape",
  "arguments": {
    "url": "https://example.com",
    "formats": ["markdown"],
    "onlyMainContent": true,
    "waitFor": 1000,
    "timeout": 30000,
    "mobile": false,
    "includeTags": ["article", "main"],
    "excludeTags": ["nav", "footer"],
    "skipTlsVerification": false
  }
}
```


<div id="2-batch-scrape-tool-firecrawl_batch_scrape">
  ### 2. Outil dâ€™extraction par lots (`firecrawl_batch_scrape`)
</div>

Exploitez plusieurs URL efficacement grÃ¢ce Ã  une limitation de dÃ©bit intÃ©grÃ©e et un traitement parallÃ¨le.

```json
{
  "name": "firecrawl_batch_scrape",
  "arguments": {
    "urls": ["https://example1.com", "https://example2.com"],
    "options": {
      "formats": ["markdown"],
      "onlyMainContent": true
    }
  }
}
```

La rÃ©ponse inclut lâ€™ID dâ€™opÃ©ration pour vÃ©rifier lâ€™Ã©tatÂ :

```json
{
  "content": [
    {
      "type": "text",
      "text": "OpÃ©ration par lots mise en file dâ€™attente avec lâ€™IDÂ : batch_1. Utilisez firecrawl_check_batch_status pour suivre la progression."
    }
  ],
  "isError": false
}
```


<div id="3-check-batch-status-firecrawl_check_batch_status">
  ### 3. VÃ©rifier lâ€™Ã©tat du lot (`firecrawl_check_batch_status`)
</div>

VÃ©rifiez lâ€™Ã©tat dâ€™une opÃ©ration par lots.

```json
{
  "name": "firecrawl_check_batch_status",
  "arguments": {
    "id": "batch_1"
  }
}
```


<div id="4-search-tool-firecrawl_search">
  ### 4. Outil de recherche (`firecrawl_search`)
</div>

Recherchez sur le Web et, si vous le souhaitez, extrayez le contenu des rÃ©sultats de recherche.

```json
{
  "name": "firecrawl_search",
  "arguments": {
    "query": "votre requÃªte de recherche",
    "limit": 5,
    "lang": "fr",
    "country": "fr",
    "scrapeOptions": {
      "formats": ["markdown"],
      "onlyMainContent": true
    }
  }
}
```


<div id="5-crawl-tool-firecrawl_crawl">
  ### 5. Outil dâ€™exploration (`firecrawl_crawl`)
</div>

DÃ©marrez une exploration asynchrone avec des options avancÃ©es.

```json
{
  "name": "firecrawl_crawl",
  "arguments": {
    "url": "https://exemple.com",
    "maxDepth": 2,
    "limit": 100,
    "allowExternalLinks": false,
    "deduplicateSimilarURLs": true
  }
}
```


<div id="6-extract-tool-firecrawl_extract">
  ### 6. Outil dâ€™extraction (`firecrawl_extract`)
</div>

Extrayez des informations structurÃ©es Ã  partir de pages web Ã  lâ€™aide de LLM. Prend en charge lâ€™extraction via IA cloud et via des LLM autoâ€‘hÃ©bergÃ©s.

```json
{
  "name": "firecrawl_extract",
  "arguments": {
    "urls": ["https://example.com/page1", "https://example.com/page2"],
    "prompt": "Extraire les informations produit, y compris le nom, le prix et la description",
    "systemPrompt": "Vous Ãªtes un assistant utile chargÃ© dâ€™extraire des informations produit"
    "schema": {
      "type": "object",
      "properties": {
        "name": { "type": "string" },
        "price": { "type": "number" },
        "description": { "type": "string" }
      },
      "required": ["name", "price"]
    },
    "allowExternalLinks": false,
    "enableWebSearch": false,
    "includeSubdomains": false
  }
}
```

Exemple de rÃ©ponseÂ :

```json
{
  "content": [
    {
      "type": "text",
      "text": {
        "name": "Example Product",
        "price": 99.99,
        "description": "Ceci est un exemple de description de produit"
      }
    }
  ],
  "isError": false
}
```


<div id="extract-tool-options">
  #### Options de lâ€™outil dâ€™extractionÂ :
</div>

- `urls`Â : Tableau dâ€™URL Ã  partir desquelles extraire des informations
- `prompt`Â : Invite personnalisÃ©e pour lâ€™extraction par le LLM
- `systemPrompt`Â : Invite systÃ¨me pour guider le LLM
- `schema`Â : SchÃ©ma JSON pour lâ€™extraction de donnÃ©es structurÃ©es
- `allowExternalLinks`Â : Autoriser lâ€™extraction Ã  partir de liens externes
- `enableWebSearch`Â : Activer la recherche web pour un contexte supplÃ©mentaire
- `includeSubdomains`Â : Inclure les sous-domaines dans lâ€™extraction

Avec une instance auto-hÃ©bergÃ©e, lâ€™extraction utilise votre LLM configurÃ©. Avec lâ€™API cloud, elle utilise le service LLM managÃ© de Firecrawl.

### 7. Outil de recherche approfondie (firecrawl&#95;deep&#95;research)

Effectuez des recherches web approfondies sur une requÃªte Ã  lâ€™aide dâ€™un crawl intelligent, de la recherche et de lâ€™analyse par LLM.

```json
{
  "name": "firecrawl_deep_research",
  "arguments": {
    "query": "Comment fonctionne la technologie de captage du carboneÂ ?",
    "maxDepth": 3,
    "timeLimit": 120,
    "maxUrls": 50
  }
}
```

ArgumentsÂ :

* query (string, requis)Â : Question de recherche ou sujet Ã  explorer.
* maxDepth (number, optionnel)Â : Profondeur de rÃ©cursion maximale pour le crawling/la recherche (par dÃ©fautÂ : 3).
* timeLimit (number, optionnel)Â : Limite de temps en secondes pour la session de recherche (par dÃ©fautÂ : 120).
* maxUrls (number, optionnel)Â : Nombre maximal dâ€™URL Ã  analyser (par dÃ©fautÂ : 50).

RenvoieÂ :

* Analyse finale gÃ©nÃ©rÃ©e par un LLM Ã  partir de la recherche. (data.finalAnalysis)
* Peut Ã©galement inclure des actions structurÃ©es et les sources utilisÃ©es durant le processus de recherche.


### 8. GÃ©nÃ©rer lâ€™outil LLMs.txt (firecrawl&#95;generate&#95;llmstxt)

GÃ©nÃ¨re un fichier llms.txt standardisÃ© (et Ã©ventuellement llms-full.txt) pour un domaine donnÃ©. Ce fichier dÃ©finit comment les grands modÃ¨les de langage doivent interagir avec le site.

```json
{
  "name": "firecrawl_generate_llmstxt",
  "arguments": {
    "url": "https://exemple.com",
    "maxUrls": 20,
    "showFullText": true
  }
}
```

ArgumentsÂ :

* url (string, obligatoire)Â : URL de base du site web Ã  analyser.
* maxUrls (number, facultatif)Â : Nombre maximal dâ€™URL Ã  inclure (par dÃ©fautÂ : 10).
* showFullText (boolean, facultatif)Â : Indique sâ€™il faut inclure le contenu de llms-full.txt dans la rÃ©ponse.

RenvoieÂ :

* Contenu gÃ©nÃ©rÃ© du fichier llms.txt et, le cas Ã©chÃ©ant, de llms-full.txt (data.llmstxt et/ou data.llmsfulltxt)


<div id="logging-system">
  ## SystÃ¨me de journalisation
</div>

Le serveur inclut une journalisation complÃ¨teÂ :

* Ã‰tat et progression des opÃ©rations
* Indicateurs de performance
* Suivi de lâ€™utilisation des crÃ©dits
* Suivi des limites de dÃ©bit
* Conditions dâ€™erreur

Exemples de messages de journalÂ :

```
[INFO] Serveur MCP Firecrawl initialisÃ© avec succÃ¨s
[INFO] Lancement du scraping pour lâ€™URLÂ : https://example.com
[INFO] OpÃ©ration par lots mise en file dâ€™attente avec lâ€™IDÂ : batch_1
[WARNING] Lâ€™utilisation des crÃ©dits a atteint le seuil dâ€™alerte
[ERROR] Limite de dÃ©bit dÃ©passÃ©e, nouvelle tentative dans 2Â sâ€¦
```


<div id="error-handling">
  ## Gestion des erreurs
</div>

Le serveur offre une gestion des erreurs robuste :

* RÃ©essais automatiques pour les erreurs transitoires
* Gestion des limites de dÃ©bit avec backoff
* Messages dâ€™erreur dÃ©taillÃ©s
* Avertissements sur lâ€™utilisation des crÃ©dits
* RÃ©silience rÃ©seau

Exemple de rÃ©ponse dâ€™erreur :

```json
{
  "content": [
    {
      "type": "text",
      "text": "ErreurÂ : limite de dÃ©bit dÃ©passÃ©e. Nouvelle tentative dans 2Â secondesâ€¦"
    }
  ],
  "isError": true
}
```


<div id="development">
  ## DÃ©veloppement
</div>

```bash
# Installer les dÃ©pendances
npm install

# GÃ©nÃ©rer le build
npm run build

# Lancer les tests
npm test
```


<div id="contributing">
  ### Contribuer
</div>

1. Forkez le dÃ©pÃ´t
2. CrÃ©ez une branche pour votre fonctionnalitÃ©
3. ExÃ©cutez les tests : `npm test`
4. Ouvrez une pull request

<div id="thanks-to-contributors">
  ### Merci aux contributeurs
</div>

Merci Ã  [@vrknetha](https://github.com/vrknetha) et [@cawstudios](https://caw.tech) pour la mise en Å“uvre initialeâ€¯!

Merci Ã  MCP.so et Klavis AI pour lâ€™hÃ©bergement, ainsi quâ€™Ã  [@gstarwd](https://github.com/gstarwd), [@xiangkaiz](https://github.com/xiangkaiz) et [@zihaolin96](https://github.com/zihaolin96) dâ€™avoir intÃ©grÃ© notre serveur.

<div id="license">
  ## Licence
</div>

Licence MIT â€” voir le fichier LICENSE pour plus de dÃ©tails