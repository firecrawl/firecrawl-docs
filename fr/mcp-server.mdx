---
title: Serveur MCP Firecrawl
description: "Utilisez l‚ÄôAPI Firecrawl via le Model Context Protocol"
og:title: 'Serveur MCP Firecrawl'
og:description: "Les serveurs MCP Firecrawl vous permettent d‚Äôutiliser l‚ÄôAPI Firecrawl via le Model Context Protocol"
sidebarTitle: 'Serveur MCP'
---

Une impl√©mentation de serveur Model Context Protocol (MCP) int√©grant [Firecrawl](https://github.com/mendableai/firecrawl) pour le web scraping. Notre serveur MCP est open source et disponible sur [GitHub](https://github.com/mendableai/firecrawl-mcp-server).

## Fonctionnalit√©s

- Scraping, crawling et d√©couverte du web
- Recherche et extraction de contenu
- Recherche approfondie et scraping en lots
- Prise en charge du cloud et de l‚Äôauto‚Äëh√©bergement
- Prise en charge du streaming HTTP

## Installation

Vous pouvez utiliser notre URL h√©berg√©e ou ex√©cuter le serveur en local. R√©cup√©rez votre cl√© API sur [https://firecrawl.dev/app/api-keys](https://www.firecrawl.dev/app/api-keys)

### URL h√©berg√©e √† distance

```bash
https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/mcp
```


### Ex√©cuter avec npx

```bash
env FIRECRAWL_API_KEY=fc-VOTRE_CL√â_API npx -y firecrawl-mcp
```


### Installation manuelle

```bash
npm install -g firecrawl-mcp
```


### Ex√©cution dans Cursor

<a href='cursor://anysphere.cursor-deeplink/mcp/install?name=firecrawl&config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyIteSIsImZpcmVjcmF3bC1tY3AiXSwiZW52Ijp7IkZJUkVDUkFXTF9BUElfS0VZIjoiWU9VUi1BUEktS0VZIn19'>
  <img
    src='https://cursor.com/deeplink/mcp-install-dark.png'
    alt='Ajouter le serveur MCP Firecrawl √† Cursor'
    style={{ maxHeight: 32 }}
  />
</a>

#### Installation manuelle

Configuration de Cursor üñ•Ô∏è
Remarque : n√©cessite Cursor version 0.45.6+
Pour des instructions de configuration √† jour, consultez la documentation officielle de Cursor sur la configuration des serveurs MCP :
[Guide de configuration du serveur MCP de Cursor](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)

Pour configurer Firecrawl MCP dans Cursor **v0.48.6**

1. Ouvrez les param√®tres de Cursor
2. Allez dans Features > MCP Servers
3. Cliquez sur "+ Add new global MCP server"
4. Saisissez le code suivant :
   ```json
   {
     "mcpServers": {
       "firecrawl-mcp": {
         "command": "npx",
         "args": ["-y", "firecrawl-mcp"],
         "env": {
           "FIRECRAWL_API_KEY": "YOUR-API-KEY"
         }
       }
     }
   }
   ```

Pour configurer Firecrawl MCP dans Cursor **v0.45.6**

1. Ouvrez les param√®tres de Cursor
2. Allez dans Features > MCP Servers
3. Cliquez sur "+ Add New MCP Server"
4. Renseignez les √©l√©ments suivants :
   - Name: "firecrawl-mcp" (ou le nom de votre choix)
   - Type: "command"
   - Command: `env FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp`

> Si vous utilisez Windows et rencontrez des probl√®mes, essayez `cmd /c "set FIRECRAWL_API_KEY=your-api-key && npx -y firecrawl-mcp"`

Remplacez `your-api-key` par votre cl√© API Firecrawl. Si vous n'en avez pas encore, cr√©ez un compte et r√©cup√©rez-la via https://www.firecrawl.dev/app/api-keys

Apr√®s l‚Äôajout, actualisez la liste des serveurs MCP pour voir les nouveaux outils. Le Composer Agent utilisera automatiquement Firecrawl MCP lorsque c‚Äôest pertinent, mais vous pouvez aussi le demander explicitement en d√©crivant vos besoins en web scraping. Acc√©dez au Composer via Command+L (Mac), s√©lectionnez ¬´ Agent ¬ª √† c√¥t√© du bouton d‚Äôenvoi, puis saisissez votre requ√™te.

### Ex√©cuter sur Windsurf

Ajoutez ceci √† votre `./codeium/windsurf/model_config.json` :

```json
{
  "mcpServers": {
    "mcp-server-firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "VOTRE_API_KEY"
      }
    }
  }
}
```


### Ex√©cution en mode HTTP diffus√©

Pour ex√©cuter le serveur en local avec le transport HTTP diffus√© plut√¥t que le transport stdio par d√©faut¬†:

```bash
env HTTP_STREAMABLE_SERVER=true FIRECRAWL_API_KEY=fc-VOTRE_CLE_API npx -y firecrawl-mcp
```

Utilisez l‚ÄôURL¬†: http://localhost:3000/v2/mcp ou https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/mcp


### Installation via Smithery (ancien)

Pour installer automatiquement Firecrawl pour Claude Desktop via [Smithery](https://smithery.ai/server/@mendableai/mcp-server-firecrawl)¬†:

```bash
npx -y @smithery/cli install @mendableai/mcp-server-firecrawl --client claude
```


### Ex√©cution dans VS Code

Pour une installation en un clic, cliquez sur l‚Äôun des boutons ci-dessous‚Ä¶

[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square\&logo=visualstudiocode\&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square\&logo=visualstudiocode\&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D\&quality=insiders)

Pour une installation manuelle, ajoutez le bloc JSON suivant √† votre fichier User Settings (JSON) dans VS Code. Pour cela, appuyez sur `Ctrl + Shift + P` et tapez `Preferences: Open User Settings (JSON)`.

```json
{
  "mcp": {
    "inputs": [
      {
        "type": "promptString",
        "id": "apiKey",
        "description": "Cl√© API Firecrawl",
        "password": true
      }
    ],
    "servers": {
      "firecrawl": {
        "command": "npx",
        "args": ["-y", "firecrawl-mcp"],
        "env": {
          "FIRECRAWL_API_KEY": "${input:apiKey}"
        }
      }
    }
  }
}
```

Vous pouvez aussi l‚Äôajouter √† un fichier nomm√© `.vscode/mcp.json` dans votre espace de travail. Cela vous permettra de partager la configuration avec d‚Äôautres¬†:

```json
{
  "inputs": [
    {
      "type": "promptString",
      "id": "apiKey",
      "description": "Cl√© API Firecrawl",
      "password": true
    }
  ],
  "servers": {
    "firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "${input:apiKey}"
      }
    }
  }
}
```

**Remarque :** Certains utilisateurs ont signal√© des probl√®mes lors de l‚Äôajout du serveur MCP √† VS Code, dus √† la validation du JSON avec un format de sch√©ma obsol√®te ([microsoft/vscode#155379](https://github.com/microsoft/vscode/issues/155379)).
Cela affecte plusieurs outils MCP, dont Firecrawl.

**Solution de contournement :** D√©sactivez la validation JSON dans VS Code pour permettre le bon chargement du serveur MCP.\
Voir r√©f√©rence : [directus/directus#25906 (commentaire)](https://github.com/directus/directus/issues/25906#issuecomment-3369169513).

Le serveur MCP fonctionne toujours correctement lorsqu‚Äôil est appel√© via d‚Äôautres extensions, mais le probl√®me survient sp√©cifiquement lors de son enregistrement direct dans la liste des serveurs MCP. Nous publierons des consignes d√®s que VS Code aura mis √† jour sa validation de sch√©ma.


### Ex√©cution sur Claude Desktop

Ajoutez ceci au fichier de configuration de Claude¬†:

```json
{
  "mcpServers": {
    "firecrawl": {
      "url": "https://mcp.firecrawl.dev/v2/mcp",
      "headers": {
        "Authorization": "Bearer VOTRE_CLE_API"
      }
    }
  }
}
```


### Ex√©cution avec Claude Code

Ajoutez le serveur MCP de Firecrawl √† l‚Äôaide de la CLI de Claude Code :

```bash
claude mcp add firecrawl -e FIRECRAWL_API_KEY=your-api-key -- npx -y firecrawl-mcp
```


### Ex√©cution sur n8n

Pour connecter le serveur MCP de Firecrawl dans n8n¬†:

1. R√©cup√©rez votre cl√© API Firecrawl depuis [https://firecrawl.dev/app/api-keys](https://www.firecrawl.dev/app/api-keys)
2. Dans votre workflow n8n, ajoutez un n≈ìud **AI Agent**
3. Dans la configuration d‚ÄôAI Agent, ajoutez un nouveau **Tool**
4. S√©lectionnez **MCP Client Tool** comme type d‚Äôoutil
5. Saisissez l‚Äôendpoint du serveur MCP (remplacez `{YOUR_FIRECRAWL_API_KEY}` par votre cl√© API)¬†:

```
  https://mcp.firecrawl.dev/{VOTRE_CLE_API_FIRECRAWL}/v2/mcp
```

6. D√©finissez **Server Transport** sur **HTTP Streamable**
7. D√©finissez **Authentication** sur **None**
8. Pour **Tools to include**, vous pouvez s√©lectionner **All**, **Selected** ou **All Except** ‚Äî cela exposera les outils Firecrawl (scrape, crawl, map, search, extract, etc.)

Pour les d√©ploiements auto-h√©berg√©s, ex√©cutez le serveur MCP avec npx et activez le mode de transport HTTP¬†:

```bash
env HTTP_STREAMABLE_SERVER=true \
    FIRECRAWL_API_KEY=fc-VOTRE_CLE_API \
    FIRECRAWL_API_URL=VOTRE_INSTANCE_FIRECRAWL \
    npx -y firecrawl-mcp
```

Cela d√©marrera le serveur sur `http://localhost:3000/v2/mcp`, que vous pourrez utiliser comme point de terminaison dans votre workflow n8n. La variable d‚Äôenvironnement `HTTP_STREAMABLE_SERVER=true` est n√©cessaire, car n8n requiert le transport HTTP.


## Configuration

### Variables d‚Äôenvironnement

#### Requis pour l‚ÄôAPI Cloud

- `FIRECRAWL_API_KEY` : votre cl√© API Firecrawl
  - Requise lors de l‚Äôutilisation de l‚ÄôAPI cloud (par d√©faut)
  - Facultative lors de l‚Äôutilisation d‚Äôune instance auto-h√©berg√©e avec `FIRECRAWL_API_URL`
- `FIRECRAWL_API_URL` (facultatif) : point de terminaison API personnalis√© pour les instances auto-h√©berg√©es
  - Exemple : `https://firecrawl.your-domain.com`
  - Si elle n‚Äôest pas renseign√©e, l‚ÄôAPI cloud sera utilis√©e (n√©cessite une cl√© API)

#### Configuration facultative

##### Configuration des relances

- `FIRECRAWL_RETRY_MAX_ATTEMPTS`: Nombre maximal de tentatives de relance (par d√©faut : 3)
- `FIRECRAWL_RETRY_INITIAL_DELAY`: D√©lai initial en millisecondes avant la premi√®re relance (par d√©faut : 1000)
- `FIRECRAWL_RETRY_MAX_DELAY`: D√©lai maximal en millisecondes entre les relances (par d√©faut : 10000)
- `FIRECRAWL_RETRY_BACKOFF_FACTOR`: Facteur de backoff exponentiel (par d√©faut : 2)

##### Surveillance de l‚Äôutilisation des cr√©dits

- `FIRECRAWL_CREDIT_WARNING_THRESHOLD`: Seuil d‚Äôavertissement pour l‚Äôutilisation des cr√©dits (par d√©faut¬†: 1000)
- `FIRECRAWL_CREDIT_CRITICAL_THRESHOLD`: Seuil critique pour l‚Äôutilisation des cr√©dits (par d√©faut¬†: 100)

### Exemples de configuration

Pour l‚Äôutilisation de l‚ÄôAPI cloud avec des tentatives de reprise personnalis√©es et le suivi des cr√©dits¬†:

```bash
# Requis pour l‚ÄôAPI cloud
export FIRECRAWL_API_KEY=your-api-key

# Param√®tres de nouvelle tentative (facultatif)
export FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Augmenter le nombre maximal de tentatives
export FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Commencer avec un d√©lai de 2 s
export FIRECRAWL_RETRY_MAX_DELAY=30000       # D√©lai maximal de 30 s
export FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # Backoff plus agressif

# Surveillance des cr√©dits (facultatif)
export FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Avertissement √† 2000 cr√©dits
export FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Seuil critique √† 500 cr√©dits
```

Pour une instance auto‚Äëh√©berg√©e¬†:

```bash
# Requis pour l‚Äôauto‚Äëh√©bergement
export FIRECRAWL_API_URL=https://firecrawl.your-domain.com

# Authentification facultative pour l‚Äôauto‚Äëh√©bergement
export FIRECRAWL_API_KEY=your-api-key  # Si votre instance requiert une authentification

# Configuration personnalis√©e des tentatives
export FIRECRAWL_RETRY_MAX_ATTEMPTS=10
export FIRECRAWL_RETRY_INITIAL_DELAY=500     # D√©marrer avec des tentatives plus rapides
```


### Configuration personnalis√©e avec Claude Desktop

Ajoutez ceci √† votre fichier `claude_desktop_config.json` :

```json
{
  "mcpServers": {
    "mcp-server-firecrawl": {
      "command": "npx",
      "args": ["-y", "firecrawl-mcp"],
      "env": {
        "FIRECRAWL_API_KEY": "VOTRE_CLEF_API_ICI",

        "FIRECRAWL_RETRY_MAX_ATTEMPTS": "5",
        "FIRECRAWL_RETRY_INITIAL_DELAY": "2000",
        "FIRECRAWL_RETRY_MAX_DELAY": "30000",
        "FIRECRAWL_RETRY_BACKOFF_FACTOR": "3",

        "FIRECRAWL_CREDIT_WARNING_THRESHOLD": "2000",
        "FIRECRAWL_CREDIT_CRITICAL_THRESHOLD": "500"
      }
    }
  }
}
```


### Configuration du syst√®me

Le serveur propose plusieurs param√®tres configurables pouvant √™tre d√©finis via des variables d‚Äôenvironnement. Voici les valeurs par d√©faut si rien n‚Äôest sp√©cifi√©¬†:

```typescript
const CONFIG = {
  retry: {
    maxAttempts: 3, // Nombre de tentatives de r√©essai pour les requ√™tes limit√©es par le d√©bit
    initialDelay: 1000, // D√©lai initial avant le premier r√©essai (en millisecondes)
    maxDelay: 10000, // D√©lai maximal entre les r√©essais (en millisecondes)
    backoffFactor: 2, // Multiplicateur pour l‚Äôexponentiel de backoff
  },
  credit: {
    warningThreshold: 1000, // Avertir lorsque l‚Äôutilisation des cr√©dits atteint ce seuil
    criticalThreshold: 100, // Alerte critique lorsque l‚Äôutilisation des cr√©dits atteint ce seuil
  },
};
```

Ces param√®tres contr√¥lent :

1. **Comportement de relance**

   * Relance automatiquement les requ√™tes √©chou√©es en raison des limites de d√©bit
   * Utilise un retour arri√®re exponentiel (exponential backoff) pour √©viter de surcharger l‚ÄôAPI
   * Exemple : avec les param√®tres par d√©faut, les relances seront tent√©es aux moments suivants :
     * 1re relance : d√©lai de 1 seconde
     * 2e relance : d√©lai de 2 secondes
     * 3e relance : d√©lai de 4 secondes (plafonn√© par maxDelay)

2. **Suivi de l‚Äôutilisation des cr√©dits**
   * Suit la consommation de cr√©dits pour l‚Äôutilisation de l‚ÄôAPI cloud
   * √âmet des avertissements √† des seuils d√©finis
   * Aide √† pr√©venir les interruptions de service impr√©vues
   * Exemple : avec les param√®tres par d√©faut :
     * Avertissement √† 1‚ÄØ000 cr√©dits restants
     * Alerte critique √† 100 cr√©dits restants


### Limitation de d√©bit et traitement par lots

Le serveur utilise les fonctionnalit√©s int√©gr√©es de Firecrawl pour la limitation de d√©bit et le traitement par lots¬†:

- Gestion automatique des limites de d√©bit avec backoff exponentiel
- Traitement parall√®le efficace pour les op√©rations par lots
- Mise en file d‚Äôattente et limitation intelligente des requ√™tes
- R√©essais automatiques en cas d‚Äôerreurs transitoires

## Outils disponibles

### 1. Outil d‚Äôextraction (`firecrawl_scrape`)

Extraire le contenu d‚Äôune URL unique avec des options avanc√©es.

```json
{
  "name": "firecrawl_scrape",
  "arguments": {
    "url": "https://example.com",
    "formats": ["markdown"],
    "onlyMainContent": true,
    "waitFor": 1000,
    "timeout": 30000,
    "mobile": false,
    "includeTags": ["article", "main"],
    "excludeTags": ["nav", "footer"],
    "skipTlsVerification": false
  }
}
```


### 2. Outil d‚Äôextraction par lots (`firecrawl_batch_scrape`)

Exploitez plusieurs URL efficacement gr√¢ce √† une limitation de d√©bit int√©gr√©e et un traitement parall√®le.

```json
{
  "name": "firecrawl_batch_scrape",
  "arguments": {
    "urls": ["https://example1.com", "https://example2.com"],
    "options": {
      "formats": ["markdown"],
      "onlyMainContent": true
    }
  }
}
```

La r√©ponse inclut l‚ÄôID d‚Äôop√©ration pour v√©rifier l‚Äô√©tat¬†:

```json
{
  "content": [
    {
      "type": "text",
      "text": "Op√©ration par lots mise en file d‚Äôattente avec l‚ÄôID¬†: batch_1. Utilisez firecrawl_check_batch_status pour suivre la progression."
    }
  ],
  "isError": false
}
```


### 3. V√©rifier l‚Äô√©tat du lot (`firecrawl_check_batch_status`)

V√©rifiez l‚Äô√©tat d‚Äôune op√©ration par lots.

```json
{
  "name": "firecrawl_check_batch_status",
  "arguments": {
    "id": "batch_1"
  }
}
```


### 4. Outil de cartographie (`firecrawl_map`)

Cartographiez un site web pour d√©couvrir toutes les URL index√©es du site.

```json
{
  "name": "firecrawl_map",
  "arguments": {
    "url": "https://example.com",
    "search": "blog",
    "sitemap": "include",
    "includeSubdomains": false,
    "limit": 100,
    "ignoreQueryParameters": true
  }
}
```


#### Options de l‚Äôoutil Map¬†:

- `url`¬†: URL de base du site √† cartographier
- `search`¬†: Terme de recherche facultatif pour filtrer les URL
- `sitemap`¬†: Contr√¥le l‚Äôutilisation du sitemap ‚Äî ¬´¬†include¬†¬ª, ¬´¬†skip¬†¬ª ou ¬´¬†only¬†¬ª
- `includeSubdomains`¬†: Indique s‚Äôil faut inclure les sous-domaines dans la cartographie
- `limit`¬†: Nombre maximal d‚ÄôURL √† retourner
- `ignoreQueryParameters`¬†: Indique s‚Äôil faut ignorer les param√®tres de requ√™te lors de la cartographie

**Id√©al pour¬†:** D√©couvrir des URL sur un site avant de d√©cider quoi extraire¬†; trouver des sections sp√©cifiques d‚Äôun site.
**Renvoie¬†:** Tableau d‚ÄôURL trouv√©es sur le site.

### 5. Outil de recherche (`firecrawl_search`)

Effectuez une recherche sur le web et, si besoin, extrayez le contenu des r√©sultats.

```json
{
  "name": "firecrawl_search",
  "arguments": {
    "query": "votre requ√™te de recherche",
    "limit": 5,
    "lang": "en",
    "country": "us",
    "scrapeOptions": {
      "formats": ["markdown"],
      "onlyMainContent": true
    }
  }
}
```


### 6. Outil d‚Äôexploration (`firecrawl_crawl`)

Lancez une exploration asynchrone avec des options avanc√©es.

```json
{
  "name": "firecrawl_crawl",
  "arguments": {
    "url": "https://example.com",
    "maxDepth": 2,
    "limit": 100,
    "allowExternalLinks": false,
    "deduplicateSimilarURLs": true
  }
}
```


### 7. V√©rifier l‚Äô√©tat du crawl (`firecrawl_check_crawl_status`)

V√©rifiez l‚Äô√©tat d‚Äôun job de crawl.

```json
{
  "name": "firecrawl_check_crawl_status",
  "arguments": {
    "id": "550e8400-e29b-41d4-a716-446655440000"
  }
}
```

**Renvoie¬†:** √âtat et avancement de la t√¢che de crawl, y compris les r√©sultats s‚Äôils sont disponibles.


### 8. Outil d‚Äôextraction (`firecrawl_extract`)

Extrayez des informations structur√©es √† partir de pages web gr√¢ce aux capacit√©s des LLM. Prend en charge l‚Äôextraction via des IA cloud ou des LLM auto‚Äëh√©berg√©s.

```json
{
  "name": "firecrawl_extract",
  "arguments": {
    "urls": ["https://example.com/page1", "https://example.com/page2"],
    "prompt": "Extraire les informations produit incluant le nom, le prix et la description",
    "systemPrompt": "Vous √™tes un assistant utile qui extrait les informations produit",
    "schema": {
      "type": "object",
      "properties": {
        "name": { "type": "string" },
        "price": { "type": "number" },
        "description": { "type": "string" }
      },
      "required": ["name", "price"]
    },
    "allowExternalLinks": false,
    "enableWebSearch": false,
    "includeSubdomains": false
  }
}
```

Exemple de r√©ponse¬†:

```json
{
  "content": [
    {
      "type": "text",
      "text": {
        "name": "Produit d'exemple",
        "price": 99.99,
        "description": "Ceci est un exemple de description de produit"
      }
    }
  ],
  "isError": false
}
```


#### Options de l‚Äôoutil d‚Äôextraction¬†:

- `urls`¬†: Tableau d‚ÄôURL √† partir desquelles extraire des informations
- `prompt`¬†: Invite personnalis√©e pour l‚Äôextraction par le LLM
- `systemPrompt`¬†: Invite syst√®me pour guider le LLM
- `schema`¬†: Sch√©ma JSON pour l‚Äôextraction de donn√©es structur√©es
- `allowExternalLinks`¬†: Autoriser l‚Äôextraction √† partir de liens externes
- `enableWebSearch`¬†: Activer la recherche web pour un contexte suppl√©mentaire
- `includeSubdomains`¬†: Inclure les sous-domaines dans l‚Äôextraction

Avec une instance auto-h√©berg√©e, l‚Äôextraction utilise votre LLM configur√©. Avec l‚ÄôAPI cloud, elle utilise le service LLM manag√© de Firecrawl.

## Syst√®me de journalisation

Le serveur inclut une journalisation compl√®te¬†:

* √âtat et progression des op√©rations
* Indicateurs de performance
* Suivi de l‚Äôutilisation des cr√©dits
* Suivi des limites de d√©bit
* Conditions d‚Äôerreur

Exemples de messages de journal¬†:

```
[INFO] Serveur MCP Firecrawl initialis√© avec succ√®s
[INFO] Lancement du scraping pour l‚ÄôURL¬†: https://example.com
[INFO] Op√©ration par lots mise en file d‚Äôattente avec l‚ÄôID¬†: batch_1
[WARNING] L‚Äôutilisation des cr√©dits a atteint le seuil d‚Äôalerte
[ERROR] Limite de d√©bit d√©pass√©e, nouvelle tentative dans 2¬†s‚Ä¶
```


## Gestion des erreurs

Le serveur offre une gestion des erreurs robuste :

* R√©essais automatiques pour les erreurs transitoires
* Gestion des limites de d√©bit avec backoff
* Messages d‚Äôerreur d√©taill√©s
* Avertissements sur l‚Äôutilisation des cr√©dits
* R√©silience r√©seau

Exemple de r√©ponse d‚Äôerreur :

```json
{
  "content": [
    {
      "type": "text",
      "text": "Erreur¬†: limite de d√©bit d√©pass√©e. Nouvelle tentative dans 2¬†secondes‚Ä¶"
    }
  ],
  "isError": true
}
```


## D√©veloppement

```bash
# Installer les d√©pendances
npm install

# G√©n√©rer le build
npm run build

# Lancer les tests
npm test
```


### Contribuer

1. Forkez le d√©p√¥t
2. Cr√©ez une branche pour votre fonctionnalit√©
3. Ex√©cutez les tests : `npm test`
4. Ouvrez une pull request

### Merci aux contributeurs

Merci √† [@vrknetha](https://github.com/vrknetha) et [@cawstudios](https://caw.tech) pour la mise en ≈ìuvre initiale‚ÄØ!

Merci √† MCP.so et Klavis AI pour l‚Äôh√©bergement, ainsi qu‚Äô√† [@gstarwd](https://github.com/gstarwd), [@xiangkaiz](https://github.com/xiangkaiz) et [@zihaolin96](https://github.com/zihaolin96) d‚Äôavoir int√©gr√© notre serveur.

## Licence

Licence MIT ‚Äî voir le fichier LICENSE pour plus de d√©tails