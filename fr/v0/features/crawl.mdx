---
title: "Crawl"
description: "Firecrawl peut explorer de façon récursive les sous-domaines d’une URL et en extraire le contenu"
icon: "spider"
og:title: "Crawl | Firecrawl"
og:description: "Firecrawl peut explorer de façon récursive les sous-domaines d’une URL et en extraire le contenu"
---

Firecrawl explore en profondeur les sites web, assurant une extraction de données complète tout en gérant des infrastructures web complexes. Voici comment cela fonctionne :

1. **Analyse de l’URL :**
   Démarre avec une URL donnée, identifie les liens en examinant le sitemap puis en explorant le site. Si aucun sitemap n’est trouvé, il parcourt le site en suivant les liens.

2. **Parcours récursif :**
   Suit chaque lien de manière récursive pour découvrir toutes les sous-pages.

3. **Scraping du contenu :**
   Récupère le contenu de chaque page visitée tout en gérant les complexités telles que le rendu JavaScript ou les limites de débit.

4. **Compilation des résultats :**
   Convertit les données collectées en markdown propre ou en sortie structurée, idéale pour le traitement par des LLM ou toute autre tâche.

Cette méthode garantit un crawl exhaustif et une collecte de données complète à partir de n’importe quelle URL de départ.

<div id="crawling">
  ## Exploration du site
</div>

<div id="crawl-endpoint">
  ### point de terminaison /crawl
</div>

Permet d’explorer une URL et toutes les sous-pages accessibles. Envoie un job de crawl et renvoie un ID de job pour suivre l’état du crawl.

<div id="installation">
  ### Installation
</div>

<CodeGroup>

```bash Python
pip install firecrawl-py
```

```bash JavaScript
npm install @mendable/firecrawl-js
```

```go Go
go get github.com/mendableai/firecrawl-go
```

```toml Rust
# Ajoutez ce qui suit à votre Cargo.toml

[dependencies]
firecrawl = "^0.1"
tokio = { version = "^1", features = ["full"] }
serde = { version = "^1.0", features = ["derive"] }
serde_json = "^1.0"
uuid = { version = "^1.10", features = ["v4"] }

[build-dependencies]
tokio = { version = "1", features = ["full"] }
```

</CodeGroup>

<div id="usage">
  ### Utilisation
</div>

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR_API_KEY")

crawl_result = app.crawl_url('mendable.ai', {'crawlerOptions': {'excludes': ['blog/*']}})

# Récupérer le markdown
for result in crawl_result:
    print(result['markdown'])
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

// Initialiser FirecrawlApp avec votre clé API
const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

// Explorer un site web
const crawlResult = await app.crawlUrl('mendable.ai', { crawlerOptions: { excludes: ['blog/*'] } });

// Afficher le markdown
console.log(crawlResult.map(result => result.markdown));
```

```go Go
import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
    log.Fatalf("Échec de l'initialisation de FirecrawlApp : %v", err)
  }

  crawlResult, err := app.CrawlURL("mendable.ai", nil)
  if err != nil {
    log.Fatalf("Échec de l'exploration de l'URL : %v", err)
  }

  fmt.Println(crawlResult)
}
```

```rust Rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
  // Initialiser FirecrawlApp avec la clé API
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Échec de l'initialisation de FirecrawlApp");

  // Explorer l'URL
  let crawl_params = json!({
    "crawlerOptions": {
        "excludes": ["blog/*"]
    }
  });

  let crawl_result = app
      .crawl_url("https://example.com", Some(crawl_params), true, 2, None)
      .await;

  // Afficher le résultat de l'exploration
  match crawl_result {
      Ok(data) => println!("Résultat de l'exploration :\n{}", data),
      Err(e) => eprintln!("Échec de l'exploration : {}", e),
  }
}
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v0/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://mendable.ai"
    }'
```

</CodeGroup>

<div id="job-id-response">
  ### Réponse d’ID de tâche
</div>

Si vous n’utilisez pas le SDK ou si vous préférez utiliser un webhook ou une autre méthode de polling, vous pouvez définir `wait_until_done` sur `false`.
Cela renverra un jobId.

Avec cURL, /crawl renverra toujours un jobId que vous pourrez utiliser pour vérifier l’état du crawl.

```json
{ "jobId": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### Vérifier un job de crawl
</div>

Permet de vérifier l'état d'un job de crawl et de récupérer son résultat.

<CodeGroup>

```python Python
status = app.check_crawl_status(job_id)
```

```js JavaScript
const status = await app.checkCrawlStatus(jobId);
```

```go Go
status, err := app.CheckCrawlStatus(jobId)
if err != nil {
  log.Fatalf("Failed to check crawl status: %v", err)
}
```

```rust Rust
let status = match app.check_crawl_status(jobId).await {
    Ok(status) => status,
    Err(e) => panic!("Failed to check crawl status: {:?}", e),
};

println!("Crawl Status: {:?}", status);
```

```bash cURL
curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
```

</CodeGroup>

<div id="response">
  #### Réponse
</div>

```json
{
  "status": "terminée",
  "current": 22,
  "total": 22,
  "data": [
    {
      "content": "Contenu brut ",
      "markdown": "# Contenu Markdown",
      "provider": "web-scraper",
      "metadata": {
        "title": "Mendable | IA pour l’expérience client et les ventes",
        "description": "IA pour l’expérience client et les ventes"
        "language": null,
        "sourceURL": "https://www.mendable.ai/"
      }
    }
  ]
}
```
