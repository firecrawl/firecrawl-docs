---
title: 'Rust'
description: 'Le SDK Rust de Firecrawl est une bibliothèque qui vous permet de scraper et d’explorer facilement des sites web, et de produire des données dans un format prêt à l’emploi pour les modèles de langage (LLM).'
icon: 'rust'
og:title: "Rust SDK | Firecrawl"
og:description: "Le SDK Rust de Firecrawl est une bibliothèque qui vous permet de scraper et d’explorer facilement des sites web, et de produire des données dans un format prêt à l’emploi pour les modèles de langage (LLM)."
---

> Remarque : ceci utilise la [version v0 de l’API Firecrawl](/fr/v0/introduction), qui est en voie de dépréciation. Nous recommandons de passer à [v1](/fr/sdks/rust).

<div id="installation">
  ## Installation
</div>

Pour installer le SDK Firecrawl pour Rust, ajoutez ce qui suit à votre `Cargo.toml` :

```toml
[dependencies]
firecrawl = "^0.1"
tokio = { version = "^1", features = ["full"] }
serde = { version = "^1.0", features = ["derive"] }
serde_json = "^1.0"
uuid = { version = "^1.10", features = ["v4"] }

[build-dependencies]
tokio = { version = "1", features = ["full"] }
```

<div id="usage">
  ## Utilisation
</div>

1. Récupérez une clé d’API sur [firecrawl.dev](https://firecrawl.dev)
2. Définissez la clé d’API comme variable d’environnement nommée `FIRECRAWL_API_KEY` ou passez-la en paramètre à la structure `FirecrawlApp`.

Voici un exemple d’utilisation du SDK en Rust :

```rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
  let api_key = "VOTRE_CLE_API";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Échec de l'initialisation de FirecrawlApp");

  // Extraire une URL
  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("Données extraites : {}", data),
    Err(e) => eprintln!("Erreur lors de l'extraction : {}", e),
  }
  // Explorer un site web
  let crawl_params = json!({
    "pageOptions": {
      "onlyMainContent": true
    }
  });

  let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;
  
  match crawl_result {
    Ok(data) => println!("Résultat de l'exploration : {}", data),
    Err(e) => eprintln!("Erreur lors de l'exploration : {}", e),
  }
}
```

<div id="scraping-a-url">
  ### Extraction d’une URL
</div>

Pour extraire une URL unique avec gestion des erreurs, utilisez la méthode `scrape_url`. Elle prend l’URL en paramètre et renvoie les données extraites sous la forme d’un `serde_json::Value`.

```rust
let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;

match scrape_result {
  Ok(data) => println!("Données récupérées : {}", data),
  Err(e) => eprintln!("Échec de l’extraction de l’URL : {}", e),
}
```

<div id="crawling-a-website">
  ### Exploration d’un site web
</div>

Pour explorer un site web, utilisez la méthode `crawl_url`. Elle prend en arguments l’URL de départ et des paramètres optionnels. Le paramètre `params` vous permet de définir des options supplémentaires pour la tâche d’exploration, telles que le nombre maximal de pages à explorer, les domaines autorisés et le format de sortie.

```rust
let crawl_params = json!({
  "crawlerOptions": {
    "excludes": ["blog/"],
    "includes": [], // laisser vide pour inclure toutes les pages
    "limit": 1000
  },
  "pageOptions": {
    "onlyMainContent": true
  }
});
let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;

match crawl_result {
  Ok(data) => println!("Résultat du crawl : {}", data),
  Err(e) => eprintln!("Échec du crawl de l’URL : {}", e),
}
```

<div id="checking-crawl-status">
  ### Vérifier l’état d’un crawl
</div>

Pour connaître l’état d’un job de crawl, utilisez la méthode `check_crawl_status`. Elle prend l’ID du job en paramètre et renvoie l’état actuel du crawl.

```rust
let job_id = "votre_id_de_job_ici";
let status = app.check_crawl_status(job_id).await;

match status {
  Ok(data) => println!("État du crawl : {}", data),
  Err(e) => eprintln!("Impossible de vérifier l’état du crawl : {}", e),
}
```

<div id="canceling-a-crawl-job">
  ### Annulation d’un job de crawl
</div>

Pour annuler un job de crawl, utilisez la méthode `cancel_crawl_job`. Elle prend l’ID du job en paramètre et renvoie le statut d’annulation du job de crawl.

```rust
let job_id = "votre_job_id_ici";
let canceled = app.cancel_crawl_job(job_id).await;

match canceled {
  Ok(status) => println!("Statut de l’annulation : {}", status),
  Err(e) => eprintln!("Échec de l’annulation du job de crawl : {}", e),
}
```

<div id="extracting-structured-data-from-a-url">
  ### Extraire des données structurées à partir d&#39;une URL
</div>

Avec l’extraction via LLM, vous pouvez facilement extraire des données structurées depuis n’importe quelle URL. Voici comment l’utiliser :

```rust
let json_schema = json!({
  "type": "object",
  "properties": {
    "top": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
        "title": {"type": "string"},
        "points": {"type": "number"},
        "by": {"type": "string"},
        "commentsURL": {"type": "string"}
      },
      "required": ["title", "points", "by", "commentsURL"]
      },
      "minItems": 5,
      "maxItems": 5,
      "description": "Top 5 des actualités sur Hacker News"
    }
  },
  "required": ["top"]
});

let llm_extraction_params = json!({
  "extractorOptions": {
    "extractionSchema": json_schema
  }
});

let scrape_result = app.scrape_url("https://news.ycombinator.com", Some(llm_extraction_params)).await;

match scrape_result {
  Ok(data) => println!("Résultat de l’extraction LLM : {}", data),
  Err(e) => eprintln!("Échec de l’extraction LLM : {}", e),
}
```

<div id="search-for-a-query">
  ### Rechercher une requête
</div>

Pour lancer une recherche sur le Web, récupérer les résultats les plus pertinents, scraper chaque page et renvoyer le markdown, utilisez la méthode `search`. Cette méthode prend la requête en paramètre et renvoie les résultats de recherche.

```rust
let query = "Qu’est-ce que Firecrawl ?";
let search_result = app.search(query).await;

match search_result {
  Ok(data) => println!("Résultats de la recherche : {}", data),
  Err(e) => eprintln!("Échec de la recherche : {}", e),
}
```

<div id="error-handling">
  ## Gestion des erreurs
</div>

Le SDK gère les erreurs renvoyées par l’API Firecrawl et déclenche des exceptions appropriées. Si une erreur survient lors d’une requête, une exception est levée avec un message d’erreur explicite.