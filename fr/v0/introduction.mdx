---
title: Démarrage rapide
description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
og:title: "Démarrage rapide | Firecrawl"
og:description: "Firecrawl vous permet de convertir des sites web entiers en markdown prêt pour les LLM"
---

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.jpg" alt="Image d’en-tête claire" />

<div id="welcome-to-firecrawl">
  ## Bienvenue sur Firecrawl
</div>

[Firecrawl](https://firecrawl.dev?ref=github) est un service d’API qui prend une URL, la explore et la convertit en markdown propre. Nous parcourons toutes les sous-pages accessibles et vous fournissons un markdown propre pour chacune. Aucun sitemap nécessaire.

<div id="how-to-use-it">
  ## Comment l’utiliser ?
</div>

Nous proposons une API simple à utiliser avec notre version hébergée. Vous trouverez l’aire de test et la documentation [ici](https://firecrawl.dev/playground). Vous pouvez également auto‑héberger le backend si vous le souhaitez.

Consultez les ressources suivantes pour démarrer :

* [x] **API** : [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs** : [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
* [x] **Frameworks LLM** : [LangChain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [LangChain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low‑code** : [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **Autres** : [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] Vous souhaitez un SDK ou une intégration ? Faites‑le nous savoir en ouvrant un ticket.

**Auto‑hébergement :** Pour auto‑héberger, consultez le guide [ici](/fr/contributing/self-host).

<div id="api-key">
  ### Clé d’API
</div>

Pour utiliser l’API, vous devez vous inscrire sur [Firecrawl](https://firecrawl.dev) et obtenir une clé d’API.

<div id="crawling">
  ## Exploration
</div>

Permet d’explorer une URL et toutes les sous-pages accessibles. Cela lance un travail d’exploration et renvoie un identifiant de travail pour vérifier l’état de l’exploration.

<div id="installation">
  ### Installation
</div>

<CodeGroup>
  ```bash Python
  pip install firecrawl-py
  ```

  ```bash JavaScript
  npm install @mendable/firecrawl-js
  ```

  ```bash Go
  go get github.com/mendableai/firecrawl-go
  ```

  ```toml Rust
  # ajoutez ce qui suit à votre Cargo.toml

  [dependencies]
  firecrawl = "^0.1"
  tokio = { version = "^1", features = ["full"] }
  serde = { version = "^1.0", features = ["derive"] }
  serde_json = "^1.0"
  uuid = { version = "^1.10", features = ["v4"] }

  [build-dependencies]
  tokio = { version = "1", features = ["full"] }
  ```
</CodeGroup>

<div id="usage">
  ### Utilisation
</div>

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  crawl_result = app.crawl_url('docs.firecrawl.dev', {'crawlerOptions': {'excludes': ['blog/*']}})

  # Récupérer le markdown
  for result in crawl_result:
      print(result['markdown'])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";

  // Initialiser FirecrawlApp avec votre clé API
  const app = new FirecrawlApp({ apiKey: "YOUR_API_KEY" });

  // Explorer un site web
  const crawlResult = await app.crawlUrl("docs.firecrawl.dev", {
    crawlerOptions: { excludes: ["blog/*"] },
  });

  // Afficher le markdown
  console.log(crawlResult.map((result) => result.markdown));
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    // Initialiser FirecrawlApp avec votre clé API
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("Échec de l'initialisation de FirecrawlApp : %v", err)
    }

    // Explorer un site web
    params := map[string]any{
      "crawlerOptions": map[string]any{
        "excludes": []string{"blog/*"},
      },
    }
    crawlResult, err := app.CrawlURL("docs.firecrawl.dev", params)
    if err != nil {
      log.Fatalf("Erreur lors de l'exploration : %v", err)
    }

    // Récupérer le markdown
    for _, result := range crawlResult {
      fmt.Println(result.Markdown)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
    // Initialiser FirecrawlApp avec la clé API
    let api_key = "YOUR_API_KEY";
    let api_url = "https://api.firecrawl.dev";
    let app = FirecrawlApp::new(api_key, api_url).expect("Échec de l'initialisation de FirecrawlApp");

    // Explorer l'URL
    let crawl_params = json!({
      "crawlerOptions": {
          "excludes": ["blog/*"]
      }
    });

    let crawl_result = app
        .crawl_url("https://example.com", Some(crawl_params), true, 2, None)
        .await;

    // Afficher le résultat de l'exploration
    match crawl_result {
        Ok(data) => println!("Résultat de l'exploration:\n{}", data),
        Err(e) => eprintln!("Échec de l'exploration : {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/crawl \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

Si vous n’utilisez pas le SDK ou préférez utiliser un webhook ou une autre méthode de polling, vous pouvez définir `wait_until_done` sur `false`.
Cela renverra un jobId.

Avec cURL, /crawl renverra toujours un jobId que vous pourrez utiliser pour vérifier l’état de l’exploration.

```json
{ "jobId": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### Vérifier une tâche de crawl
</div>

Permet de vérifier l’état d’une tâche de crawl et d’en récupérer le résultat.

<CodeGroup>
  ```python Python
  status = app.check_crawl_status(job_id)
  ```

  ```js JavaScript
  const status = await app.checkCrawlStatus(jobId);
  ```

  ```go Go
  status, err := app.CheckCrawlStatus(jobId)
  if err != nil {
    log.Fatalf("Failed to check crawl status: %v", err)
  }
  ```

  ```rust Rust
  let status = match app.check_crawl_status(jobId).await {
      Ok(status) => status,
      Err(e) => panic!("Failed to check crawl status: {:?}", e),
  };

  println!("Crawl Status: {:?}", status);
  ```

  ```bash cURL
  curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY'
  ```
</CodeGroup>

<div id="response">
  #### Réponse
</div>

```json
{
  "status": "terminé",
  "current": 22,
  "total": 22,
  "data": [
    {
      "content": "Contenu brut ",
      "markdown": "# Contenu Markdown",
      "provider": "web-scraper",
      "metadata": {
        "title": "Firecrawl | Récupérez le web de façon fiable pour vos LLM",
        "description": "IA pour l’Expérience Client et les Ventes"
        "language": null,
        "sourceURL": "https://docs.firecrawl.dev/"
      }
    }
  ]
}
```

<div id="scraping">
  ## Scraping
</div>

Pour récupérer le contenu d’une seule URL, utilisez la méthode `scrape_url`. Elle prend l’URL en paramètre et renvoie les données extraites sous forme de dictionnaire.

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  content = app.scrape_url("https://docs.firecrawl.dev")
  ```

  ```JavaScript JavaScript
  import { FirecrawlApp } from 'firecrawl-js';

  const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

  const content = await app.scrapeUrl('https://docs.firecrawl.dev');
  ```

  ```go Go
  import (
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
    }

    content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
    if err != nil {
      log.Fatalf("Failed to scrape URL: %v", err)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Initialiser FirecrawlApp avec la clé API
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

      // Scraper l’URL
      let scrape_result = app.scrape_url("https://example.com", None).await;

      // Afficher le résultat du scraping
    match scrape_result {
      Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
      Err(e) => eprintln!("Scrape failed: {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

### Réponse

```json
{
  "success": true,
  "data": {
    "markdown": "<chaîne>",
    "content": "<chaîne>",
    "html": "<chaîne>",
    "rawHtml": "<chaîne>",
    "metadata": {
      "title": "<chaîne>",
      "description": "<chaîne>",
      "language": "<chaîne>",
      "sourceURL": "<chaîne>",
      "<autres métadonnées>": "<chaîne>",
      "pageStatusCode": 123,
      "pageError": "<chaîne>"
    },
    "llm_extraction": {},
    "warning": "<chaîne>"
  }
}
```

<div id="extraction">
  ## Extraction
</div>

Avec l’extraction par LLM, vous pouvez facilement extraire des données structurées depuis n’importe quelle URL. Nous prenons en charge les schémas Pydantic pour vous simplifier la vie. Voici comment l’utiliser :

<CodeGroup>
  ```python Python
  class ArticleSchema(BaseModel):
      title: str
      points: int 
      by: str
      commentsURL: str

  class TopArticlesSchema(BaseModel):
  top: List[ArticleSchema] = Field(..., max_items=5, description="Top 5 articles")

  data = app.scrape_url('https://news.ycombinator.com', {
  'extractorOptions': {
  'extractionSchema': TopArticlesSchema.model_json_schema(),
  'mode': 'llm-extraction'
  },
  'pageOptions':{
  'onlyMainContent': True
  }
  })
  print(data["llm_extraction"])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";
  import { z } from "zod";

  const app = new FirecrawlApp({
    apiKey: "fc-YOUR_API_KEY",
  });

  // Définir le schéma dans lequel extraire le contenu
  const schema = z.object({
    top: z
      .array(
        z.object({
          title: z.string(),
          points: z.number(),
          by: z.string(),
          commentsURL: z.string(),
        })
      )
      .length(5)
      .describe("Top 5 des actualités sur Hacker News"),
  });

  const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
    extractorOptions: { extractionSchema: schema },
  });

  console.log(scrapeResult.data["llm_extraction"]);
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  app, err := NewFirecrawlApp(TEST_API_KEY, API_URL)
  if err != nil {
    log.Fatalf("Échec de l’initialisation de FirecrawlApp : %v", err)
  }

  params := map[string]any{
    "extractorOptions": ExtractorOptions{
      Mode:             "llm-extraction",
      ExtractionPrompt: "D’après les informations de la page, identifiez la mission de l’entreprise, précisez si elle prend en charge le SSO et si elle est open source",
      ExtractionSchema: map[string]any{
        "type": "object",
        "properties": map[string]any{
          "company_mission": map[string]string{"type": "string"},
          "supports_sso":    map[string]string{"type": "boolean"},
          "is_open_source":  map[string]string{"type": "boolean"},
        },
        "required": []string{"company_mission", "supports_sso", "is_open_source"},
      },
    },
  }

  scrapeResult, err := app.ScrapeURL("https://news.ycombinator.com", params)
  if err != nil {
    log.Fatalf("Échec du scraping de l’URL : %v", err)
  }
  fmt.Println(scrapeResult.LLMExtraction)
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Initialiser FirecrawlApp avec la clé d’API
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("Échec de l’initialisation de FirecrawlApp")

      // Définir le schéma d’extraction du contenu
      let json_schema = json!({
          "type": "object",
          "properties": {
              "top": {
                  "type": "array",
                  "items": {
                      "type": "object",
                      "properties": {
                          "title": {"type": "string"},
                          "points": {"type": "number"},
                          "by": {"type": "string"},
                          "commentsURL": {"type": "string"}
                      },
                      "required": ["title", "points", "by", "commentsURL"]
                  },
                  "minItems": 5,
                  "maxItems": 5,
                  "description": "Top 5 des actualités sur Hacker News"
              }
          },
          "required": ["top"]
      });

      let llm_extraction_params = json!({
          "extractorOptions": {
              "extractionSchema": json_schema,
              "mode": "llm-extraction"
          },
          "pageOptions": {
              "onlyMainContent": true
          }
      });

      let llm_extraction_result = app
          .scrape_url("https://news.ycombinator.com", Some(llm_extraction_params))
          .await;
      match llm_extraction_result {
          Ok(data) => println!("Résultat de l’extraction LLM :\n{}", data["llm_extraction"]),
          Err(e) => eprintln!("Échec de l’extraction LLM : {}", e),
      }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer VOTRE_JETON_API' \
      -d '{
        "url": "https://docs.firecrawl.dev/",
        "extractorOptions": {
          "mode": "llm-extraction",
          "extractionPrompt": "D’après les informations de la page, extrayez les données selon le schéma. ",
          "extractionSchema": {
            "type": "object",
            "properties": {
              "company_mission": {
                        "type": "string"
              },
              "supports_sso": {
                        "type": "boolean"
              },
              "is_open_source": {
                        "type": "boolean"
              },
              "is_in_yc": {
                        "type": "boolean"
              }
            },
            "required": [
              "company_mission",
              "supports_sso",
              "is_open_source",
              "is_in_yc"
            ]
          }
        }
      }'
  ```
</CodeGroup>

<div id="contributing">
  ## Contribution
</div>

Nous apprécions vos contributions ! Veuillez lire notre [guide de contribution](https://github.com/firecrawl/firecrawl/blob/main/CONTRIBUTING.md) avant de soumettre une pull request.