---
title: "Scrape par lots"
description: "Scraper plusieurs URL par lots"
og:title: "Scrape par lots | Firecrawl"
og:description: "Scraper plusieurs URL par lots"
---

import BatchScrapePython from '/snippets/fr/v2/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/fr/v2/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/fr/v2/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/fr/v2/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/fr/v2/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/fr/v2/batch-scrape/json/python.mdx';
import BatchScrapeExtractNode from '/snippets/fr/v2/batch-scrape/json/js.mdx';
import BatchScrapeExtractCURL from '/snippets/fr/v2/batch-scrape/json/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/fr/v2/batch-scrape/json/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/fr/v2/batch-scrape/json/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/fr/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## Extraction en lot de plusieurs URL
</div>

Vous pouvez désormais extraire en lot plusieurs URL simultanément. La fonction prend les URL de départ et des paramètres optionnels comme arguments. L’argument params vous permet de définir des options supplémentaires pour le traitement en lot, telles que les formats de sortie.

<div id="how-it-works">
  ### Fonctionnement
</div>

C’est très similaire au fonctionnement du point de terminaison `/crawl`. Vous pouvez soit lancer le lot et attendre qu’il se termine, soit le lancer et gérer vous‑même sa finalisation.

* `batchScrape` (JS) / `batch_scrape` (Python) : lance un lot et attend sa fin, puis renvoie les résultats.
* `startBatchScrape` (JS) / `start_batch_scrape` (Python) : lance un lot et renvoie l’ID du job pour que vous puissiez effectuer du polling ou utiliser des webhooks.

<div id="usage">
  ### Utilisation
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

### Réponse

Appeler `batchScrape`/`batch_scrape` renvoie les résultats complets une fois le lot terminé.

<BatchScrapeOutput />

Appeler `startBatchScrape`/`start_batch_scrape` renvoie
un ID de tâche que vous pouvez suivre via `getBatchScrapeStatus`/`get_batch_scrape_status`, en utilisant
le point de terminaison API `/batch/scrape/{id}` ou des webhooks. Les résultats de la tâche sont accessibles via l&#39;API pendant 24 heures après son achèvement. Passé ce délai, vous pouvez toujours consulter l&#39;historique et les résultats de vos batch scrapes dans les [journaux d&#39;activité](https://www.firecrawl.dev/app/logs).

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-structured-extraction">
  ## Grattage en lot avec extraction structurée
</div>

Vous pouvez aussi utiliser le point de terminaison de grattage en lot pour extraire des données structurées depuis les pages. C’est utile si vous voulez obtenir les mêmes données structurées à partir d’une liste d’URL.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Réponse
</div>

`batchScrape`/`batch_scrape` retourne les résultats complets :

<BatchScrapeExtractOutput />

`startBatchScrape`/`start_batch_scrape` retourne un ID de tâche :

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Récupération en lot avec webhooks
</div>

Vous pouvez configurer des webhooks pour recevoir des notifications en temps réel à mesure que chaque URL de votre lot est récupérée. Cela vous permet de traiter les résultats immédiatement, sans attendre la fin de l’ensemble du lot.

<BatchScrapeWebhookCURL />

<div id="quick-reference">
  ### Référence rapide
</div>

**Types d’événements :**

* `batch_scrape.started` - Lorsque le scraping par lot démarre
* `batch_scrape.page` - Pour chaque URL extraite avec succès
* `batch_scrape.completed` - Lorsque toutes les URL sont traitées
* `batch_scrape.failed` - Si le scraping par lot rencontre une erreur

**Charge utile de base :**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Données de page pour les événements 'page'
  "metadata": {}, // Your custom metadata
  "error": null
}
```

<div id="security-verifying-webhook-signatures">
  ### Sécurité : vérification des signatures de webhook
</div>

Chaque requête de webhook provenant de Firecrawl inclut un en-tête `X-Firecrawl-Signature` contenant une signature HMAC-SHA256. **Vérifiez toujours cette signature** pour vous assurer que le webhook est authentique et n&#39;a pas été altéré.

**Fonctionnement :**

1. Récupérez votre secret de webhook dans l&#39;[onglet Advanced](https://www.firecrawl.dev/app/settings?tab=advanced) des paramètres de votre compte
2. Extrayez la signature depuis l&#39;en-tête `X-Firecrawl-Signature`
3. Calculez le HMAC-SHA256 du corps brut de la requête en utilisant votre secret
4. Comparez-la à l&#39;en-tête de signature à l&#39;aide d&#39;une fonction sécurisée vis-à-vis du temps d&#39;exécution (timing-safe)

<Warning>
  Ne traitez jamais un webhook sans vérifier d&#39;abord sa signature. L&#39;en-tête `X-Firecrawl-Signature` contient la signature au format : `sha256=abc123def456...`
</Warning>

Pour des exemples d&#39;implémentation complets en JavaScript et Python, consultez la [documentation sur la sécurité des webhooks](/fr/webhooks/security).

<div id="full-documentation">
  ### Documentation complète
</div>

Pour une documentation complète sur les webhooks, incluant des payloads d’événements détaillés, une configuration avancée et des conseils de dépannage, consultez la [documentation sur les webhooks](/fr/webhooks/overview).