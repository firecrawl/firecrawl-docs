---
title: "Mode avancé"
description: "Utilisez des proxies avancés pour un scraping fiable sur des sites complexes tout en préservant la confidentialité"
og:title: "Mode avancé | Firecrawl"
og:description: "Utilisez des proxies avancés pour un scraping fiable sur des sites complexes tout en préservant la confidentialité"
---

import ProxyPython from "/snippets/fr/v2/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/fr/v2/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/fr/v2/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/fr/v2/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/fr/v2/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/fr/v2/scrape/proxy-retry/curl.mdx";

Firecrawl propose différents types de proxy pour vous aider à effectuer du scraping sur des sites web de complexité variable. Le type de proxy peut être spécifié à l&#39;aide du paramètre `proxy`.


<div id="proxy-types">
  ### Types de proxy
</div>

Firecrawl prend en charge trois types de proxy :

- **basic** : Proxies pour le scraping de la plupart des sites. Rapides et généralement efficaces.
- **enhanced** : Proxies avancés pour le scraping de sites complexes tout en préservant la confidentialité. Plus lents, mais plus fiables sur certains sites.
- **auto** : Firecrawl réessaiera automatiquement le scraping avec des proxies enhanced si le proxy basic échoue. Si le nouvel essai avec enhanced réussit, 5 crédits seront facturés pour le scraping. Si la première tentative avec basic réussit, seul le coût standard sera facturé.

Si vous ne spécifiez pas de proxy, Firecrawl utilisera auto par défaut.

<div id="using-enhanced-mode">
  ### Utiliser le mode amélioré
</div>

Lors du scraping de sites web complexes, vous pouvez utiliser le mode amélioré pour améliorer votre taux de réussite tout en préservant la confidentialité.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Remarque :** les requêtes via le proxy en mode amélioré coûtent 5 crédits par requête.

<div id="using-enhanced-as-a-retry-mechanism">
  ## Utiliser Enhanced comme mécanisme de réessai
</div>

Un modèle courant consiste à d'abord essayer de faire du scraping avec les paramètres de proxy par défaut, puis à réessayer avec le mode Enhanced si vous rencontrez des codes d'état d'erreur spécifiques (401, 403 ou 500) dans le champ `metadata.statusCode` de la réponse. Ces codes d'état peuvent indiquer que le site web bloque votre requête.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Cette approche vous permet d'optimiser votre consommation de crédits en n'utilisant le mode Enhanced que lorsque c'est nécessaire.