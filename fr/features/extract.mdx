---
title: "Extraction"
description: "Extraire des données structurées à partir de pages à l’aide de LLM"
og:title: "Extraction | Firecrawl"
og:description: "Extraire des données structurées à partir de pages à l’aide de LLM"
icon: "barcode-read"
sidebarTitle: "Extraction"
---

import ExtractCURL from "/snippets/fr/v2/extract/base/curl.mdx";
import ExtractPython from "/snippets/fr/v2/extract/base/python.mdx";
import ExtractNode from "/snippets/fr/v2/extract/base/js.mdx";
import ExtractOutput from "/snippets/fr/v2/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/fr/v2/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/fr/v2/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/fr/v2/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/fr/v2/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/fr/v2/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/fr/v2/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/fr/v2/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/fr/v2/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/fr/v2/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/fr/v2/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/fr/v2/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/fr/v2/extract/status/pending.mdx";
import ExtractStatusDone from "/snippets/fr/v2/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/fr/v2/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/fr/v2/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/fr/v2/extract/without-urls/curl.mdx";

Le point de terminaison `/extract` simplifie la collecte de données structurées à partir d’un nombre quelconque d’URL ou de domaines entiers. Fournissez une liste d’URL, éventuellement avec des caractères génériques (p. ex. `example.com/*`), ainsi qu’un prompt ou un schéma décrivant les informations recherchées. Firecrawl gère les détails du crawling, du parsing et de la consolidation de jeux de données, petits ou grands.

<Info>Extract est facturé différemment des autres points de terminaison. Consultez la [tarification d’Extract](https://www.firecrawl.dev/extract#pricing) pour plus de détails.</Info>


<div id="using-extract">
  ## Utilisation de `/extract`
</div>

Vous pouvez extraire des données structurées à partir d’une ou plusieurs URL, y compris avec des caractères génériques :

- **Page unique**  
  Exemple : `https://firecrawl.dev/some-page`
- **Pages multiples / Domaine complet**  
  Exemple : `https://firecrawl.dev/*`

Lorsque vous utilisez `/*`, Firecrawl va automatiquement explorer et parser toutes les URL qu’il peut découvrir sur ce domaine, puis extraire les données demandées. Cette fonctionnalité est expérimentale ; écrivez à [help@firecrawl.com](mailto:help@firecrawl.com) en cas de problème.

<div id="example-usage">
  ### Exemple d’utilisation
</div>

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

**Paramètres clés :**

- **urls** : Tableau d’une ou plusieurs URL. Prend en charge les caractères génériques (`/*`) pour un crawl plus large.
- **prompt** (Optionnel sauf si aucun schéma) : Instruction en langage naturel décrivant les données souhaitées ou la manière dont vous voulez qu’elles soient structurées.
- **schema** (Optionnel sauf si aucun prompt) : Structure plus stricte si vous connaissez déjà le format JSON.
- **enableWebSearch** (Optionnel) : Lorsque `true`, l’extraction peut suivre des liens en dehors du domaine spécifié.

Voir la [référence de l’API](https://docs.firecrawl.dev/api-reference/endpoint/extract) pour plus de détails.

<div id="response-sdks">
  ### Réponse (SDKs)
</div>

<ExtractOutput />

<div id="job-status-and-completion">
  ## Statut et achèvement du job
</div>

Lorsque vous lancez un job d’extraction — directement via l’API ou via les méthodes de démarrage — vous recevez un ID de job. Vous pouvez utiliser cet ID pour :

- Consulter le statut du job : envoyez une requête au point de terminaison /extract/{ID} pour vérifier s’il est toujours en cours ou terminé.
- Attendre les résultats : si vous utilisez la méthode par défaut `extract` (Python/Node), le SDK attend et renvoie les résultats finaux.
- Démarrer puis interroger : si vous utilisez les méthodes de démarrage — `start_extract` (Python) ou `startExtract` (Node) — le SDK renvoie immédiatement un ID de job. Utilisez `get_extract_status` (Python) ou `getExtractStatus` (Node) pour suivre l’avancement.

<Note>
  Ce point de terminaison ne fonctionne que pour les jobs en cours ou récemment terminés (dans les 24 heures).
</Note>

Ci-dessous, des exemples de code pour vérifier le statut d’un job d’extraction avec Python, Node.js et cURL :

<CodeGroup>

<CheckExtractJobPython />
<CheckExtractJobJS />
<CheckExtractJobCURL />

</CodeGroup>

<div id="possible-states">
  ### États possibles
</div>

- **completed**: L’extraction a réussi.
- **processing**: Firecrawl traite encore votre requête.
- **failed**: Une erreur s’est produite ; les données n’ont pas été entièrement extraites.
- **cancelled**: La tâche a été annulée par l’utilisateur.

<div id="pending-example">
  #### Exemple en cours
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### Exemple terminé
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## Extraction sans schéma
</div>

Si vous préférez ne pas définir une structure stricte, vous pouvez simplement fournir un `prompt`. Le modèle sous-jacent choisira une structure pour vous, ce qui peut être utile pour des requêtes plus exploratoires ou plus flexibles.

<CodeGroup>

<ExtractNoSchemaPython />
<ExtractNoSchemaJS />
<ExtractNoSchemaCURL />

</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## Améliorer les résultats avec la recherche web
</div>

Définir `enableWebSearch = true` dans votre requête étend l’exploration au-delà de l’ensemble d’URL fourni. Cela permet de récupérer des informations complémentaires ou liées depuis des pages référencées.

Voici un exemple qui extrait des informations sur les caméras embarquées (dash cams), en enrichissant les résultats avec des données issues de pages connexes :

<CodeGroup>

<ExtractWebSearchPython />
<ExtractWebSearchJS />
<ExtractWebSearchCURL />

</CodeGroup>

<div id="example-response-with-web-search">
  ### Exemple de réponse avec recherche web
</div>

<ExtractWebSearchOutput />

La réponse inclut un contexte supplémentaire tiré de pages connexes, offrant des informations plus complètes et plus précises.

<div id="extracting-without-urls">
  ## Extraire sans URL
</div>

Le point de terminaison `/extract` prend désormais en charge l’extraction de données structurées à l’aide d’un prompt, sans avoir besoin d’URL spécifiques. C’est utile pour la recherche ou lorsque les URL exactes ne sont pas connues. Actuellement en alpha.

<CodeGroup>

<ExtractWithoutURLsPython />
<ExtractWithoutURLsJS />
<ExtractWithoutURLsCURL />

</CodeGroup>

<div id="known-limitations-beta">
  ## Limitations connues (bêta)
</div>

1. **Couverture de sites à grande échelle**  
   La couverture complète de sites très volumineux (p. ex. « tous les produits sur Amazon ») en une seule requête n’est pas encore prise en charge.

2. **Requêtes logiques complexes**  
   Des requêtes comme « trouver toutes les publications de 2025 » peuvent ne pas renvoyer de manière fiable toutes les données attendues. Des capacités de requête plus avancées sont en cours de développement.

3. **Incohérences occasionnelles**  
   Les résultats peuvent varier d’une exécution à l’autre, en particulier pour les sites très vastes ou dynamiques. En général, les informations essentielles sont capturées, mais des variations sont possibles.

4. **État bêta**  
   Comme `/extract` est encore en bêta, les fonctionnalités et les performances continueront d’évoluer. Nous accueillons les signalements de bugs et vos retours pour nous aider à nous améliorer.

<div id="using-fire-1">
  ## Utiliser FIRE-1
</div>

FIRE-1 est un agent IA qui étend les capacités de scraping de Firecrawl. Il peut contrôler des actions du navigateur et naviguer dans des structures de sites web complexes pour permettre une extraction de données plus complète que les méthodes de scraping traditionnelles.

Vous pouvez utiliser l’agent FIRE-1 avec le point de terminaison `/extract` pour des tâches d’extraction complexes nécessitant une navigation sur plusieurs pages ou une interaction avec des éléments.

**Exemple (cURL) :**

```bash
curl -X POST https://api.firecrawl.dev/v2/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer VOTRE_CLÉ_API' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "Extraire tous les commentaires des utilisateurs de ce fil de discussion.",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> FIRE-1 est déjà disponible et accessible en avant-première.


<div id="billing-and-usage-tracking">
  ## Facturation et suivi de l’utilisation
</div>

Vous pouvez consulter les tarifs de /extract sur la [page tarifs d’Extract](https://www.firecrawl.dev/extract#pricing) et suivre votre utilisation via la [page Extract du tableau de bord](https://www.firecrawl.dev/app/extract).

Des commentaires ou besoin d’aide ? Écrivez à [help@firecrawl.com](mailto:help@firecrawl.com).