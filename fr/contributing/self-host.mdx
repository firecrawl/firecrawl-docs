---
title: "Auto-h√©bergement"
description: "D√©couvrez comment auto-h√©berger Firecrawl pour l‚Äôex√©cuter chez vous et contribuer au projet."
og:title: "Auto-h√©bergement | Firecrawl"
og:description: "D√©couvrez comment auto-h√©berger Firecrawl pour l‚Äôex√©cuter chez vous et contribuer au projet."
---

<div id="contributor">
  #### Vous souhaitez contribuer ?
</div>

Bienvenue sur [Firecrawl](https://firecrawl.dev) üî• ! Voici quelques instructions pour r√©cup√©rer le projet en local afin de l‚Äôex√©cuter vous-m√™me et d‚Äôy contribuer.

Si vous contribuez, notez que le processus est similaire √† d‚Äôautres d√©p√¥ts open source‚ÄØ: forkez Firecrawl, apportez vos modifications, ex√©cutez les tests, puis ouvrez une PR.

Si vous avez des questions ou souhaitez de l‚Äôaide pour d√©marrer, rejoignez notre communaut√© Discord [ici](https://discord.gg/gSmWdAkdwd) pour en savoir plus, ou ouvrez une issue sur GitHub [ici](https://github.com/firecrawl/firecrawl/issues/new/choose) !

<div id="self-hosting-firecrawl">
  ## Auto-h√©bergement de Firecrawl
</div>

Consultez [SELF_HOST.md](https://github.com/firecrawl/firecrawl/blob/main/SELF_HOST.md) pour savoir comment l‚Äôex√©cuter en local.

<div id="why">
  ## Pourquoi ?
</div>

L‚Äôauto‚Äëh√©bergement de Firecrawl est particuli√®rement utile pour les organisations dont les politiques de s√©curit√© exigent que les donn√©es restent dans des environnements contr√¥l√©s. Voici quelques raisons majeures d‚Äôenvisager l‚Äôauto‚Äëh√©bergement :

- **S√©curit√© et conformit√© renforc√©es :** En auto‚Äëh√©bergeant, vous garantissez que l‚Äôensemble de la gestion et du traitement des donn√©es respecte les r√©glementations internes et externes, en conservant les informations sensibles au sein de votre infrastructure s√©curis√©e. Notez que Firecrawl est un produit Mendable et s‚Äôappuie sur la certification SOC 2 Type II, ce qui signifie que la plateforme respecte des normes √©lev√©es du secteur en mati√®re de s√©curit√© des donn√©es.
- **Services personnalisables :** L‚Äôauto‚Äëh√©bergement vous permet d‚Äôadapter des services, comme Playwright, pour r√©pondre √† des besoins sp√©cifiques ou couvrir des cas d‚Äôusage particuliers qui ne sont pas forc√©ment pris en charge par l‚Äôoffre cloud standard.
- **Apprentissage et contribution √† la communaut√© :** En configurant et en maintenant votre propre instance, vous approfondissez votre compr√©hension du fonctionnement de Firecrawl, ce qui peut √©galement conduire √† des contributions plus significatives au projet.

<div id="considerations">
  ### Consid√©rations
</div>

Cependant, il existe certaines limites et des responsabilit√©s suppl√©mentaires √† garder √† l‚Äôesprit :

1. **Acc√®s limit√© √† Fire-engine :** Actuellement, les instances auto-h√©berg√©es de Firecrawl n‚Äôont pas acc√®s √† Fire-engine, qui comprend des fonctionnalit√©s avanc√©es pour g√©rer les blocages d‚ÄôIP, les m√©canismes de d√©tection des robots, et plus encore. Cela signifie que, m√™me si vous pouvez traiter des t√¢ches de scraping de base, des cas plus complexes peuvent n√©cessiter une configuration suppl√©mentaire ou ne pas √™tre pris en charge.
2. **Configuration manuelle requise :** Si vous devez utiliser des m√©thodes de scraping au-del√† des options de base `fetch` et Playwright, vous devrez les configurer manuellement dans le fichier `.env`. Cela n√©cessite une compr√©hension plus approfondie des technologies et peut impliquer davantage de temps de mise en place.

| Fonctionnalit√© | Cloud | Auto-h√©bergement |
| --- | --- | --- |
| Tous les endpoints d‚ÄôAPI pris en charge | Oui | Pas toujours ; `/agent` n‚Äôest pas pris en charge en auto-h√©bergement |
| Prise en charge des captures d‚Äô√©cran | Oui | Oui, lorsque le service Playwright est en cours d‚Äôex√©cution |
| LLM locaux (par ex. Ollama) | Non pris en charge | Pris en charge via `OLLAMA_BASE_URL` (exp√©rimental) |

L‚Äôauto-h√©bergement de Firecrawl est id√©al pour ceux qui ont besoin d‚Äôun contr√¥le total sur leurs environnements de scraping et de traitement des donn√©es, mais il s‚Äôaccompagne du revers d‚Äôune charge suppl√©mentaire de maintenance et de configuration.

<div id="steps">
  ## √âtapes
</div>

1. Commencez par installer les d√©pendances

* Docker [instructions](https://docs.docker.com/get-docker/)

2. D√©finissez les variables d&#39;environnement

Cr√©ez un fichier `.env` √† la racine du projet. Vous pouvez copier le mod√®le situ√© dans `apps/api/.env.example`.

Pour commencer, nous ne configurerons ni l&#39;authentification ni aucun sous-service optionnel (parsing PDF, prise en charge du blocage de JS, fonctionnalit√©s IA)

```
# .env

# ===== Required ENVS ======
PORT=3002
HOST=0.0.0.0

# Note: PORT is used by both the main API server and worker liveness check endpoint

# To turn on DB authentication, you need to set up Supabase.
USE_DB_AUTHENTICATION=false

# ===== Optional ENVS ======

## === AI features (JSON format on scrape, /extract API) ===
# Provide your OpenAI API key here to enable AI features
# OPENAI_API_KEY=

# Experimental: Use Ollama
# OLLAMA_BASE_URL=http://localhost:11434/api
# MODEL_NAME=deepseek-r1:7b
# MODEL_EMBEDDING_NAME=nomic-embed-text

# Experimental: Use any OpenAI-compatible API
# OPENAI_BASE_URL=https://example.com/v1
# OPENAI_API_KEY=

## === Proxy ===
# PROXY_SERVER can be a full URL (e.g. http://0.1.2.3:1234) or just an IP and port combo (e.g. 0.1.2.3:1234)
# Do not uncomment PROXY_USERNAME and PROXY_PASSWORD if your proxy is unauthenticated
# PROXY_SERVER=
# PROXY_USERNAME=
# PROXY_PASSWORD=

## === API /search ===

# Vous pouvez sp√©cifier un serveur SearXNG avec le format JSON activ√©, si vous souhaitez l'utiliser √† la place de Google direct.
# Vous pouvez √©galement personnaliser les param√®tres engines et categories, mais les valeurs par d√©faut devraient √©galement fonctionner correctement.
# SEARXNG_ENDPOINT=http://your.searxng.server
# SEARXNG_ENGINES=
# SEARXNG_CATEGORIES=

## === Other ===

# Supabase Setup (used to support DB authentication, advanced logging, etc.)
# SUPABASE_ANON_TOKEN=
# SUPABASE_URL=
# SUPABASE_SERVICE_TOKEN=

# Use if you've set up authentication and want to test with a real API key
# TEST_API_KEY=

# This key lets you access the queue admin panel. Change this if your deployment is publicly accessible.
BULL_AUTH_KEY=CHANGEME

# This is now autoconfigured by the docker-compose.yaml. You shouldn't need to set it.
# PLAYWRIGHT_MICROSERVICE_URL=http://playwright-service:3000/scrape
# REDIS_URL=redis://redis:6379
# REDIS_RATE_LIMIT_URL=redis://redis:6379

# Set if you have a llamaparse key you'd like to use to parse pdfs
# LLAMAPARSE_API_KEY=

# Set if you'd like to send server health status messages to Slack
# SLACK_WEBHOOK_URL=

# Set if you'd like to send posthog events like job logs
# POSTHOG_API_KEY=
# POSTHOG_HOST=

## === System Resource Configuration ===
# Maximum CPU usage threshold (0.0-1.0). Worker will reject new jobs when CPU usage exceeds this value.
# Default: 0.8 (80%)
# MAX_CPU=0.8

# Maximum RAM usage threshold (0.0-1.0). Worker will reject new jobs when memory usage exceeds this value.
# Default: 0.8 (80%)
# MAX_RAM=0.8

# Set if you'd like to allow local webhooks to be sent to your self-hosted instance
# ALLOW_LOCAL_WEBHOOKS=true
```

<Note>
  Les fonctionnalit√©s d‚ÄôIA suivantes n√©cessitent qu‚Äôun fournisseur de LLM soit configur√© (par exemple, `OPENAI_API_KEY` ou des alternatives dans la section des fonctionnalit√©s d‚ÄôIA ci-dessus)¬†:

  * Format JSON lors du scrape
  * API /extract
  * Format de r√©sum√©
  * Format de branding
  * Format de suivi des modifications
</Note>

3. *(Optionnel) Ex√©cuter avec le service Playwright en TypeScript*

   * Mettez √† jour le fichier `docker-compose.yml` pour modifier le service Playwright¬†:

     ```plaintext
         build: apps/playwright-service
     ```

     EN

     ```plaintext
         build: apps/playwright-service-ts
     ```

   * D√©finissez la variable `PLAYWRIGHT_MICROSERVICE_URL` dans votre fichier `.env`¬†:

     ```plaintext
     PLAYWRIGHT_MICROSERVICE_URL=http://localhost:3000/scrape
     ```

   * N‚Äôoubliez pas de configurer le serveur proxy dans votre fichier `.env` si n√©cessaire.

4. Construisez et lancez les conteneurs Docker¬†:

   ```bash
   docker compose build
   docker compose up
   ```

Cela d√©marre une instance locale de Firecrawl accessible √† l‚Äôadresse `http://localhost:3002`.

Vous devriez voir l‚Äôinterface Bull Queue Manager √† l‚Äôadresse `http://localhost:3002/admin/{BULL_AUTH_KEY}/queues`.

5. *(Optionnel)* Tester l&#39;API

Si vous souhaitez tester l‚Äôendpoint de crawl, vous pouvez ex√©cuter la commande suivante¬†:

```bash
  curl -X POST http://localhost:3002/v2/crawl \
      -H 'Content-Type: application/json' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
```


<div id="troubleshooting">
  ## D√©pannage
</div>

Cette section propose des solutions aux probl√®mes courants que vous pouvez rencontrer lors de la configuration ou de l‚Äôex√©cution de votre instance Firecrawl auto-h√©berg√©e.

<div id="supabase-client-is-not-configured">
  ### Le client Supabase n‚Äôest pas configur√©
</div>

**Sympt√¥me :**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Tentative d‚Äôacc√®s au client Supabase alors qu‚Äôil n‚Äôest pas configur√©.
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Erreur lors de l‚Äôinsertion de l‚Äô√©v√©nement de scraping¬†: Erreur¬†: le client Supabase n‚Äôest pas configur√©.
```

**Explication :**
Cette erreur se produit parce que la configuration du client Supabase n‚Äôest pas finalis√©e. Vous devriez pouvoir lancer des op√©rations de scraping et de crawling sans probl√®me. √Ä l‚Äôheure actuelle, il n‚Äôest pas possible de configurer Supabase sur des instances auto‚Äëh√©berg√©es.

<div id="youre-bypassing-authentication">
  ### Vous contournez le m√©canisme d‚Äôauthentification
</div>

**Sympt√¥me :**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]WARN - You're bypassing authentication
```

**Explication¬†:**
Cette erreur se produit parce que la configuration du client Supabase n‚Äôest pas finalis√©e. Vous pouvez tout de m√™me effectuer du scraping et du crawling sans probl√®me. Pour le moment, il n‚Äôest pas possible de configurer Supabase sur des instances auto-h√©berg√©es.


<div id="docker-containers-fail-to-start">
  ### Les conteneurs Docker ne d√©marrent pas
</div>

**Sympt√¥me :**
Les conteneurs Docker s&#39;arr√™tent de mani√®re inattendue ou ne parviennent pas √† d√©marrer.

**Solution :**
V√©rifiez les logs Docker pour d√©tecter d&#39;√©ventuels messages d&#39;erreur en utilisant la commande :

```bash
docker logs [container_name]
```

* Assurez-vous que toutes les variables d&#39;environnement n√©cessaires sont correctement d√©finies dans le fichier .env.
* V√©rifiez que tous les services Docker d√©finis dans docker-compose.yml sont correctement configur√©s et que les images requises sont disponibles.


<div id="connection-issues-with-redis">
  ### Probl√®mes de connexion avec Redis
</div>

**Sympt√¥me :**
Erreurs li√©es √† la connexion √† Redis, telles que des d√©lais d‚Äôattente d√©pass√©s ou des erreurs ¬´ Connection refused ¬ª.

**Solution :**

- Assurez-vous que le service Redis est d√©marr√© et fonctionne dans votre environnement Docker.
- V√©rifiez que les variables REDIS_URL et REDIS_RATE_LIMIT_URL dans votre fichier .env pointent vers la bonne instance Redis.
- V√©rifiez les param√®tres r√©seau et les r√®gles de pare-feu susceptibles de bloquer la connexion au port Redis.

<div id="api-endpoint-does-not-respond">
  ### Le point de terminaison API ne r√©pond pas
</div>

**Sympt√¥me :**
Les requ√™tes API vers l‚Äôinstance Firecrawl expirent ou ne renvoient aucune r√©ponse.

**Solution :**

- Assurez-vous que le service Firecrawl est en cours d‚Äôex√©cution en v√©rifiant l‚Äô√©tat du conteneur Docker.
- V√©rifiez que les variables PORT et HOST dans votre fichier .env sont correctes et qu‚Äôaucun autre service n‚Äôutilise le m√™me port.
- Contr√¥lez la configuration r√©seau pour vous assurer que l‚Äôh√¥te est accessible depuis le client qui effectue la requ√™te API.

En r√©solvant ces probl√®mes courants, vous faciliterez la configuration et le fonctionnement de votre instance Firecrawl auto-h√©berg√©e.

<div id="install-firecrawl-on-a-kubernetes-cluster-simple-version">
  ## Installer Firecrawl sur un cluster Kubernetes (version simple)
</div>

Consultez le fichier [examples/kubernetes-cluster-install/README.md](https://github.com/firecrawl/firecrawl/tree/main/examples/kubernetes/cluster-install#readme) pour savoir comment installer Firecrawl sur un cluster Kubernetes.