---
title: "Guide de scraping avancé"
description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
og:title: "Guide de scraping avancé | Firecrawl"
og:description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
---

Ce guide présente les différents points de terminaison de Firecrawl et explique comment les utiliser au mieux avec l’ensemble de leurs paramètres.

<div id="basic-scraping-with-firecrawl">
  ## Scraping basique avec Firecrawl
</div>

Pour extraire une seule page et obtenir un contenu Markdown propre, utilisez le point de terminaison `/scrape`.

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## Extraction de PDF
</div>

Firecrawl prend en charge les PDF. Utilisez l’option `parsers` (par exemple `parsers: ["pdf"]`) lorsque vous voulez garantir l’analyse des PDF.

<div id="scrape-options">
  ## Options d’extraction
</div>

Lorsque vous utilisez le point de terminaison /scrape, vous pouvez personnaliser l’extraction avec les options ci-dessous.

<div id="formats-formats">
  ### Formats (`formats`)
</div>

- **Type**: `array`
- **Chaînes**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **Formats d’objet**:
  - JSON : `{ type: "json", prompt, schema }`
  - Capture d’écran : `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - Suivi des modifications : `{ type: "changeTracking", modes?, prompt?, schema?, tag? }` (nécessite `markdown`)
- **Par défaut**: `["markdown"]`

<div id="full-page-content-vs-main-content-onlymaincontent">
  ### Contenu complet de la page vs contenu principal (`onlyMainContent`)
</div>

- **Type**: `boolean`
- **Description**: Par défaut, le scraper renvoie uniquement le contenu principal. Définissez sur `false` pour renvoyer l’intégralité du contenu de la page.
- **Par défaut**: `true`

<div id="include-tags-includetags">
  ### Balises à inclure (`includeTags`)
</div>

- **Type**: `array`
- **Description**: Balises/classes/ID HTML à inclure dans le scraping.

<div id="exclude-tags-excludetags">
  ### Exclure des balises (`excludeTags`)
</div>

- **Type**: `array`
- **Description**: Balises/classes/IDs HTML à exclure de l'extraction.

<div id="wait-for-page-readiness-waitfor">
  ### Attente de préparation de la page (`waitFor`)
</div>

- **Type** : `integer`
- **Description** : Nombre de millisecondes d'attente supplémentaire avant le scraping (à utiliser avec parcimonie). Ce délai s'ajoute à la fonctionnalité d'attente intelligente de Firecrawl.
- **Valeur par défaut** : `0`

<div id="freshness-and-cache-maxage">
  ### Fraîcheur et cache (`maxAge`)
</div>

- **Type**: `integer` (millisecondes)
- **Description**: Si une version en cache de la page est plus récente que `maxAge`, Firecrawl la renvoie immédiatement ; sinon, il procède à une nouvelle extraction et met à jour le cache. Définissez `0` pour toujours récupérer une version fraîche.
- **Par défaut**: `172800000` (2 jours)

<div id="request-timeout-timeout">
  ### Délai d’expiration de la requête (`timeout`)
</div>

- **Type**: `integer`
- **Description**: Durée maximale en millisecondes avant l’interruption.
- **Valeur par défaut**: `30000` (30 secondes)

<div id="pdf-parsing-parsers">
  ### Analyse des PDF (`parsers`)
</div>

- **Type**: `array`
- **Description**: Contrôle le comportement d’analyse. Pour traiter des PDF, définissez `parsers: ["pdf"]`.
- **Coût** : L’analyse de PDF coûte 1 crédit par page PDF. Pour ignorer l’analyse de PDF et recevoir le fichier en base64 (1 crédit forfaitaire), définissez `parsers: []`.
- **Limiter le nombre de pages** : Pour limiter l’analyse de PDF à un nombre spécifique de pages, utilisez `parsers: [{"type": "pdf", "maxPages": 10}]`.

<div id="actions-actions">
  ### Actions (`actions`)
</div>

Lors de l'utilisation du point de terminaison /scrape, Firecrawl vous permet d'exécuter diverses actions sur une page web avant d'en extraire le contenu. Cela est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre des pages ou accéder à du contenu qui nécessite une interaction de l'utilisateur.

- **Type** : `array`
- **Description** : Séquence d'étapes du navigateur à exécuter avant le scraping.
- **Actions prises en charge** :
    - `wait` - Attendre le chargement de la page : `{ type: "wait", milliseconds: number }` ou `{ type: "wait", selector: string }`
    - `click` - Cliquer sur un élément : `{ type: "click", selector: string, all?: boolean }`
    - `write` - Saisir du texte dans un champ : `{ type: "write", text: string }` (l'élément doit d'abord avoir le focus via un clic)
    - `press` - Appuyer sur une touche du clavier : `{ type: "press", key: string }`
    - `scroll` - Faire défiler la page : `{ type: "scroll", direction: "up" | "down", selector?: string }`
    - `screenshot` - Prendre une capture d'écran : `{ type: "screenshot", fullPage?: boolean, quality?: number, viewport?: { width: number, height: number } }`
    - `scrape` - Extraire un sous-élément : `{ type: "scrape" }`
    - `executeJavascript` - Exécuter du code JS : `{ type: "executeJavascript", script: string }`
    - `pdf` - Générer un PDF : `{ type: "pdf", format?: string, landscape?: boolean, scale?: number }`

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  'actions': [
    { 'type': 'wait', 'milliseconds': 1000 },
    { 'type': 'click', 'selector': '#accept' },
    { 'type': 'scroll', 'direction': 'down' },
    { 'type': 'click', 'selector': '#q' },
    { 'type': 'write', 'text': 'firecrawl' },
    { 'type': 'press', 'key': 'Enter' },
    { 'type': 'wait', 'milliseconds': 2000 }
  ],
  'formats': ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'click', selector: '#q' },
    { type: 'write', text: 'firecrawl' },
    { type: 'press', key: 'Enter' },
    { type: 'wait', milliseconds: 2000 }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "click", "selector": "#q" },
      { "type": "write", "text": "firecrawl" },
      { "type": "press", "key": "Enter" },
      { "type": "wait", "milliseconds": 2000 }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

<div id="action-execution-notes">
  ### Notes sur l'exécution des actions
</div>

- **Action `write`** : vous devez d'abord mettre l'élément au focus en utilisant une action `click` avant d'utiliser `write`. Le texte est saisi caractère par caractère pour simuler une saisie au clavier.
- **Sélecteur pour `scroll`** : si vous voulez faire défiler un élément spécifique plutôt que la page entière, fournissez le paramètre `selector` à `scroll`.
- **Attente avec sélecteur** : vous pouvez attendre qu'un élément spécifique soit visible en utilisant `wait` avec un paramètre `selector`, ou attendre une durée fixe en utilisant `milliseconds`.
- **Les actions sont séquentielles** : les actions sont exécutées dans l'ordre et Firecrawl attend que les interactions avec la page soient terminées avant de passer à l'action suivante.

<div id="advanced-action-examples">
  ### Exemples d’actions avancées
</div>

**Prendre une capture d’écran :**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "click", "selector": "#load-more" },
      { "type": "wait", "milliseconds": 1000 },
      { "type": "screenshot", "fullPage": true, "quality": 80 }
    ]
  }'
```

**Clic sur plusieurs éléments :**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "click", "selector": ".expand-button", "all": true },
      { "type": "wait", "milliseconds": 500 }
    ],
    "formats": ["markdown"]
  }'
```

**Générer un PDF :**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "pdf", "format": "A4", "landscape": false }
    ]
  }'
```


<div id="example-usage">
  ### Exemple d’utilisation
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

Dans cet exemple, le scraper va :

* Renvoyer le contenu complet de la page en Markdown.
* Inclure le Markdown, le HTML brut, le HTML, les liens et une capture d’écran dans la réponse.
* Inclure uniquement les balises HTML `<h1>`, `<p>`, `<a>` et les éléments avec la classe `.main-content`, tout en excluant les éléments avec les ID `#ad` et `#footer`.
* Attendre 1000 millisecondes (1 seconde) avant d’extraire afin de laisser la page se charger.
* Définir la durée maximale de la requête d’extraction à 15000 millisecondes (15 secondes).
* Analyser explicitement les PDF via `parsers: ["pdf"]`.

Voici la référence de l’API : [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

<div id="json-extraction-via-formats">
  ## Extraction JSON via formats
</div>

Utilisez l’objet de format JSON dans `formats` pour extraire des données structurées en une seule fois :

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "Extract the features of the product",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```


<div id="extract-endpoint">
  ## Endpoint d'extraction
</div>

Utilisez l'API dédiée aux jobs d'extraction lorsque vous avez besoin d'une extraction asynchrone avec interrogation du statut.

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// Démarrer un job d'extraction
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extraire le titre',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// Interroger le statut
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extraire le titre",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extraire le titre",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

<div id="crawling-multiple-pages">
  ## Explorer plusieurs pages
</div>

Pour explorer plusieurs pages, utilisez le point de terminaison `/v2/crawl`.

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLE-API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Renvoie un ID

```json
{ "id": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### Vérifier l’état d’une tâche de crawl
</div>

Permet de vérifier l’état d’une tâche de crawl et de récupérer son résultat.

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY'
```


<div id="paginationnext-url">
  #### Pagination/URL suivante
</div>

Si le contenu dépasse 10&nbsp;Mo ou si le job de crawl est encore en cours, la réponse peut inclure un paramètre `next`, une URL vers la page suivante de résultats.

<div id="crawl-prompt-and-params-preview">
  ### Aperçu du prompt et des paramètres de crawl
</div>

Vous pouvez fournir un `prompt` en langage naturel pour permettre à Firecrawl de déterminer les paramètres de crawl. Prévisualisez-les d’abord :

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "Extraire la doc et le blog"
  }'
```

<div id="crawler-options">
  ### Options du crawler
</div>

Lorsque vous utilisez l’endpoint `/v2/crawl`, vous pouvez personnaliser le comportement du crawl à l’aide des options suivantes :

<div id="includepaths">
  #### includePaths
</div>

- **Type**: `array`
- **Description**: Motifs regex à inclure.
- **Example**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### excludePaths
</div>

- **Type**: `array`
- **Description**: Expressions régulières à exclure.
- **Example**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdiscoverydepth">
  #### maxDiscoveryDepth
</div>

- **Type**: `integer`
- **Description**: Profondeur maximale d’exploration pour découvrir de nouvelles URL.

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: Nombre maximal de pages à explorer.
- **Default**: `10000`

<div id="crawlentiredomain">
  #### crawlEntireDomain
</div>

- **Type**: `boolean`
- **Description**: Explorer via les pages sœurs/parentes pour couvrir l’ensemble du domaine.
- **Default**: `false`

<div id="allowexternallinks">
  #### allowExternalLinks
</div>

- **Type**: `boolean`
- **Description**: Suivre les liens vers des domaines externes.
- **Default**: `false`

<div id="allowsubdomains">
  #### allowSubdomains
</div>

- **Type**: `boolean`
- **Description**: Autoriser le suivi des sous-domaines du domaine principal.
- **Default**: `false`

<div id="delay">
  #### delay
</div>

- **Type**: `number`
- **Description**: Délai en secondes entre les opérations de scraping.
- **Default**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

- **Type**: `object`
- **Description**: Options du scraper (voir Formats ci-dessus).
- **Example**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **Defaults**: `formats: ["markdown"]`, mise en cache activée par défaut (maxAge ~ 2 jours)

### Exemple d’usage

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```

<div id="mapping-website-links">
  ## Cartographie des liens d'un site web
</div>

Le point de terminaison `/v2/map` identifie les URL associées à un site web donné.

<div id="usage">
  ### Utilisation
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

<div id="map-options">
  ### Options de cartographie
</div>

<div id="search">
  #### search
</div>

- **Type**: `string`
- **Description**: Filtre les liens contenant un texte donné.

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: Nombre maximal de liens à renvoyer.
- **Default**: `100`

<div id="sitemap">
  #### sitemap
</div>

- **Type**: `"only" | "include" | "skip"`
- **Description**: Contrôle l’utilisation du sitemap lors du mappage.
- **Default**: `"include"`

<div id="includesubdomains">
  #### includeSubdomains
</div>

- **Type**: `boolean`
- **Description**: Inclure les sous-domaines du site.
- **Default**: `true`

Voici la référence de l’API correspondante : [Documentation du point de terminaison /map](https://docs.firecrawl.dev/api-reference/endpoint/map)

Merci de votre lecture !