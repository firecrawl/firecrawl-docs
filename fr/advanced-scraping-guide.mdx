---
title: "Guide de scraping avancé"
description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
og:title: "Guide de scraping avancé | Firecrawl"
og:description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
---

Ce guide présente les différents points de terminaison de Firecrawl et explique comment les utiliser au mieux avec l’ensemble de leurs paramètres.

## Scraping basique avec Firecrawl

Pour extraire une seule page et obtenir un contenu Markdown propre, utilisez le point de terminaison `/scrape`.

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

## Extraction de PDF

Firecrawl prend en charge les PDF. Utilisez l’option `parsers` (par exemple `parsers: ["pdf"]`) lorsque vous voulez garantir l’analyse des PDF.

## Options d’extraction

Lorsque vous utilisez le point de terminaison /scrape, vous pouvez personnaliser l’extraction avec les options ci-dessous.

### Formats (`formats`)

- **Type**: `array`
- **Chaînes**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **Formats d’objet**:
  - JSON : `{ type: "json", prompt, schema }`
  - Capture d’écran : `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - Suivi des modifications : `{ type: "changeTracking", modes?, prompt?, schema?, tag? }` (nécessite `markdown`)
- **Par défaut**: `["markdown"]`

### Contenu complet de la page vs contenu principal (`onlyMainContent`)

- **Type**: `boolean`
- **Description**: Par défaut, le scraper renvoie uniquement le contenu principal. Définissez sur `false` pour renvoyer l’intégralité du contenu de la page.
- **Par défaut**: `true`

### Balises à inclure (`includeTags`)

- **Type**: `array`
- **Description**: Balises/classes/ID HTML à inclure dans le scraping.

### Exclure des balises (`excludeTags`)

- **Type**: `array`
- **Description**: Balises/classes/IDs HTML à exclure de l'extraction.

### Attendre que la page soit prête (`waitFor`)

- **Type**: `integer`
- **Description**: Nombre de millisecondes à attendre avant le scraping (à utiliser avec parcimonie).
- **Default**: `0`

### Fraîcheur et cache (`maxAge`)

- **Type**: `integer` (millisecondes)
- **Description**: Si une version en cache de la page est plus récente que `maxAge`, Firecrawl la renvoie immédiatement ; sinon, il procède à une nouvelle extraction et met à jour le cache. Définissez `0` pour toujours récupérer une version fraîche.
- **Par défaut**: `172800000` (2 jours)

### Délai d’expiration de la requête (`timeout`)

- **Type**: `integer`
- **Description**: Durée maximale en millisecondes avant l’interruption.
- **Valeur par défaut**: `30000` (30 secondes)

### Analyse des PDF (`parsers`)

- **Type**: `array`
- **Description**: Contrôle le comportement d’analyse. Pour traiter des PDF, définissez `parsers: ["pdf"]`.

### Actions (`actions`)

Lors de l’utilisation du point de terminaison /scrape, Firecrawl vous permet d’exécuter diverses actions sur une page web avant d’en extraire le contenu. C’est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre des pages ou accéder à du contenu nécessitant une interaction utilisateur.

- **Type**: `array`
- **Description**: Séquence d’étapes du navigateur à exécuter avant l’extraction.
- **Actions prises en charge**:
    - `wait` `{ milliseconds }`
    - `click` `{ selector }`
    - `write` `{ selector, text }`
    - `press` `{ key }`
    - `scroll` `{ direction: "up" | "down" }`
    - `scrape` `{ selector }` (extraire un sous-élément)
    - `executeJavascript` `{ script }`
    - `pdf` (déclencher le rendu PDF dans certains parcours)

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "write", "selector": "#q", "text": "firecrawl" },
      { "type": "press", "key": "Enter" }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

### Exemple d’utilisation

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

Dans cet exemple, le scraper va :

* Renvoyer le contenu complet de la page en Markdown.
* Inclure le Markdown, le HTML brut, le HTML, les liens et une capture d’écran dans la réponse.
* Inclure uniquement les balises HTML `<h1>`, `<p>`, `<a>` et les éléments avec la classe `.main-content`, tout en excluant les éléments avec les ID `#ad` et `#footer`.
* Attendre 1000 millisecondes (1 seconde) avant d’extraire afin de laisser la page se charger.
* Définir la durée maximale de la requête d’extraction à 15000 millisecondes (15 secondes).
* Analyser explicitement les PDF via `parsers: ["pdf"]`.

Voici la référence de l’API : [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


## Extraction JSON via les formats

Utilisez l’objet de format JSON dans `formats` pour extraire des données structurées en un seul passage :

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "Extraire les fonctionnalités du produit",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```


## Point de terminaison /extract

Utilisez l’API dédiée aux tâches d’extraction lorsque vous avez besoin d’une extraction asynchrone avec sondage de l’état.

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// Démarrer une tâche d’extraction
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extract title',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// Sondage de l’état
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract title",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extract title",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

## Explorer plusieurs pages

Pour explorer plusieurs pages, utilisez le point de terminaison `/v2/crawl`.

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLE-API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Renvoie un ID

```json
{ "id": "1234-5678-9101" }
```


### Vérifier une tâche de crawl

Permet de vérifier l’état d’une tâche de crawl et d’en récupérer le résultat.

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-VOTRE-CLÉ-API'
```


#### Pagination/URL suivante

Si le contenu dépasse 10 Mo ou si la tâche de crawl est encore en cours, la réponse peut inclure un paramètre `next`, une URL vers la page suivante des résultats.

### Aperçu du prompt et des paramètres de crawl

Vous pouvez fournir un `prompt` en langage naturel pour permettre à Firecrawl de déterminer les paramètres de crawl. Prévisualisez-les d’abord :

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "Extraire la doc et le blog"
  }'
```


### Options du crawler

Lorsque vous utilisez le point de terminaison `/v2/crawl`, vous pouvez ajuster le comportement d’exploration avec :

#### includePaths

- **Type**: `array`
- **Description**: Motifs regex à inclure.
- **Example**: `["^/blog/.*$", "^/docs/.*$"]`

#### excludePaths

- **Type**: `array`
- **Description**: Expressions régulières à exclure.
- **Example**: `["^/admin/.*$", "^/private/.*$"]`

#### maxDiscoveryDepth

- **Type**: `integer`
- **Description**: Profondeur maximale d’exploration pour découvrir de nouvelles URL.

#### limit

- **Type**: `integer`
- **Description**: Nombre maximal de pages à explorer.
- **Default**: `10000`

#### crawlEntireDomain

- **Type**: `boolean`
- **Description**: Explorer via les pages sœurs/parentes pour couvrir l’ensemble du domaine.
- **Default**: `false`

#### allowExternalLinks

- **Type**: `boolean`
- **Description**: Suivre les liens vers des domaines externes.
- **Default**: `false`

#### allowSubdomains

- **Type**: `boolean`
- **Description**: Autoriser le suivi des sous-domaines du domaine principal.
- **Default**: `false`

#### delay

- **Type**: `number`
- **Description**: Délai en secondes entre les opérations de scraping.
- **Default**: `undefined`

#### scrapeOptions

- **Type**: `object`
- **Description**: Options du scraper (voir Formats ci-dessus).
- **Example**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **Defaults**: `formats: ["markdown"]`, mise en cache activée par défaut (maxAge ~ 2 jours)

### Exemple d’usage

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```


## Cartographier les liens d’un site web

Le point de terminaison `/v2/map` identifie les URL associées à un site web donné.

### Utilisation

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```


### Options de mappage

#### search

- **Type**: `string`
- **Description**: Filtre les liens contenant un texte donné.

#### limit

- **Type**: `integer`
- **Description**: Nombre maximal de liens à renvoyer.
- **Default**: `100`

#### sitemap

- **Type**: `"only" | "include" | "skip"`
- **Description**: Contrôle l’utilisation du sitemap lors du mappage.
- **Default**: `"include"`

#### includeSubdomains

- **Type**: `boolean`
- **Description**: Inclure les sous-domaines du site.
- **Default**: `true`

Voici la référence de l’API correspondante : [Documentation du point de terminaison /map](https://docs.firecrawl.dev/api-reference/endpoint/map)

Merci de votre lecture !