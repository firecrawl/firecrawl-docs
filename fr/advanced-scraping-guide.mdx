---
title: "Guide de scraping avancé"
description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
og:title: "Guide de scraping avancé | Firecrawl"
og:description: "Découvrez comment optimiser votre scraping Firecrawl grâce à des options avancées."
---

Ce guide présente les différents points de terminaison de Firecrawl et explique comment les utiliser au mieux avec l’ensemble de leurs paramètres.

<div id="basic-scraping-with-firecrawl">
  ## Scraping basique avec Firecrawl
</div>

Pour extraire une seule page et obtenir un contenu Markdown propre, utilisez le point de terminaison `/scrape`.

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## Extraction de PDF
</div>

Firecrawl prend en charge les PDF. Utilisez l’option `parsers` (par exemple `parsers: ["pdf"]`) lorsque vous voulez garantir l’analyse des PDF.

<div id="scrape-options">
  ## Options d’extraction
</div>

Lorsque vous utilisez le point de terminaison /scrape, vous pouvez personnaliser l’extraction avec les options ci-dessous.

<div id="formats-formats">
  ### Formats (`formats`)
</div>

- **Type**: `array`
- **Chaînes**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **Formats d’objet**:
  - JSON : `{ type: "json", prompt, schema }`
  - Capture d’écran : `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - Suivi des modifications : `{ type: "changeTracking", modes?, prompt?, schema?, tag? }` (nécessite `markdown`)
- **Par défaut**: `["markdown"]`

<div id="full-page-content-vs-main-content-onlymaincontent">
  ### Contenu complet de la page vs contenu principal (`onlyMainContent`)
</div>

- **Type**: `boolean`
- **Description**: Par défaut, le scraper renvoie uniquement le contenu principal. Définissez sur `false` pour renvoyer l’intégralité du contenu de la page.
- **Par défaut**: `true`

<div id="include-tags-includetags">
  ### Balises à inclure (`includeTags`)
</div>

- **Type**: `array`
- **Description**: Balises/classes/ID HTML à inclure dans le scraping.

<div id="exclude-tags-excludetags">
  ### Exclure des balises (`excludeTags`)
</div>

- **Type**: `array`
- **Description**: Balises/classes/IDs HTML à exclure de l'extraction.

<div id="wait-for-page-readiness-waitfor">
  ### Attendre que la page soit prête (`waitFor`)
</div>

- **Type**: `integer`
- **Description**: Nombre de millisecondes à attendre avant le scraping (à utiliser avec parcimonie).
- **Default**: `0`

<div id="freshness-and-cache-maxage">
  ### Fraîcheur et cache (`maxAge`)
</div>

- **Type**: `integer` (millisecondes)
- **Description**: Si une version en cache de la page est plus récente que `maxAge`, Firecrawl la renvoie immédiatement ; sinon, il procède à une nouvelle extraction et met à jour le cache. Définissez `0` pour toujours récupérer une version fraîche.
- **Par défaut**: `172800000` (2 jours)

<div id="request-timeout-timeout">
  ### Délai d’expiration de la requête (`timeout`)
</div>

- **Type**: `integer`
- **Description**: Durée maximale en millisecondes avant l’interruption.
- **Valeur par défaut**: `30000` (30 secondes)

<div id="pdf-parsing-parsers">
  ### Analyse des PDF (`parsers`)
</div>

- **Type**: `array`
- **Description**: Contrôle le comportement d’analyse. Pour traiter des PDF, définissez `parsers: ["pdf"]`.

<div id="actions-actions">
  ### Actions (`actions`)
</div>

Lors de l’utilisation du point de terminaison /scrape, Firecrawl vous permet d’exécuter diverses actions sur une page web avant d’en extraire le contenu. C’est particulièrement utile pour interagir avec du contenu dynamique, naviguer entre des pages ou accéder à du contenu nécessitant une interaction utilisateur.

- **Type**: `array`
- **Description**: Séquence d’étapes du navigateur à exécuter avant l’extraction.
- **Actions prises en charge**:
    - `wait` `{ milliseconds }`
    - `click` `{ selector }`
    - `write` `{ selector, text }`
    - `press` `{ key }`
    - `scroll` `{ direction: "up" | "down" }`
    - `scrape` `{ selector }` (extraire un sous-élément)
    - `executeJavascript` `{ script }`
    - `pdf` (déclencher le rendu PDF dans certains parcours)

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "write", "selector": "#q", "text": "firecrawl" },
      { "type": "press", "key": "Enter" }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

<div id="example-usage">
  ### Exemple d’utilisation
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

Dans cet exemple, le scraper va :

* Renvoyer le contenu complet de la page en Markdown.
* Inclure le Markdown, le HTML brut, le HTML, les liens et une capture d’écran dans la réponse.
* Inclure uniquement les balises HTML `<h1>`, `<p>`, `<a>` et les éléments avec la classe `.main-content`, tout en excluant les éléments avec les ID `#ad` et `#footer`.
* Attendre 1000 millisecondes (1 seconde) avant d’extraire afin de laisser la page se charger.
* Définir la durée maximale de la requête d’extraction à 15000 millisecondes (15 secondes).
* Analyser explicitement les PDF via `parsers: ["pdf"]`.

Voici la référence de l’API : [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


<div id="json-extraction-via-formats">
  ## Extraction JSON via les formats
</div>

Utilisez l’objet de format JSON dans `formats` pour extraire des données structurées en un seul passage :

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "Extraire les fonctionnalités du produit",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```


<div id="extract-endpoint">
  ## Point de terminaison /extract
</div>

Utilisez l’API dédiée aux tâches d’extraction lorsque vous avez besoin d’une extraction asynchrone avec sondage de l’état.

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// Démarrer une tâche d’extraction
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extract title',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// Sondage de l’état
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract title",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extract title",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

<div id="crawling-multiple-pages">
  ## Explorer plusieurs pages
</div>

Pour explorer plusieurs pages, utilisez le point de terminaison `/v2/crawl`.

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLE-API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Renvoie un ID

```json
{ "id": "1234-5678-9101" }
```


<div id="check-crawl-job">
  ### Vérifier une tâche de crawl
</div>

Permet de vérifier l’état d’une tâche de crawl et d’en récupérer le résultat.

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-VOTRE-CLÉ-API'
```


<div id="paginationnext-url">
  #### Pagination/URL suivante
</div>

Si le contenu dépasse 10 Mo ou si la tâche de crawl est encore en cours, la réponse peut inclure un paramètre `next`, une URL vers la page suivante des résultats.

<div id="crawl-prompt-and-params-preview">
  ### Aperçu du prompt et des paramètres de crawl
</div>

Vous pouvez fournir un `prompt` en langage naturel pour permettre à Firecrawl de déterminer les paramètres de crawl. Prévisualisez-les d’abord :

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "Extraire la doc et le blog"
  }'
```


<div id="crawler-options">
  ### Options du crawler
</div>

Lorsque vous utilisez le point de terminaison `/v2/crawl`, vous pouvez ajuster le comportement d’exploration avec :

<div id="includepaths">
  #### includePaths
</div>

- **Type**: `array`
- **Description**: Motifs regex à inclure.
- **Example**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### excludePaths
</div>

- **Type**: `array`
- **Description**: Expressions régulières à exclure.
- **Example**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdiscoverydepth">
  #### maxDiscoveryDepth
</div>

- **Type**: `integer`
- **Description**: Profondeur maximale d’exploration pour découvrir de nouvelles URL.

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: Nombre maximal de pages à explorer.
- **Default**: `10000`

<div id="crawlentiredomain">
  #### crawlEntireDomain
</div>

- **Type**: `boolean`
- **Description**: Explorer via les pages sœurs/parentes pour couvrir l’ensemble du domaine.
- **Default**: `false`

<div id="allowexternallinks">
  #### allowExternalLinks
</div>

- **Type**: `boolean`
- **Description**: Suivre les liens vers des domaines externes.
- **Default**: `false`

<div id="allowsubdomains">
  #### allowSubdomains
</div>

- **Type**: `boolean`
- **Description**: Autoriser le suivi des sous-domaines du domaine principal.
- **Default**: `false`

<div id="delay">
  #### delay
</div>

- **Type**: `number`
- **Description**: Délai en secondes entre les opérations de scraping.
- **Default**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

- **Type**: `object`
- **Description**: Options du scraper (voir Formats ci-dessus).
- **Example**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **Defaults**: `formats: ["markdown"]`, mise en cache activée par défaut (maxAge ~ 2 jours)

<div id="example-usage">
  ### Exemple d’usage
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```


<div id="mapping-website-links">
  ## Cartographier les liens d’un site web
</div>

Le point de terminaison `/v2/map` identifie les URL associées à un site web donné.

<div id="usage">
  ### Utilisation
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-VOTRE-CLÉ D’API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```


<div id="map-options">
  ### Options de mappage
</div>

<div id="search">
  #### search
</div>

- **Type**: `string`
- **Description**: Filtre les liens contenant un texte donné.

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: Nombre maximal de liens à renvoyer.
- **Default**: `100`

<div id="sitemap">
  #### sitemap
</div>

- **Type**: `"only" | "include" | "skip"`
- **Description**: Contrôle l’utilisation du sitemap lors du mappage.
- **Default**: `"include"`

<div id="includesubdomains">
  #### includeSubdomains
</div>

- **Type**: `boolean`
- **Description**: Inclure les sous-domaines du site.
- **Default**: `true`

Voici la référence de l’API correspondante : [Documentation du point de terminaison /map](https://docs.firecrawl.dev/api-reference/endpoint/map)

Merci de votre lecture !