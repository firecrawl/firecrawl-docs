---
title: "Agent"
description: "Gather data wherever it lives on the web. Describe what you want, /agent handles the rest."
og:title: "Agent | Firecrawl"
og:description: "Gather data wherever it lives on the web. Describe what you want, /agent handles the rest."
icon: "magic"
sidebarTitle: "Agent"
---

import AgentPython from "/snippets/v2/agent/base/python.mdx";
import AgentJS from "/snippets/v2/agent/base/js.mdx";
import AgentCURL from "/snippets/v2/agent/base/curl.mdx";
import AgentOutput from "/snippets/v2/agent/base/output.mdx";
import AgentWithSchemaPython from "/snippets/v2/agent/with-schema/python.mdx";
import AgentWithSchemaJS from "/snippets/v2/agent/with-schema/js.mdx";
import AgentWithSchemaCURL from "/snippets/v2/agent/with-schema/curl.mdx";
import AgentWithSchemaOutput from "/snippets/v2/agent/with-schema/output.mdx";
import AgentWithURLsPython from "/snippets/v2/agent/with-urls/python.mdx";
import AgentWithURLsJS from "/snippets/v2/agent/with-urls/js.mdx";
import AgentWithURLsCURL from "/snippets/v2/agent/with-urls/curl.mdx";
import AgentStatusPython from "/snippets/v2/agent/status/python.mdx";
import AgentStatusJS from "/snippets/v2/agent/status/js.mdx";
import AgentStatusCURL from "/snippets/v2/agent/status/curl.mdx";
import AgentStatusPending from "/snippets/v2/agent/status/pending.mdx";
import AgentStatusCompleted from "/snippets/v2/agent/status/completed.mdx";


Firecrawl `/agent` is a magic API that searches, navigates, and gathers data from even the most complex websites, finding data in hard-to-reach places and discovering data anywhere on the internet. It accomplishes in a few minutes what would take a human many hours, and makes traditional web scraping obsolete.

**Just describe what data you want and `/agent` handles the rest.**

<Info>
**Research Preview**: Agent is in early access. Expect rough edges. It will get significantly better over time. [Share feedback â†’](mailto:product@firecrawl.com)
</Info>

Agent builds on everything great about `/extract` and takes it further:

- **No URLs Required**: Just describe what you need via `prompt` parameter. URLs are optional.
- **Deep Web Search**: Autonomously searches and navigates deep into sites to find your data
- **Reliable and Accurate**: Works with a wide variety of queries and use cases
- **Faster**: Processes multiple sources in parallel for quicker results
- **Cheaper**: Agent is more cost-effective than `/extract` for complex use cases

## Using `/agent`

The only required parameter is `prompt`. Simply describe what data you want to extract. For structured output, provide a JSON schema. The SDKs support Pydantic (Python) and Zod (Node) for type-safe schema definitions:

<CodeGroup>

<AgentWithSchemaPython />
<AgentWithSchemaJS />
<AgentWithSchemaCURL />

</CodeGroup>

### Response

<AgentWithSchemaOutput />

## Providing URLs (Optional)

You can optionally provide URLs to focus the agent on specific pages:

<CodeGroup>

<AgentWithURLsPython />
<AgentWithURLsJS />
<AgentWithURLsCURL />

</CodeGroup>



## Job Status and Completion

Agent jobs run asynchronously. When you submit a job, you'll receive a Job ID that you can use to check status:

- **Default method**: `agent()` waits and returns final results
- **Start then poll**: Use `start_agent` (Python) or `startAgent` (Node) to get a Job ID immediately, then poll with `get_agent_status` / `getAgentStatus`

<Note>Job results are available for 24 hours after completion.</Note>

<CodeGroup>

<AgentStatusPython />
<AgentStatusJS />
<AgentStatusCURL />

</CodeGroup>

### Possible States

| Status | Description |
|--------|-------------|
| `processing` | The agent is still working on your request |
| `completed` | Extraction finished successfully |
| `failed` | An error occurred during extraction |

#### Pending Example

<AgentStatusPending />

#### Completed Example

<AgentStatusCompleted />

## Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | **Yes** | Natural language description of the data you want to extract (max 10,000 characters) |
| `urls` | array | No | Optional list of URLs to focus the extraction |
| `schema` | object | No | Optional JSON schema for structured output |

## Agent vs Extract: What's Improved

| Feature | Agent (New) | Extract |
|---------|-------------|---------|
| URLs Required | No | Yes |
| Speed | Faster | Standard |
| Cost | Lower | Standard |
| Reliability | Higher | Standard |
| Query Flexibility | High | Moderate |

## Example Use Cases

- **Research**: "Find the top 5 AI startups and their funding amounts"
- **Competitive Analysis**: "Compare pricing plans between Slack and Microsoft Teams"
- **Data Gathering**: "Extract contact information from company websites"
- **Content Summarization**: "Summarize the latest blog posts about web scraping"

## API Reference

Check out the [Agent API Reference](/api-reference/endpoint/agent) for more details.

Have feedback or need help? Email [help@firecrawl.com](mailto:help@firecrawl.com).

## Pricing

Firecrawl Agent uses **dynamic billing** that scales with the complexity of your data extraction request. You pay based on the actual work Agent performs, ensuring fair pricing whether you're extracting simple data points or complex structured information from multiple sources.

### How Agent pricing works

Agent pricing is **dynamic and credit-based** during Research Preview:

* **Simple extractions** (like contact info from a single page) typically use fewer credits and cost less
* **Complex research tasks** (like competitive analysis across multiple domains) use more credits but reflect the total effort involved
* **Transparent usage** shows you exactly how many credits each request consumed
* **Credit conversion** automatically converts agent credit usage to credits for easy billing

<Info>
  Credit usage varies based on the complexity of your prompt, the amount of data processed, and the structure of the output requested.
</Info>

### Getting started

**All users** receive **5 free daily runs** to explore Agent's capabilities without any cost.

Additional usage is billed based on credit consumption and converted to credits.


### Managing costs

Agent can be expensive, but there are some ways to decrease the cost:

* **Start with free runs**: Use your 5 daily free requests to understand pricing
* **Set a `maxCredits` parameter**: Limit your spending by setting a maximum number of credits you're willing to spend
* **Optimize prompts**: More specific prompts often use fewer credits
* **Monitor usage**: Track your consumption through the dashboard
* **Set expectations**: Complex multi-domain research will use more credits than simple single-page extractions

Try Agent now at [firecrawl.dev/app/agent](https://www.firecrawl.dev/app/agent) to see how credit usage scales with your specific use cases.

<Note>
  Pricing is subject to change as we move from Research Preview to general availability. Current users will receive advance notice of any pricing updates.
</Note>