---
title: Início rápido
description: "O Firecrawl permite transformar sites inteiros em markdown pronto para LLM"
og:title: "Início rápido | Firecrawl"
og:description: "O Firecrawl permite transformar sites inteiros em markdown pronto para LLM"
---

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.jpg" alt="Hero Light" />

<div id="welcome-to-firecrawl">
  ## Bem-vindo ao Firecrawl
</div>

O [Firecrawl](https://firecrawl.dev?ref=github) é um serviço de API que recebe uma URL, a rastreia e a converte em Markdown limpo. Rastreamos todas as subpáginas acessíveis e entregamos Markdown limpo para cada uma. Não é necessário sitemap.

<div id="how-to-use-it">
  ## Como usar?
</div>

Fornecemos uma API fácil de usar com nossa versão hospedada. Você pode acessar o playground e a documentação [aqui](https://firecrawl.dev/playground). Você também pode hospedar o backend por conta própria, se preferir.

Confira os seguintes recursos para começar:

* [x] **API**: [Documentação](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
* [x] **Frameworks de LLM**: [Langchain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low-code**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **Outros**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] Quer um SDK ou integração? Avise-nos abrindo uma issue.

**Self-host:** Para hospedar por conta própria, consulte o guia [aqui](/pt-BR/contributing/self-host).

<div id="api-key">
  ### Chave de API
</div>

Para usar a API, você precisa se inscrever no [Firecrawl](https://firecrawl.dev) e obter uma chave de API.

<div id="crawling">
  ## Rastreamento
</div>

Usado para rastrear uma URL e todas as subpáginas acessíveis. Isso envia uma tarefa de rastreamento e retorna um ID da tarefa para verificar o status do rastreamento.

<div id="installation">
  ### Instalação
</div>

<CodeGroup>
  ```bash Python
  pip install firecrawl-py
  ```

  ```bash JavaScript
  npm install @mendable/firecrawl-js
  ```

  ```bash Go
  go get github.com/mendableai/firecrawl-go
  ```

  ```toml Rust
  # adicione o seguinte ao seu Cargo.toml

  [dependencies]
  firecrawl = "^0.1"
  tokio = { version = "^1", features = ["full"] }
  serde = { version = "^1.0", features = ["derive"] }
  serde_json = "^1.0"
  uuid = { version = "^1.10", features = ["v4"] }

  [build-dependencies]
  tokio = { version = "1", features = ["full"] }
  ```
</CodeGroup>

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  crawl_result = app.crawl_url('docs.firecrawl.dev', {'crawlerOptions': {'excludes': ['blog/*']}})

  # Obter o markdown
  for result in crawl_result:
      print(result['markdown'])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";

  // Inicialize o FirecrawlApp com sua chave de API
  const app = new FirecrawlApp({ apiKey: "YOUR_API_KEY" });

  // Rastreiar um site
  const crawlResult = await app.crawlUrl("docs.firecrawl.dev", {
    crawlerOptions: { excludes: ["blog/*"] },
  });

  // Exibir o markdown no console
  console.log(crawlResult.map((result) => result.markdown));
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    // Inicialize o FirecrawlApp com sua chave de API
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("Falha ao inicializar o FirecrawlApp: %v", err)
    }

    // Rastrear um site
    params := map[string]any{
      "crawlerOptions": map[string]any{
        "excludes": []string{"blog/*"},
      },
    }
    crawlResult, err := app.CrawlURL("docs.firecrawl.dev", params)
    if err != nil {
      log.Fatalf("Ocorreu um erro durante o rastreamento: %v", err)
    }

    // Obter o markdown
    for _, result := range crawlResult {
      fmt.Println(result.Markdown)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
    // Inicialize o FirecrawlApp com a chave de API
    let api_key = "YOUR_API_KEY";
    let api_url = "https://api.firecrawl.dev";
    let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

    // Rastrear a URL
    let crawl_params = json!({
      "crawlerOptions": {
          "excludes": ["blog/*"]
      }
    });

    let crawl_result = app
        .crawl_url("https://example.com", Some(crawl_params), true, 2, None)
        .await;

    // Imprimir o resultado do rastreamento
    match crawl_result {
        Ok(data) => println!("Resultado do rastreamento:\n{}", data),
        Err(e) => eprintln!("Falha no rastreamento: {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/crawl \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

Se você não estiver usando o SDK ou preferir usar webhook ou outro método de polling, defina `wait_until_done` como `false`.
Isso retornará um jobId.

No cURL, /crawl sempre retornará um jobId que você pode usar para verificar o status do rastreamento.

```json
{ "jobId": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### Verificar status do crawl
</div>

Usado para checar o status de um job de crawl e obter seu resultado.

<CodeGroup>
  ```python Python
  status = app.check_crawl_status(job_id)
  ```

  ```js JavaScript
  const status = await app.checkCrawlStatus(jobId);
  ```

  ```go Go
  status, err := app.CheckCrawlStatus(jobId)
  if err != nil {
    log.Fatalf("Failed to check crawl status: %v", err)
  }
  ```

  ```rust Rust
  let status = match app.check_crawl_status(jobId).await {
      Ok(status) => status,
      Err(e) => panic!("Failed to check crawl status: {:?}", e),
  };

  println!("Crawl Status: {:?}", status);
  ```

  ```bash cURL
  curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY'
  ```
</CodeGroup>

<div id="response">
  #### Resposta
</div>

```json
{
  "status": "concluído",
  "current": 22,
  "total": 22,
  "data": [
    {
      "content": "Conteúdo bruto ",
      "markdown": "# Conteúdo em Markdown",
      "provider": "web-scraper",
      "metadata": {
        "title": "Firecrawl | Raspagem confiável da web para seus LLMs",
        "description": "IA para CX e Vendas"
        "language": null,
        "sourceURL": "https://docs.firecrawl.dev/"
      }
    }
  ]
}
```

<div id="scraping">
  ## Scraping
</div>

Para extrair dados de uma única URL, use o método `scrape_url`. Ele recebe a URL como parâmetro e retorna os dados coletados como um dicionário.

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  content = app.scrape_url("https://docs.firecrawl.dev")
  ```

  ```JavaScript JavaScript
  import { FirecrawlApp } from 'firecrawl-js';

  const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

  const content = await app.scrapeUrl('https://docs.firecrawl.dev');
  ```

  ```go Go
  import (
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
    }

    content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
    if err != nil {
      log.Fatalf("Failed to scrape URL: %v", err)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Inicialize o FirecrawlApp com a chave de API
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

      // Faça o scraping da URL
      let scrape_result = app.scrape_url("https://example.com", None).await;

      // Imprima o resultado do scraping
    match scrape_result {
      Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
      Err(e) => eprintln!("Scrape failed: {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

<div id="response">
  ### Resposta
</div>

```json
{
  "success": true,
  "data": {
    "markdown": "<string>",
    "content": "<string>",
    "html": "<string>",
    "rawHtml": "<string>",
    "metadata": {
      "title": "<string>",
      "description": "<string>",
      "language": "<string>",
      "sourceURL": "<string>",
      "<outros metadados>": "<string>",
      "pageStatusCode": 123,
      "pageError": "<string>"
    },
    "llm_extraction": {},
    "warning": "<string>"
  }
}
```

<div id="extraction">
  ## Extração
</div>

Com a extração via LLM, você pode extrair facilmente dados estruturados de qualquer URL. Oferecemos suporte a schemas Pydantic para facilitar seu uso. Veja como utilizá-la:

<CodeGroup>
  ```python Python
  class ArticleSchema(BaseModel):
      title: str
      points: int 
      by: str
      commentsURL: str

  class TopArticlesSchema(BaseModel):
  top: List[ArticleSchema] = Field(..., max_items=5, description="Top 5 notícias")

  data = app.scrape_url('https://news.ycombinator.com', {
  'extractorOptions': {
  'extractionSchema': TopArticlesSchema.model_json_schema(),
  'mode': 'llm-extraction'
  },
  'pageOptions':{
  'onlyMainContent': True
  }
  })
  print(data["llm_extraction"])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";
  import { z } from "zod";

  const app = new FirecrawlApp({
    apiKey: "fc-YOUR_API_KEY",
  });

  // Defina o schema para extrair o conteúdo
  const schema = z.object({
    top: z
      .array(
        z.object({
          title: z.string(),
          points: z.number(),
          by: z.string(),
          commentsURL: z.string(),
        })
      )
      .length(5)
      .describe("Top 5 matérias no Hacker News"),
  });

  const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
    extractorOptions: { extractionSchema: schema },
  });

  console.log(scrapeResult.data["llm_extraction"]);
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  app, err := NewFirecrawlApp(TEST_API_KEY, API_URL)
  if err != nil {
    log.Fatalf("Falha ao inicializar o FirecrawlApp: %v", err)
  }

  params := map[string]any{
    "extractorOptions": ExtractorOptions{
      Mode:             "llm-extraction",
      ExtractionPrompt: "Com base nas informações da página, identifique qual é a missão da empresa, se ela oferece suporte a SSO e se é open source",
      ExtractionSchema: map[string]any{
        "type": "object",
        "properties": map[string]any{
          "company_mission": map[string]string{"type": "string"},
          "supports_sso":    map[string]string{"type": "boolean"},
          "is_open_source":  map[string]string{"type": "boolean"},
        },
        "required": []string{"company_mission", "supports_sso", "is_open_source"},
      },
    },
  }

  scrapeResult, err := app.ScrapeURL("https://news.ycombinator.com", params)
  if err != nil {
    log.Fatalf("Falha ao fazer o scrape da URL: %v", err)
  }
  fmt.Println(scrapeResult.LLMExtraction)
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Inicialize o FirecrawlApp com a chave da API
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

      // Defina o schema para extrair o conteúdo
      let json_schema = json!({
          "type": "object",
          "properties": {
              "top": {
                  "type": "array",
                  "items": {
                      "type": "object",
                      "properties": {
                          "title": {"type": "string"},
                          "points": {"type": "number"},
                          "by": {"type": "string"},
                          "commentsURL": {"type": "string"}
                      },
                      "required": ["title", "points", "by", "commentsURL"]
                  },
                  "minItems": 5,
                  "maxItems": 5,
                  "description": "Top 5 matérias no Hacker News"
              }
          },
          "required": ["top"]
      });

      let llm_extraction_params = json!({
          "extractorOptions": {
              "extractionSchema": json_schema,
              "mode": "llm-extraction"
          },
          "pageOptions": {
              "onlyMainContent": true
          }
      });

      let llm_extraction_result = app
          .scrape_url("https://news.ycombinator.com", Some(llm_extraction_params))
          .await;
      match llm_extraction_result {
          Ok(data) => println!("Resultado da extração por LLM:\n{}", data["llm_extraction"]),
          Err(e) => eprintln!("Falha na extração por LLM: {}", e),
      }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev/",
        "extractorOptions": {
          "mode": "llm-extraction",
          "extractionPrompt": "Com base nas informações da página, extraia os dados conforme o esquema.",
          "extractionSchema": {
            "type": "object",
            "properties": {
              "company_mission": {
                        "type": "string"
              },
              "supports_sso": {
                        "type": "boolean"
              },
              "is_open_source": {
                        "type": "boolean"
              },
              "is_in_yc": {
                        "type": "boolean"
              }
            },
            "required": [
              "company_mission",
              "supports_sso",
              "is_open_source",
              "is_in_yc"
            ]
          }
        }
      }'
  ```
</CodeGroup>

<div id="contributing">
  ## Contribuindo
</div>

Adoramos contribuições! Leia nosso [guia de contribuição](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) antes de enviar um pull request.