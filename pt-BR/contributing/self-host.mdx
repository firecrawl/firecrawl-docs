---
title: "Hospedagem pr√≥pria"
description: "Aprenda a hospedar o Firecrawl por conta pr√≥pria e contribuir com o projeto."
og:title: "Hospedagem pr√≥pria | Firecrawl"
og:description: "Aprenda a hospedar o Firecrawl por conta pr√≥pria e contribuir com o projeto."
---

<div id="contributor">
  #### Vai contribuir?
</div>

Bem-vindo ao [Firecrawl](https://firecrawl.dev) üî•! Aqui est√£o algumas instru√ß√µes para obter o projeto localmente, execut√°-lo por conta pr√≥pria e contribuir.

Se voc√™ for contribuir, observe que o processo √© semelhante ao de outros reposit√≥rios de c√≥digo aberto: fa√ßa um fork do Firecrawl, fa√ßa altera√ß√µes, rode os testes e abra um PR.

Se tiver d√∫vidas ou precisar de ajuda para come√ßar, entre na nossa comunidade no Discord [aqui](https://discord.gg/gSmWdAkdwd) para mais informa√ß√µes ou abra uma issue no GitHub [aqui](https://github.com/mendableai/firecrawl/issues/new/choose)!

<div id="self-hosting-firecrawl">
  ## Hospedando o Firecrawl por conta pr√≥pria
</div>

Consulte [SELF_HOST.md](https://github.com/mendableai/firecrawl/blob/main/SELF_HOST.md) para instru√ß√µes sobre como execut√°-lo localmente.

<div id="why">
  ## Por qu√™?
</div>

Hospedar o Firecrawl por conta pr√≥pria √© especialmente vantajoso para organiza√ß√µes com pol√≠ticas de seguran√ßa rigorosas que exigem manter os dados em ambientes controlados. Aqui est√£o alguns motivos principais para considerar a hospedagem pr√≥pria:

- **Seguran√ßa e conformidade refor√ßadas:** Ao auto-hospedar, voc√™ garante que todo o tratamento e processamento de dados esteja em conformidade com regulamenta√ß√µes internas e externas, mantendo informa√ß√µes sens√≠veis dentro da sua infraestrutura segura. Observe que o Firecrawl √© um produto da Mendable e possui certifica√ß√£o SOC 2 Type II, o que significa que a plataforma segue altos padr√µes do setor para gest√£o da seguran√ßa de dados.
- **Servi√ßos personaliz√°veis:** A hospedagem pr√≥pria permite adaptar servi√ßos, como o Playwright, para atender a necessidades espec√≠ficas ou lidar com casos de uso particulares que podem n√£o ser contemplados pela oferta padr√£o em nuvem.
- **Aprendizado e contribui√ß√£o para a comunidade:** Ao configurar e manter sua pr√≥pria inst√¢ncia, voc√™ obt√©m um entendimento mais profundo de como o Firecrawl funciona, o que tamb√©m pode resultar em contribui√ß√µes mais relevantes para o projeto.

<div id="considerations">
  ### Considera√ß√µes
</div>

No entanto, h√° algumas limita√ß√µes e responsabilidades adicionais das quais voc√™ deve estar ciente:

1. **Acesso limitado ao Fire-engine:** Atualmente, inst√¢ncias auto-hospedadas do Firecrawl n√£o t√™m acesso ao Fire-engine, que inclui recursos avan√ßados para lidar com bloqueios de IP, mecanismos de detec√ß√£o de rob√¥s e mais. Isso significa que, embora voc√™ possa gerenciar tarefas b√°sicas de scraping, cen√°rios mais complexos podem exigir configura√ß√£o adicional ou talvez n√£o sejam suportados.
2. **Configura√ß√£o manual necess√°ria:** Se voc√™ precisar usar m√©todos de scraping al√©m das op√ß√µes b√°sicas de `fetch` e Playwright, ser√° necess√°rio configur√°-los manualmente no arquivo `.env`. Isso exige um entendimento mais profundo das tecnologias e pode demandar mais tempo de configura√ß√£o.

| Capacidade | Cloud | Auto-hospedagem |
| --- | --- | --- |
| Todos os endpoints da API suportados | Sim | Nem sempre; `/agent` n√£o √© suportado em auto-hospedagem |
| Suporte a captura de tela | Sim | Sim, quando o servi√ßo do Playwright estiver em execu√ß√£o |
| LLMs locais (por exemplo, Ollama) | N√£o suportado | Suportado via `OLLAMA_BASE_URL` (experimental) |

Hospedar o Firecrawl por conta pr√≥pria √© ideal para quem precisa de controle total sobre seus ambientes de scraping e processamento de dados, mas tem como contrapartida a necessidade de manuten√ß√£o e configura√ß√µes adicionais.

<div id="steps">
  ## Etapas
</div>

1. Primeiro, instale as depend√™ncias

* Docker [instru√ß√µes](https://docs.docker.com/get-docker/)

2. Configure as vari√°veis de ambiente

Crie um arquivo `.env` no diret√≥rio raiz; voc√™ pode copiar o template em `apps/api/.env.example`

Para come√ßar, n√£o vamos configurar autentica√ß√£o nem quaisquer subservi√ßos opcionais (an√°lise de PDF, bloqueio de JS, recursos de IA)

```
# .env

# ===== Required ENVS ======
PORT=3002
HOST=0.0.0.0

# Note: PORT is used by both the main API server and worker liveness check endpoint

# To turn on DB authentication, you need to set up Supabase.
USE_DB_AUTHENTICATION=false

# ===== Optional ENVS ======

## === AI features (JSON format on scrape, /extract API) ===
# Provide your OpenAI API key here to enable AI features
# OPENAI_API_KEY=

# Experimental: Use Ollama
# OLLAMA_BASE_URL=http://localhost:11434/api
# MODEL_NAME=deepseek-r1:7b
# MODEL_EMBEDDING_NAME=nomic-embed-text

# Experimental: Use any OpenAI-compatible API
# OPENAI_BASE_URL=https://example.com/v1
# OPENAI_API_KEY=

## === Proxy ===
# PROXY_SERVER can be a full URL (e.g. http://0.1.2.3:1234) or just an IP and port combo (e.g. 0.1.2.3:1234)
# Do not uncomment PROXY_USERNAME and PROXY_PASSWORD if your proxy is unauthenticated
# PROXY_SERVER=
# PROXY_USERNAME=
# PROXY_PASSWORD=

## === /search API ===

# Voc√™ pode especificar um servidor SearXNG com o formato JSON habilitado, se quiser usar isso em vez do Google direto.
# Voc√™ tamb√©m pode personalizar os par√¢metros engines e categories, mas os padr√µes tamb√©m devem funcionar bem.
# SEARXNG_ENDPOINT=http://your.searxng.server
# SEARXNG_ENGINES=
# SEARXNG_CATEGORIES=

## === Other ===

# Supabase Setup (used to support DB authentication, advanced logging, etc.)
# SUPABASE_ANON_TOKEN=
# SUPABASE_URL=
# SUPABASE_SERVICE_TOKEN=

# Use if you've set up authentication and want to test with a real API key
# TEST_API_KEY=

# This key lets you access the queue admin panel. Change this if your deployment is publicly accessible.
BULL_AUTH_KEY=CHANGEME

# This is now autoconfigured by the docker-compose.yaml. You shouldn't need to set it.
# PLAYWRIGHT_MICROSERVICE_URL=http://playwright-service:3000/scrape
# REDIS_URL=redis://redis:6379
# REDIS_RATE_LIMIT_URL=redis://redis:6379

# Set if you have a llamaparse key you'd like to use to parse pdfs
# LLAMAPARSE_API_KEY=

# Set if you'd like to send server health status messages to Slack
# SLACK_WEBHOOK_URL=

# Set if you'd like to send posthog events like job logs
# POSTHOG_API_KEY=
# POSTHOG_HOST=

## === System Resource Configuration ===
# Maximum CPU usage threshold (0.0-1.0). Worker will reject new jobs when CPU usage exceeds this value.
# Default: 0.8 (80%)
# MAX_CPU=0.8

# Maximum RAM usage threshold (0.0-1.0). Worker will reject new jobs when memory usage exceeds this value.
# Default: 0.8 (80%)
# MAX_RAM=0.8

# Set if you'd like to allow local webhooks to be sent to your self-hosted instance
# ALLOW_LOCAL_WEBHOOKS=true
```

<Note>
  Os seguintes recursos de IA exigem um provedor de LLM configurado (por exemplo, `OPENAI_API_KEY` ou alternativas na se√ß√£o de recursos de IA acima):

  * Formato JSON na raspagem
  * API /extract
  * Formato de resumo
  * Formato de branding
  * Formato de monitoramento de altera√ß√µes
</Note>

3. *(Opcional) Executar com o TypeScript Playwright Service*

   * Atualize o arquivo `docker-compose.yml` para alterar o servi√ßo do Playwright:

     ```plaintext
         build: apps/playwright-service
     ```

     PARA

     ```plaintext
         build: apps/playwright-service-ts
     ```

   * Defina `PLAYWRIGHT_MICROSERVICE_URL` no arquivo `.env`:

     ```plaintext
     PLAYWRIGHT_MICROSERVICE_URL=http://localhost:3000/scrape
     ```

   * N√£o se esque√ßa de configurar o servidor proxy no arquivo `.env`, conforme necess√°rio.

4. Compile e execute os cont√™ineres Docker:

   ```bash
   docker compose build
   docker compose up
   ```

Isso iniciar√° uma inst√¢ncia local do Firecrawl, acess√≠vel em `http://localhost:3002`.

Voc√™ deve conseguir ver a interface do Bull Queue Manager em `http://localhost:3002/admin/{BULL_AUTH_KEY}/queues`.

5. *(Opcional)* Teste a API

Se voc√™ quiser testar o endpoint de crawl, pode executar o seguinte:

```bash
  curl -X POST http://localhost:3002/v2/crawl \
      -H 'Content-Type: application/json' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
```


<div id="troubleshooting">
  ## Resolu√ß√£o de problemas
</div>

Esta se√ß√£o apresenta solu√ß√µes para problemas comuns que voc√™ pode encontrar ao configurar ou executar sua inst√¢ncia self-hosted do Firecrawl.

<div id="supabase-client-is-not-configured">
  ### O cliente Supabase n√£o est√° configurado
</div>

**Sintoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Tentativa de acessar o cliente do Supabase quando ele n√£o est√° configurado.
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Erro ao inserir evento de scraping: Erro: o cliente do Supabase n√£o est√° configurado.
```

**Explica√ß√£o:**
Esse erro ocorre porque a configura√ß√£o do cliente do Supabase n√£o foi conclu√≠da. Voc√™ deve conseguir executar scraping e crawling sem problemas. No momento, n√£o √© poss√≠vel configurar o Supabase em inst√¢ncias auto-hospedadas.

<div id="youre-bypassing-authentication">
  ### Voc√™ est√° ignorando a autentica√ß√£o
</div>

**Sintoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]WARN - You're bypassing authentication
```

**Explica√ß√£o:**
Esse erro ocorre porque a configura√ß√£o do cliente do Supabase n√£o foi conclu√≠da. Voc√™ ainda consegue fazer scraping e crawling sem problemas. No momento, n√£o √© poss√≠vel configurar o Supabase em inst√¢ncias self-hosted.


<div id="docker-containers-fail-to-start">
  ### Falha ao iniciar cont√™ineres Docker
</div>

**Sintoma:**
Os cont√™ineres Docker s√£o encerrados inesperadamente ou n√£o iniciam.

**Solu√ß√£o:**
Verifique os logs do Docker em busca de mensagens de erro usando o comando:

```bash
docker logs [container_name]
```

* Certifique-se de que todas as vari√°veis de ambiente necess√°rias estejam configuradas corretamente no arquivo .env.
* Verifique se todos os servi√ßos Docker definidos em docker-compose.yml est√£o configurados corretamente e se as imagens necess√°rias est√£o dispon√≠veis.


<div id="connection-issues-with-redis">
  ### Problemas de conex√£o com o Redis
</div>

**Sintoma:**
Erros relacionados √† conex√£o com o Redis, como timeouts ou "Connection refused".

**Solu√ß√£o:**

- Certifique-se de que o servi√ßo Redis est√° em execu√ß√£o no seu ambiente Docker.
- Verifique se as vari√°veis REDIS_URL e REDIS_RATE_LIMIT_URL no seu arquivo .env apontam para a inst√¢ncia Redis correta.
- Verifique as configura√ß√µes de rede e as regras de firewall que possam estar bloqueando a conex√£o com a porta do Redis.

<div id="api-endpoint-does-not-respond">
  ### O endpoint da API n√£o responde
</div>

**Sintoma:**
As requisi√ß√µes de API para a inst√¢ncia do Firecrawl esgotam o tempo (timeout) ou n√£o retornam resposta.

**Solu√ß√£o:**

- Verifique se o servi√ßo do Firecrawl est√° em execu√ß√£o conferindo o status do cont√™iner Docker.
- Confirme se as vari√°veis PORT e HOST no arquivo .env est√£o corretas e se nenhum outro servi√ßo est√° usando a mesma porta.
- Verifique a configura√ß√£o de rede para garantir que o host esteja acess√≠vel a partir do cliente que faz a requisi√ß√£o de API.

Ao corrigir esses problemas comuns, voc√™ garante uma configura√ß√£o e opera√ß√£o mais est√°veis da sua inst√¢ncia autogerenciada do Firecrawl.

<div id="install-firecrawl-on-a-kubernetes-cluster-simple-version">
  ## Instalar o Firecrawl em um cluster do Kubernetes (vers√£o simples)
</div>

Leia o [examples/kubernetes-cluster-install/README.md](https://github.com/firecrawl/firecrawl/tree/main/examples/kubernetes/cluster-install#readme) para obter instru√ß√µes sobre como instalar o Firecrawl em um cluster do Kubernetes.