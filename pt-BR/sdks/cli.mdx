---
title: 'CLI'
description: 'Firecrawl CLI é uma interface de linha de comando para fazer scraping, crawling, mapeamento e busca na web diretamente no seu terminal.'
icon: 'terminal'
og:title: "CLI | Firecrawl"
og:description: "Firecrawl CLI é uma interface de linha de comando para fazer scraping, crawling, mapeamento e busca na web diretamente no seu terminal."
---

import InstallationCLI from '/snippets/pt-BR/v2/cli/installation/bash.mdx'
import AuthLogin from '/snippets/pt-BR/v2/cli/auth/login.mdx'
import AuthLogout from '/snippets/pt-BR/v2/cli/auth/logout.mdx'
import AuthConfig from '/snippets/pt-BR/v2/cli/auth/config.mdx'
import ScrapeBasic from '/snippets/pt-BR/v2/cli/scrape/basic.mdx'
import ScrapeFormats from '/snippets/pt-BR/v2/cli/scrape/formats.mdx'
import ScrapeOptions from '/snippets/pt-BR/v2/cli/scrape/options.mdx'
import CrawlBasic from '/snippets/pt-BR/v2/cli/crawl/basic.mdx'
import CrawlStatus from '/snippets/pt-BR/v2/cli/crawl/status.mdx'
import CrawlOptions from '/snippets/pt-BR/v2/cli/crawl/options.mdx'
import MapBasic from '/snippets/pt-BR/v2/cli/map/basic.mdx'
import MapOptions from '/snippets/pt-BR/v2/cli/map/options.mdx'
import SearchBasic from '/snippets/pt-BR/v2/cli/search/basic.mdx'
import SearchOptions from '/snippets/pt-BR/v2/cli/search/options.mdx'


<div id="installation">
  ## Instalação
</div>

Instale globalmente a CLI do Firecrawl com npm:

<InstallationCLI />

Se você estiver usando em algum agente de IA, como o Claude Code, poderá instalar a skill com:

```bash
npx skills add firecrawl/cli
```


<div id="authentication">
  ## Autenticação
</div>

Antes de usar a CLI, você precisa autenticar-se com sua chave de API do Firecrawl.

<div id="login">
  ### Login
</div>

<AuthLogin />

<div id="view-configuration">
  ### Visualizar configuração
</div>

<AuthConfig />

<div id="logout">
  ### Logout
</div>

<AuthLogout />

<div id="commands">
  ## Comandos
</div>

<div id="scrape">
  ### Scrape
</div>

Faça scraping de uma única URL e extraia seu conteúdo em vários formatos.

<ScrapeBasic />

<div id="output-formats">
  #### Formatos de saída
</div>

<ScrapeFormats />

<div id="scrape-options">
  #### Opções de Scrape
</div>

<ScrapeOptions />

**Opções disponíveis:**

| Opção | Atalho | Descrição |
|--------|-------|-------------|
| `--url <url>` | `-u` | URL para extrair conteúdo (alternativa ao argumento posicional) |
| `--format <formats>` | `-f` | formatos de saída (separados por vírgula): `markdown`, `html`, `rawHtml`, `links`, `images`, `screenshot`, `json` |
| `--html` | `-H` | Atalho para `--format html` |
| `--only-main-content` | | Extrair apenas o conteúdo principal |
| `--wait-for <ms>` | | Tempo de espera, em milissegundos, para renderização de JS |
| `--screenshot` | | Fazer uma captura de tela |
| `--include-tags <tags>` | | Tags HTML a incluir (separadas por vírgula) |
| `--exclude-tags <tags>` | | Tags HTML a excluir (separadas por vírgula) |
| `--output <path>` | `-o` | Salvar o resultado em um arquivo |
| `--pretty` | | Imprimir a saída JSON formatada |

---

<div id="crawl">
  ### Crawl
</div>

Rastreia um site inteiro a partir de uma URL.

<CrawlBasic />

<div id="check-crawl-status">
  #### Verificar status do crawl
</div>

<CrawlStatus />

<div id="crawl-options">
  #### Opções de Crawl
</div>

<CrawlOptions />

**Opções disponíveis:**

| Opção | Descrição |
|--------|-------------|
| `--url <url>` | URL para rastrear (alternativa ao argumento posicional) |
| `--wait` | Aguardar a conclusão do crawl |
| `--progress` | Mostrar indicador de progresso enquanto aguarda |
| `--poll-interval <seconds>` | Intervalo de consulta (polling) (padrão: 5) |
| `--timeout <seconds>` | Tempo limite ao aguardar |
| `--status` | Verificar o status de uma tarefa de crawl existente |
| `--limit <number>` | Número máximo de páginas a rastrear |
| `--max-depth <number>` | Profundidade máxima do crawl |
| `--include-paths <paths>` | Caminhos a incluir (separados por vírgula) |
| `--exclude-paths <paths>` | Caminhos a excluir (separados por vírgula) |
| `--allow-subdomains` | Incluir subdomínios |
| `--allow-external-links` | Seguir links externos |
| `--output <path>` | Salvar resultado em arquivo |
| `--pretty` | Imprimir saída JSON formatada |

---

<div id="map">
  ### Mapear
</div>

Descubra rapidamente todas as URLs de um site.

<MapBasic />

<div id="map-options">
  #### Opções do Map
</div>

<MapOptions />

**Opções disponíveis:**

| Opção | Descrição |
|--------|-------------|
| `--url <url>` | URL a ser mapeada (alternativa ao argumento posicional) |
| `--limit <number>` | Número máximo de URLs a serem descobertas |
| `--search <query>` | Filtra URLs pela consulta de busca |
| `--sitemap <mode>` | Tratamento de sitemap: `include`, `skip`, `only` |
| `--include-subdomains` | Inclui subdomínios |
| `--ignore-query-parameters` | Trata URLs com parâmetros diferentes como iguais |
| `--json` | Saída em JSON |
| `--output <path>` | Salva a saída em um arquivo |
| `--pretty` | Imprime a saída JSON formatada |

---

<div id="search">
  ### Pesquisar
</div>

Pesquise na web e, opcionalmente, faça o scraping dos resultados.

<SearchBasic />

<div id="search-options">
  #### Opções de busca
</div>

<SearchOptions />

**Opções disponíveis:**

| Opção | Descrição |
|--------|-------------|
| `--limit <number>` | Número máximo de resultados (padrão: 5, máx.: 100) |
| `--sources <sources>` | Fontes de pesquisa: `web`, `images`, `news` (separadas por vírgula) |
| `--categories <categories>` | Filtrar por categoria: `github`, `research`, `pdf` (separadas por vírgula) |
| `--tbs <value>` | Filtro de tempo: `qdr:h` (hora), `qdr:d` (dia), `qdr:w` (semana), `qdr:m` (mês), `qdr:y` (ano) |
| `--location <location>` | Segmentação geográfica (ex.: "Berlin,Germany") |
| `--country <code>` | Código de país ISO (padrão: US) |
| `--scrape` | Fazer scraping dos resultados da pesquisa |
| `--scrape-formats <formats>` | Formatos para o conteúdo extraído (padrão: markdown) |
| `--only-main-content` | Incluir apenas o conteúdo principal ao fazer scraping |
| `--json` | Saída em JSON |
| `--output <path>` | Salvar saída em arquivo |
| `--pretty` | Imprimir saída JSON formatada |

---

<div id="credit-usage">
  ### Uso de créditos
</div>

Verifique o saldo de créditos e o uso pela sua equipe.

```bash CLI
# Ver uso de créditos
firecrawl credit-usage

# Saída em JSON
firecrawl credit-usage --json --pretty
```

***


<div id="version">
  ### Versão
</div>

Exibe a versão da CLI.

```bash CLI
firecrawl version
# ou
firecrawl --version
```


<div id="global-options">
  ## Opções globais
</div>

Essas opções estão disponíveis para todos os comandos:

| Opção | Atalho | Descrição |
|--------|-------|-------------|
| `--api-key <key>` | `-k` | Substitui a chave de API armazenada para este comando |
| `--help` | `-h` | Exibe a ajuda de um comando |
| `--version` | `-V` | Exibe a versão da CLI |

<div id="output-handling">
  ## Manipulação da saída
</div>

A CLI envia a saída para stdout por padrão, facilitando o uso de pipes ou redirecionamentos:

```bash CLI
# Pipe markdown para outro comando
firecrawl https://example.com | head -50

# Redirecionar para um arquivo
firecrawl https://example.com > output.md

# Salvar JSON com formatação legível
firecrawl https://example.com --format markdown,links --pretty -o data.json
```


<div id="examples">
  ## Exemplos
</div>

<div id="quick-scrape">
  ### Raspagem rápida
</div>

```bash CLI
# Obter conteúdo markdown de uma URL
firecrawl https://docs.firecrawl.dev

# Get HTML content
firecrawl https://example.com --html -o page.html
```


<div id="full-site-crawl">
  ### Rastreamento completo do site
</div>

```bash CLI
# Rastreia um site de docs com limites
firecrawl crawl https://docs.example.com --limit 50 --max-depth 2 --wait --progress -o docs.json
```


<div id="site-discovery">
  ### Descoberta de sites
</div>

```bash CLI
# Encontre todas as postagens do blog
firecrawl map https://example.com --search "blog" -o blog-urls.txt
```


<div id="research-workflow">
  ### Fluxo de Pesquisa
</div>

```bash CLI
# Buscar e raspar resultados para pesquisa
firecrawl search "machine learning best practices 2024" --scrape --scrape-formats markdown --pretty
```
