---
title: 'LlamaIndex'
description: 'O Firecrawl integra-se ao LlamaIndex como leitor de documentos.'
og:title: "LlamaIndex | Firecrawl"
og:description: "O Firecrawl integra-se ao LlamaIndex como leitor de documentos."
---

> Observação: esta integração ainda usa a [versão v0 da API do Firecrawl](/pt-BR/v0/introduction). Você pode instalar a versão 0.0.20 do SDK para Python ou a 0.0.36 do SDK para Node.

<div id="installation">
  ## Instalação
</div>

```bash
pip install firecrawl-py==0.0.20 llama_index llama-index llama-index-readers-web

```

<div id="usage">
  ## Uso
</div>

<div id="using-firecrawl-to-gather-an-entire-website">
  ### Usando o Firecrawl para coletar um site inteiro
</div>

```python
from llama_index.readers.web import FireCrawlWebReader
from llama_index.core import SummaryIndex
import os


# Inicialize o FireCrawlWebReader para rastrear um site
firecrawl_reader = FireCrawlWebReader(
    api_key="<your_api_key>",  # Substitua pela sua chave de API em https://www.firecrawl.dev/
    mode="scrape",  # Escolha entre "crawl" e "scrape" para extrair uma única página
    params={"additional": "parameters"}  # Parâmetros adicionais opcionais
)

# Defina a variável de ambiente para a chave da API
os.environ["OPENAI_API_KEY"] = "<OPENAI_API_KEY>"

# Carregue documentos de uma única URL
documents = firecrawl_reader.load_data(url="http://paulgraham.com/")
index = SummaryIndex.from_documents(documents)

# Ajuste o nível de log para DEBUG para obter saídas mais detalhadas
query_engine = index.as_query_engine()
response = query_engine.query("O que o autor fez quando estava crescendo?")
display(Markdown(f"<b>{response}</b>"))
```

<div id="using-firecrawl-to-gather-a-single-page">
  ### Usando o Firecrawl para coletar uma única página
</div>

```python
from llama_index.readers.web import FireCrawlWebReader

# Inicialize o FireCrawlWebReader com sua chave de API e o modo desejado
firecrawl_reader = FireCrawlWebReader(
    api_key="<your_api_key>",  # Substitua pela sua chave de API em https://www.firecrawl.dev/
    mode="scrape",  # Escolha entre "crawl" e "scrape"
    params={"additional": "parameters"}  # Parâmetros adicionais opcionais
)

# Carregue documentos de uma URL específica
documents = firecrawl_reader.load_data(url="http://paulgraham.com/worked.html")
index = SummaryIndex.from_documents(documents)

# Defina o nível de log como DEBUG para obter saídas mais detalhadas
query_engine = index.as_query_engine()
response = query_engine.query("O que o autor fazia quando estava crescendo?")
display(Markdown(f"<b>{response}</b>"))
```
