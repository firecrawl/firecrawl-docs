---
title: "Usando Extração com LLM para Insights de Clientes"
description: "Usando Extração com LLM para insights e geração de leads com Make e Firecrawl."
og:title: "Usando Extração com LLM para Insights de Clientes | Firecrawl"
og:description: "Usando Extração com LLM para insights e geração de leads com Make e Firecrawl."
---

> Observação: este exemplo usa a [versão v0 da API do Firecrawl](/pt-BR/v0/introduction). Você pode instalar a versão 0.0.20 do SDK para Python ou a 0.0.36 do SDK para Node.

<div id="introduction">
  ### Introdução
</div>

Entender nossos clientes — não apenas quem eles são, mas o que fazem — é crucial para adequar nossos produtos e serviços de forma eficaz. Ao operar um modelo self-serve, muitos clientes chegam com pouco ou nenhum conhecimento prévio da nossa parte. O processo de compreender proativamente quem são essas pessoas tradicionalmente consome muito tempo, exigindo coleta e análise manual de dados para gerar insights acionáveis.

No entanto, com o poder dos LLMs e sua capacidade de extração avançada de dados, automatizamos esse processo. Usando LLMs para extrair e analisar dados de clientes, reduzimos significativamente nossa carga de trabalho, permitindo entender e atender nossa base de clientes de forma mais eficaz do que nunca.

Se você tem conhecimento técnico limitado, pode criar uma automação para obter informações específicas sobre seus clientes com fins de direcionamento de produto e geração de leads. Veja como você mesmo pode fazer isso com o [Make](https://make.com/) e o [Firecrawl](https://www.firecrawl.dev/).

***

<div id="overview-of-the-tools">
  ### Visão geral das ferramentas
</div>

**Firecrawl**

Firecrawl é uma plataforma de scraping, busca e extração. Ela permite capturar dados da web e convertê-los em markdown legível por LLM ou em dados estruturados.

Quando queremos obter informações sobre nossos clientes, podemos usar a funcionalidade de extração com LLM do Firecrawl para especificar exatamente quais dados queremos dos sites deles.

**Make.com (antigo Integromat)**

Make é uma plataforma de automação que permite criar fluxos de trabalho personalizados para conectar diversos apps e serviços sem exigir conhecimento técnico avançado. Ela usa uma interface visual em que os usuários podem arrastar e soltar elementos para desenhar suas automações.

Podemos usar o Make para conectar uma planilha com dados de usuários ao Firecrawl, permitindo realizar extrações com apenas um pouco de JSON.

<div id="preparing-our-data">
  ### Configurando o cenário
</div>

* Guia passo a passo para configurar o processo de extração de dados.
* **Conectando o Google Sheets ao Make.com**
  * Como os dados dos usuários são inicialmente coletados e armazenados.
* **Configurando a requisição HTTP no Make.com**
  * Descrição de como configurar requisições de API para o Firecrawl.
  * Finalidade dessas requisições (por exemplo, extrair informações da empresa).

### Preparando nossos dados

Antes de começarmos, queremos garantir que nossos dados estejam prontos para o Firecrawl. Neste caso, criei uma planilha simples com usuários importados do nosso banco de dados. Queremos pegar os domínios de e-mail dos nossos usuários e transformá-los em links no formato https://:

![](https://i.imgur.com/gssynZa.png)

Também queremos adicionar alguns atributos que gostaríamos de saber sobre essas empresas. No meu caso, quero entender um pouco sobre a empresa, seu setor e seus clientes. Defini estes em colunas como:
company&#95;description
company&#95;type
who&#95;they&#95;serve

Agora que nossos dados estão preparados, podemos começar a configurar nossa automação no Make!

## Configurando a nossa automação

Para colocar nossa automação em funcionamento, basta seguir um processo de três etapas no Make. Aqui, vamos escolher três apps no nosso cenário:

Google Sheets - Obter valores de um intervalo
HTTP - Fazer uma requisição com autenticação por chave de API
Google Sheets - Atualizar uma linha

Também vamos adicionar a ferramenta de ignorar controle de fluxo caso encontremos algum erro. Isso manterá a automação em execução.

![](https://i.imgur.com/MdCWv30.png)

Esta automação permitirá que a gente extraia um conjunto de links da nossa planilha, os envie ao Firecrawl para extração de dados e depois preencha novamente nossa planilha com as informações desejadas.

Vamos começar configurando nosso primeiro app. Nosso objetivo é exportar todas as URLs para enviá-las ao Firecrawl para extração. Aqui está a configuração para obter essas URLs:

![](https://i.imgur.com/WHa91kY.png)

**Importante* - queremos garantir que começaremos a extrair os dados a partir da segunda linha. Se você incluir o cabeçalho, acabará encontrando um erro.

***

Ótimo! Agora que isso está configurado, vamos preparar nossa solicitação HTTP. Para isso, acesse https://firecrawl.dev para se cadastrar e obter sua chave de API (você pode começar gratuitamente!). Depois de se cadastrar, vá a https://firecrawl.dev/account para ver sua chave de API.

Usaremos o endpoint /scrape do Firecrawl. Esse endpoint nos permitirá obter informações de uma única URL, convertê-las em markdown limpo e usá-las para extrair os dados de que precisamos. Vou preencher todas as condições necessárias na nossa requisição HTTP no Make usando a referência da API na documentação.

Agora, no Make, configuro a chamada à API seguindo a documentação do Firecrawl. Usaremos POST como método HTTP e incluiremos dois cabeçalhos.

```
Cabeçalho 1:
Nome: Authorization
Valor: Bearer sua chave de API

Cabeçalho 2:
Nome: Content-Type
Valor: application/json
```

![](https://i.imgur.com/LJ8g142.png)
Também queremos definir o corpo e os tipos de conteúdo. Aqui faremos:

```
Tipo de corpo: Raw
Tipo de conteúdo: JSON (application/json)
```

Também vamos clicar em “sim” para fazer o parsing da nossa resposta. Isso irá convertê-la automaticamente para JSON.

O conteúdo da solicitação é o elemento central do que queremos alcançar. Aqui está o conteúdo da solicitação que usaremos neste caso de uso:

```
{
  "url": "1. url(B)",

"pageOptions": {
    "onlyMainContent": true
  },
  "extractorOptions": {
    "mode": "llm-extraction",
    "extractionPrompt": "Extraia a descrição da empresa (em uma frase, explique o que a empresa faz), o setor da empresa (software, serviços, IA etc.) — isso deve ser apenas uma tag com algumas palavras-chave — e quem ela atende (quem são seus clientes). Se não houver informações claras para responder à pergunta, escreva 'sem info'.",
    "extractionSchema": {
      "type": "object",
      "properties": {
        "company_description": {
          "type": "string"
        },
        "company_industry": {
          "type": "string"
        },
        "who_they_serve": {
          "type": "string"
        }
      },
      "required": [
        "company_description",
        "company_industry",
        "who_they_serve"
      ]
    }
  }
}
```

![](https://i.imgur.com/DrMc1g2.png)

**Observação*: o campo verde na captura de tela é um item dinâmico que você pode selecionar na interface do Make. Em vez de `url (B)`, o bloco pode ser a primeira URL nos seus dados.

![](https://i.imgur.com/D4HCBNe.png)

Fantástico! Agora que configuramos nossa requisição HTTP, vamos testá-la para garantir que tudo esteja funcionando como deveria. Clique em “Run once” no Make e você deverá receber os dados de volta.

![](https://i.imgur.com/QuQZs0U.png)

Ao executar, vamos conferir nossa primeira operação. Na saída, devemos ver um `status code: 200`, indicando que nossa solicitação à API foi bem-sucedida. Na saída, clique em data para confirmar que obtivemos os dados necessários.

![](https://i.imgur.com/pm614VA.png)

Nosso resultado parece bem-sucedido! Em llm&#95;extraction, estamos vendo os três atributos de dados que queríamos do site.

**Observação* se você estiver recebendo um erro `500` na primeira operação e respostas `200` nas seguintes, isso pode ocorrer porque a operação está sendo executada na primeira linha dos seus dados (a linha de cabeçalho). Isso causará problemas ao importar os dados de volta para a planilha! Certifique-se de começar a partir da segunda linha, como mencionado antes.

Agora que sabemos que a requisição HTTP está funcionando corretamente, basta pegar o JSON gerado pelo Firecrawl e colocá-lo de volta na nossa planilha.

***

Agora precisamos pegar os dados extraídos e devolvê-los à planilha. Para isso, vamos usar o JSON retornado pela nossa requisição HTTP e exportar o texto para as tabelas relevantes.

Vamos começar conectando a mesma planilha do Google e definindo o critério de Número da linha. Aqui, vamos simplesmente usar a interface do Make para escolher “row number”.

![](https://i.imgur.com/BYpPabk.png)

Resta apenas especificar quais dados extraídos pelo LLM vão para quais colunas. Aqui, podemos simplesmente usar a interface do Make para configurar isso.

![](https://i.imgur.com/219tft2.png)

Pronto — agora é hora de testar nossa automação!

***

Vamos clicar em `run once` na interface do Make e garantir que tudo esteja funcionando bem. A automação deve começar a iterar link por link e preencher nossa planilha em tempo real.

![](https://i.imgur.com/vU1CJlt.png)

Sucesso! Usando o Make e o Firecrawl, conseguimos extrair informações específicas sobre nossos clientes sem precisar visitar manualmente cada um de seus sites.

Observando os dados, estamos começando a entender melhor nossos clientes. No entanto, não estamos limitados a essas características específicas. Se quisermos, podemos personalizar nosso JSON e o Prompt de Extração para descobrir outras informações sobre essas empresas.

<div id="going-a-step-further">
  ### Casos de uso
</div>

A extração com LLM permite obter rapidamente informações específicas da web relevantes para o nosso negócio. Podemos usar essas automações para executar uma variedade de tarefas.

**Produto:**
Especialmente para empresas self-serve, podemos entender as tendências nos setores que usam nosso produto. Quais são os 2–3 principais setores usando nossa tecnologia e para que a utilizam? Isso nos permitirá tomar melhores decisões de produto, priorizando os clientes certos em que focar.

**Desenvolvimento de negócios:**
Ao entender quem são nossos usuários, podemos buscar empresas semelhantes que também possam se beneficiar do nosso produto. Ao fazer uma automação semelhante, podemos extrair sinais/indicadores positivos de potenciais clientes que se beneficiariam do nosso produto.

Também podemos usar esses dados para gerar e-mails de outreach melhores e mais específicos para cada potencial cliente.

**Pesquisa de mercado:**
Empresas de pesquisa de mercado gastam muito tempo fazendo pesquisa secundária, especialmente em setores de nicho. Podemos agilizar a coleta de dados automatizando a extração e a organização de dados de fontes diversas. Essa automação ajuda a aumentar a eficiência e a escalar conforme as necessidades de dados crescem, tornando-se uma ferramenta valiosa para a tomada de decisões estratégicas em setores que evoluem rapidamente.

### Indo um passo além

Este foi apenas um exemplo simples de como usar LLMs para extrair dados relevantes de sites a partir de uma planilha estática. Você pode tornar isso mais avançado conectando-o dinamicamente aos seus cadastros. Além disso, é possível integrar com outras ferramentas para impulsionar ainda mais a produtividade. Por exemplo, usar o conteúdo extraído para gerar textos mais personalizados para prospecção.

Se você achou isto útil, fique à vontade para me avisar! Vou adorar receber seu feedback ou saber no que você está trabalhando. Você pode me contatar em eric@mendable.ai. Boa sorte e boas construções!