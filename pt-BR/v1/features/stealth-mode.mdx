---
title: "Modo furtivo"
description: "Use proxies furtivos para sites com soluções avançadas de anti-bot"
og:title: "Modo furtivo | Firecrawl"
og:description: "Use proxies furtivos para sites com soluções avançadas de anti-bot"
---

import ProxyPython from "/snippets/pt-BR/v1/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/pt-BR/v1/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/pt-BR/v1/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/pt-BR/v1/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/pt-BR/v1/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/pt-BR/v1/scrape/proxy-retry/curl.mdx";

O Firecrawl oferece diferentes tipos de proxy para ajudar você a extrair dados de sites com diversos níveis de proteção anti-bot. O tipo de proxy pode ser especificado usando o parâmetro `proxy`.


<div id="proxy-types">
  ### Tipos de proxy
</div>

Firecrawl oferece suporte a três tipos de proxy:

- **basic**: Proxies para scraping em sites sem ou com soluções anti-bot básicas. Rápido e geralmente funciona.
- **stealth**: Proxies stealth para scraping em sites com soluções anti-bot avançadas. Mais lento, mas mais confiável em certos sites.
- **auto**: O Firecrawl tentará automaticamente novamente usando proxies stealth se o proxy basic falhar. Se a nova tentativa com stealth for bem-sucedida, 5 créditos serão cobrados pelo scraping. Se a primeira tentativa com basic for bem-sucedida, apenas o custo padrão será cobrado.

Se você não especificar um proxy, o Firecrawl usará basic por padrão.

<div id="using-stealth-mode">
  ### Usando o modo stealth
</div>

Ao fazer scraping de sites com proteção avançada contra bots, você pode usar o modo de proxy stealth para aumentar sua taxa de sucesso.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Observação:** A partir de 8 de maio, as solicitações com proxy stealth custam 5 créditos por requisição.

<div id="using-stealth-as-a-retry-mechanism">
  ## Usando o modo stealth como mecanismo de nova tentativa
</div>

Um padrão comum é primeiro tentar o scraping com as configurações de proxy padrão e, depois, repetir a tentativa com o modo stealth se você encontrar códigos de status específicos (401, 403 ou 500) no campo `metadata.statusCode` da resposta. Esses códigos podem indicar que o site está bloqueando sua requisição.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Essa abordagem ajuda a otimizar o uso de créditos, acionando o modo stealth apenas quando necessário.