---
title: "Coleta em lote"
description: "Coleta várias URLs em lote"
og:title: "Coleta em lote | Firecrawl"
og:description: "Coleta várias URLs em lote"
---

import BatchScrapePython from "/snippets/pt-BR/v1/batch-scrape/base/python.mdx";
import BatchScrapeNode from "/snippets/pt-BR/v1/batch-scrape/base/js.mdx";
import BatchScrapeCURL from "/snippets/pt-BR/v1/batch-scrape/base/curl.mdx";
import BatchScrapeOutput from "/snippets/pt-BR/v1/batch-scrape/base/output.mdx";
import BatchScrapeAsyncOutput from "/snippets/pt-BR/v1/batch-scrape/base/async-output.mdx";
import BatchScrapeExtractPython from "/snippets/pt-BR/v1/batch-scrape/extract/python.mdx";
import BatchScrapeExtractNode from "/snippets/pt-BR/v1/batch-scrape/extract/js.mdx";
import BatchScrapeExtractCURL from "/snippets/pt-BR/v1/batch-scrape/extract/curl.mdx";
import BatchScrapeExtractOutput from "/snippets/pt-BR/v1/batch-scrape/extract/output.mdx";
import BatchScrapeExtractAsyncOutput from "/snippets/pt-BR/v1/batch-scrape/extract/async-output.mdx";
import BatchScrapeWebhookCURL from "/snippets/pt-BR/v1/batch-scrape-webhook/base/curl.mdx";

<div id="batch-scraping-multiple-urls">
  ## Raspagem em lote de múltiplas URLs
</div>

Agora você pode raspar várias URLs em lote ao mesmo tempo. A função recebe as URLs iniciais e parâmetros opcionais como argumentos. O argumento params permite especificar opções adicionais para o job de raspagem em lote, como os formatos de saída.

<div id="how-it-works">
  ### Como funciona
</div>

Funciona de forma muito semelhante ao endpoint `/crawl`. Ele envia um trabalho de raspagem em lote e retorna um ID de trabalho para verificar o status dessa raspagem em lote.

O SDK oferece 2 métodos: síncrono e assíncrono. O método síncrono retorna os resultados do trabalho de raspagem em lote, enquanto o método assíncrono retorna um ID de trabalho que você pode usar para acompanhar o status da raspagem em lote.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

Se você estiver usando os métodos síncronos dos SDKs, serão retornados os resultados da raspagem em lote. Caso contrário, será retornado um ID de tarefa que você pode usar para verificar o status da raspagem em lote.

<div id="synchronous">
  #### Sincronizado
</div>

<BatchScrapeOutput />

<div id="asynchronous">
  #### Assíncrono
</div>

Você pode usar o ID do job para verificar o status do batch scrape chamando o endpoint `/batch/scrape/{id}`. Esse endpoint deve ser usado enquanto o job ainda está em execução ou logo após a conclusão, **pois jobs de batch scrape expiram após 24 horas**.

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-extraction">
  ## Raspagem em lote com extração
</div>

Você também pode usar o endpoint de raspagem em lote para extrair dados estruturados das páginas. Isso é útil quando você precisa obter os mesmos dados estruturados de uma lista de URLs.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

<div id="synchronous">
  #### Sincronamente
</div>

<BatchScrapeExtractOutput />

<div id="asynchronous">
  #### Assíncrono
</div>

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Coleta em lote com webhooks
</div>

Você pode configurar webhooks para receber notificações em tempo real conforme cada URL do seu lote é processada. Isso permite processar os resultados imediatamente, em vez de esperar a conclusão de todo o lote.

<BatchScrapeWebhookCURL />

Para uma documentação completa sobre webhooks, incluindo tipos de eventos, estrutura do payload e exemplos de implementação, consulte a [documentação de webhooks](/pt-BR/features/webhooks).

<div id="quick-reference">
  ### Referência rápida
</div>

**Tipos de evento:**

* `batch_scrape.started` - Quando a raspagem em lote é iniciada
* `batch_scrape.page` - Para cada URL raspada com sucesso
* `batch_scrape.completed` - Quando todas as URLs são processadas
* `batch_scrape.failed` - Se a raspagem em lote encontrar um erro

**Payload básico:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Dados da página para eventos "page"
  "metadata": {}, // Metadados personalizados
  "error": null
}
```

<Note>
  Para obter detalhes sobre configuração de webhooks, práticas recomendadas de segurança e solução de problemas, visite a [documentação de webhooks](/pt-BR/features/webhooks).
</Note>
