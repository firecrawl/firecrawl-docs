---
title: "Raspagem em lote"
description: "Raspagem em lote de múltiplas URLs"
og:title: "Raspagem em lote | Firecrawl"
og:description: "Raspagem em lote de múltiplas URLs"
---

import BatchScrapePython from '/snippets/pt-BR/v1/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/pt-BR/v1/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/pt-BR/v1/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/pt-BR/v1/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/pt-BR/v1/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/pt-BR/v1/batch-scrape/extract/python.mdx';
import BatchScrapeExtractNode from '/snippets/pt-BR/v1/batch-scrape/extract/js.mdx';
import BatchScrapeExtractCURL from '/snippets/pt-BR/v1/batch-scrape/extract/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/pt-BR/v1/batch-scrape/extract/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/pt-BR/v1/batch-scrape/extract/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/pt-BR/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## Raspagem em lote de múltiplas URLs
</div>

Agora você pode raspar várias URLs em lote ao mesmo tempo. A função recebe as URLs iniciais e parâmetros opcionais como argumentos. O argumento params permite especificar opções adicionais para o job de raspagem em lote, como os formatos de saída.

<div id="how-it-works">
  ### Como funciona
</div>

Funciona de forma muito semelhante ao endpoint `/crawl`. Ele envia uma tarefa de scraping em lote e retorna um ID de tarefa para verificar o status do processamento.

O SDK oferece 2 métodos, síncrono e assíncrono. O método síncrono retorna os resultados da tarefa em lote, enquanto o método assíncrono retorna um ID de tarefa que você pode usar para acompanhar o status.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

Se você estiver usando os métodos síncronos dos SDKs, serão retornados os resultados da raspagem em lote. Caso contrário, será retornado um ID de tarefa que você pode usar para verificar o status da raspagem em lote.

#### Sincronizado

<BatchScrapeOutput />

<div id="asynchronous">
  #### Assíncrono
</div>

Você pode usar o ID do job para verificar o status do batch scrape chamando o endpoint `/batch/scrape/{id}`. Esse endpoint deve ser usado enquanto o job ainda está em execução ou logo após a conclusão, **pois jobs de batch scrape expiram após 24 horas**.

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-extraction">
  ## Raspagem em lote com extração
</div>

Você também pode usar o endpoint de raspagem em lote para extrair dados estruturados das páginas. Isso é útil quando você precisa obter os mesmos dados estruturados de uma lista de URLs.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

<div id="synchronous">
  #### Sincronamente
</div>

<BatchScrapeExtractOutput />

<div id="asynchronous">
  #### Assíncrono
</div>

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Raspagem em lote com webhooks
</div>

Você pode configurar webhooks para receber notificações em tempo real conforme cada URL do seu lote é processada. Isso permite processar os resultados imediatamente, em vez de aguardar a conclusão de todo o lote.

<BatchScrapeWebhookCURL />

Para documentação completa sobre webhooks — incluindo tipos de eventos, estrutura do payload e exemplos de implementação — consulte a [documentação de webhooks](/pt-BR/webhooks/overview).

<div id="quick-reference">
  ### Referência rápida
</div>

**Tipos de eventos:**

* `batch_scrape.started` - Quando a coleta em lote é iniciada
* `batch_scrape.page` - Para cada URL coletada com sucesso
* `batch_scrape.completed` - Quando todas as URLs forem processadas
* `batch_scrape.failed` - Se a coleta em lote encontrar um erro

**Payload básico:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Dados da página para eventos 'page'
  "metadata": {}, // Seus metadados customizados
  "error": null
}
```

<Note>
  Para detalhes sobre configuração de webhooks, melhores práticas de segurança e
  solução de problemas, visite a [documentação de webhooks](/pt-BR/webhooks/overview).
</Note>
