---
title: "Extração"
description: "Extraia dados estruturados de páginas usando LLMs"
og:title: "Extração | Firecrawl"
og:description: "Extraia dados estruturados de páginas usando LLMs"
icon: "barcode-read"
sidebarTitle: "Extração"
---

import ExtractCURL from "/snippets/pt-BR/v1/extract/base/curl.mdx";
import ExtractPython from "/snippets/pt-BR/v1/extract/base/python.mdx";
import ExtractNode from "/snippets/pt-BR/v1/extract/base/js.mdx";
import ExtractOutput from "/snippets/pt-BR/v1/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/pt-BR/v1/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/pt-BR/v1/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/pt-BR/v1/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/pt-BR/v1/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/pt-BR/v1/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/pt-BR/v1/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/pt-BR/v1/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/pt-BR/v1/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/pt-BR/v1/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/pt-BR/v1/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/pt-BR/v1/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/pt-BR/v1/extract/status/pending.mdx";
import ExtractStatusAsync from "/snippets/pt-BR/v1/extract/async-response/async.mdx";
import ExtractStatusDone from "/snippets/pt-BR/v1/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/pt-BR/v1/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/pt-BR/v1/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/pt-BR/v1/extract/without-urls/curl.mdx";

O endpoint `/extract` simplifica a coleta de dados estruturados a partir de qualquer quantidade de URLs ou até de domínios inteiros. Forneça uma lista de URLs, opcionalmente com curingas (por exemplo, `example.com/*`), e um prompt ou um schema descrevendo as informações que você quer. O Firecrawl cuida dos detalhes de rastreamento, parsing e consolidação, seja para conjuntos de dados grandes ou pequenos.

<Info>O Extract tem cobrança diferente dos demais endpoints. Veja a [tabela de preços do Extract](https://www.firecrawl.dev/extract#pricing) para mais detalhes.</Info>


<div id="using-extract">
  ## Usando `/extract`
</div>

Você pode extrair dados estruturados de uma ou várias URLs, incluindo curingas:

- **Página única**  
  Exemplo: `https://firecrawl.dev/some-page`
- **Múltiplas páginas / Domínio completo**  
  Exemplo: `https://firecrawl.dev/*`

Ao usar `/*`, o Firecrawl rastreará e analisará automaticamente todas as URLs que conseguir descobrir nesse domínio e, em seguida, extrairá os dados solicitados. Este recurso é experimental; envie um e-mail para [help@firecrawl.com](mailto:help@firecrawl.com) se tiver problemas.

<div id="example-usage">
  ### Exemplo de uso
</div>

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

**Parâmetros principais:**

- **urls**: Uma lista com uma ou mais URLs. Suporta curingas (`/*`) para ampliar o rastreamento.
- **prompt** (Opcional, a menos que não haja schema): Um prompt em linguagem natural descrevendo os dados desejados ou especificando como você quer que esses dados sejam estruturados.
- **schema** (Opcional, a menos que não haja prompt): Uma estrutura mais rígida caso você já conheça o layout do JSON.
- **enableWebSearch** (Opcional): Quando `true`, a extração pode seguir links fora do domínio especificado.

Consulte a [Referência da API](https://docs.firecrawl.dev/api-reference/endpoint/extract) para mais detalhes.

<div id="response-sdks">
  ### Resposta (SDKs)
</div>

<ExtractOutput />

<div id="asynchronous-extraction-status-checking">
  ## Extração assíncrona e verificação de status
</div>

Quando você envia um job de extração — diretamente pela API ou pelos métodos assíncronos do SDK — recebe um ID de job. Você pode usar esse ID para:

- Verificar o status do job: Envie uma requisição para o endpoint /extract/{ID} para ver se o job ainda está em execução ou se foi concluído.
- Fazer polling automático (comportamento padrão do SDK): Se você usar o método padrão extract (Python/Node), o SDK faz polling automaticamente nesse endpoint e retorna os resultados finais quando o job é concluído.
- Fazer polling manual (métodos assíncronos do SDK): Se você usar os métodos assíncronos — async_extract (Python) ou asyncExtract (Node) — o SDK retorna imediatamente um ID de job que você pode acompanhar. Use get_extract_status (Python) ou getExtractStatus (Node) para verificar o progresso do job no seu próprio ritmo.

<Note>
  Este endpoint funciona apenas para jobs em andamento ou concluídos recentemente (dentro de 24 horas).
</Note>

Abaixo estão exemplos de código para verificar o status de um job de extração usando Python, Node.js e cURL:

<CodeGroup>

<CheckExtractJobPython />
<CheckExtractJobJS />
<CheckExtractJobCURL />

</CodeGroup>

<div id="possible-states">
  ### Possíveis estados
</div>

- **completed**: A extração foi concluída com sucesso.
- **processing**: O Firecrawl ainda está processando sua solicitação.
- **failed**: Ocorreu um erro; os dados não foram totalmente extraídos.
- **cancelled**: A tarefa foi cancelada pelo usuário.

<div id="pending-example">
  #### Exemplo pendente
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### Exemplo concluído
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## Extração sem esquema
</div>

Se preferir não definir uma estrutura rígida, basta fornecer um `prompt`. O modelo por trás do processo escolherá uma estrutura para você, o que pode ser útil para solicitações mais exploratórias ou flexíveis.

<CodeGroup>

<ExtractNoSchemaPython />
<ExtractNoSchemaJS />
<ExtractNoSchemaCURL />

</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## Melhorando os resultados com pesquisa na web
</div>

Definir `enableWebSearch = true` na sua requisição expandirá o crawl além do conjunto de URLs fornecido. Isso pode capturar informações adicionais ou relacionadas a partir de páginas vinculadas.

Veja um exemplo que extrai informações sobre dash cams, enriquecendo os resultados com dados de páginas relacionadas:

<CodeGroup>

<ExtractWebSearchPython />
<ExtractWebSearchJS />
<ExtractWebSearchCURL />

</CodeGroup>

<div id="example-response-with-web-search">
  ### Exemplo de resposta com pesquisa na web
</div>

<ExtractWebSearchOutput />

A resposta inclui contexto adicional obtido de páginas relacionadas, oferecendo informações mais completas e precisas.

<div id="extracting-without-urls">
  ## Extraindo sem URLs
</div>

O endpoint `/extract` agora permite extrair dados estruturados usando um prompt, sem a necessidade de fornecer URLs específicas. Isso é útil para pesquisas ou quando as URLs exatas são desconhecidas. Atualmente em Alfa.

<CodeGroup>

<ExtractWithoutURLsPython />
<ExtractWithoutURLsJS />
<ExtractWithoutURLsCURL />

</CodeGroup>

<div id="known-limitations-beta">
  ## Limitações Conhecidas (Beta)
</div>

1. **Cobertura de Sites em Grande Escala**  
   A cobertura completa de sites gigantes (por exemplo, “todos os produtos da Amazon”) em uma única requisição ainda não é suportada.

2. **Consultas Lógicas Complexas**  
   Pedidos como “encontre todas as postagens de 2025” podem não retornar de forma confiável todos os dados esperados. Capacidades de consulta mais avançadas estão em desenvolvimento.

3. **Inconsistências Ocasionalmente**  
   Os resultados podem variar entre execuções, especialmente em sites muito grandes ou dinâmicos. Em geral, os detalhes essenciais são capturados, mas alguma variação é possível.

4. **Estado Beta**  
   Como o endpoint `/extract` ainda está em Beta, os recursos e o desempenho continuarão evoluindo. Agradecemos relatos de bugs e feedback para nos ajudar a melhorar.

<div id="using-fire-1">
  ## Usando o FIRE-1
</div>

FIRE-1 é um agente de IA que amplia as capacidades de scraping do Firecrawl. Ele pode controlar ações do navegador e navegar por estruturas de sites complexas para viabilizar uma extração de dados mais completa do que os métodos tradicionais de scraping.

Você pode usar o agente FIRE-1 com o endpoint `/v1/extract` para tarefas de extração complexas que exigem navegação por várias páginas ou interação com elementos.

**Exemplo (cURL):**

```bash
curl -X POST https://api.firecrawl.dev/v1/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer SUA_CHAVE_DE_API' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "Extraia todos os comentários de usuários deste tópico no fórum.",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> O FIRE-1 já está no ar e disponível em prévia.


<div id="billing-and-usage-tracking">
  ## Cobrança e acompanhamento de uso
</div>

Você pode conferir os preços do endpoint /extract na [página de preços do Extract](https://www.firecrawl.dev/extract#pricing) e acompanhar o uso pela [página do Extract no painel](https://www.firecrawl.dev/app/extract).

Tem feedback ou precisa de ajuda? Envie um e-mail para [help@firecrawl.com](mailto:help@firecrawl.com).