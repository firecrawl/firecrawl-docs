---
title: Início rápido
description: "O Firecrawl permite transformar sites inteiros em markdown pronto para LLMs"
og:title: "Início rápido | Firecrawl"
og:description: "O Firecrawl permite transformar sites inteiros em markdown pronto para LLMs"
---

import InstallationPython from "/snippets/pt-BR/v1/installation/python.mdx";
import InstallationNode from "/snippets/pt-BR/v1/installation/js.mdx";
import InstallationGo from "/snippets/pt-BR/v1/installation/go.mdx";
import InstallationRust from "/snippets/pt-BR/v1/installation/rust.mdx";
import ScrapePython from "/snippets/pt-BR/v1/scrape/base/python.mdx";
import ScrapeNode from "/snippets/pt-BR/v1/scrape/base/js.mdx";
import ScrapeGo from "/snippets/pt-BR/v1/scrape/base/go.mdx";
import ScrapeRust from "/snippets/pt-BR/v1/scrape/base/rust.mdx";
import ScrapeCURL from "/snippets/pt-BR/v1/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/pt-BR/v1/scrape/base/output.mdx";
import CrawlPython from "/snippets/pt-BR/v1/crawl/base/python.mdx";
import CrawlNode from "/snippets/pt-BR/v1/crawl/base/js.mdx";
import CrawlGo from "/snippets/pt-BR/v1/crawl/base/go.mdx";
import CrawlRust from "/snippets/pt-BR/v1/crawl/base/rust.mdx";
import CrawlCURL from "/snippets/pt-BR/v1/crawl/base/curl.mdx";
import CrawlAsyncOutput from "/snippets/pt-BR/v1/crawl-async/base/output.mdx";
import CheckCrawlJobPython from "/snippets/pt-BR/v1/crawl-status/short/python.mdx";
import CheckCrawlJobNode from "/snippets/pt-BR/v1/crawl-status/short/js.mdx";
import CheckCrawlJobGo from "/snippets/pt-BR/v1/crawl-status/short/go.mdx";
import CheckCrawlJobRust from "/snippets/pt-BR/v1/crawl-status/short/rust.mdx";
import CheckCrawlJobCURL from "/snippets/pt-BR/v1/crawl-status/short/curl.mdx";
import CheckCrawlJobOutputScraping from "/snippets/pt-BR/v1/crawl-status/base/output-scraping.mdx";
import CheckCrawlJobOutputCompleted from "/snippets/pt-BR/v1/crawl-status/base/output-completed.mdx";
import ExtractCURL from "/snippets/pt-BR/v1/llm-extract/base/curl.mdx";
import ExtractPython from "/snippets/pt-BR/v1/llm-extract/base/python.mdx";
import ExtractNode from "/snippets/pt-BR/v1/llm-extract/base/js.mdx";
import ExtractOutput from "/snippets/pt-BR/v1/llm-extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/pt-BR/v1/llm-extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/pt-BR/v1/llm-extract/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/pt-BR/v1/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/pt-BR/v1/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/pt-BR/v1/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/pt-BR/v1/scrape/actions/output.mdx";

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.png" alt="Hero claro" />

<div id="welcome-to-firecrawl">
  ## Bem-vindo ao Firecrawl
</div>

O [Firecrawl](https://firecrawl.dev?ref=github) é um serviço de API que recebe uma URL, a rastreia e a converte em markdown limpo. Rastreamos todas as subpáginas acessíveis e entregamos markdown limpo para cada uma. Não é necessário sitemap.

<div id="how-to-use-it">
  ## Como usar?
</div>

Oferecemos uma API fácil de usar com nossa versão hospedada. Você pode acessar o playground e a documentação [aqui](https://firecrawl.dev/playground). Você também pode hospedar o backend por conta própria, se preferir.

Confira os seguintes recursos para começar:

* [x] **API**: [Documentação](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
* [x] **Frameworks de LLM**: [Langchain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low-code**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **Outros**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] Quer um SDK ou integração? Avise a gente abrindo uma issue.

**Self-host:** Para hospedar por conta própria, consulte o guia [aqui](/pt-BR/contributing/self-host).

<div id="api-key">
  ### Chave de API
</div>

Para usar a API, você precisa criar uma conta no [Firecrawl](https://firecrawl.dev) e obter uma chave de API.

<div id="features">
  ### Recursos
</div>

* [**Scrape**](#scraping): extrai o conteúdo de uma URL em formato pronto para LLM (markdown, resumo, dados estruturados via [modo JSON](#json-mode), captura de tela, HTML)
* [**Crawl**](#crawling): rastreia todas as URLs de uma página e retorna o conteúdo em formato pronto para LLM
* [**Map**](/pt-BR/features/map): informe um site e obtenha todas as URLs do domínio — extremamente rápido
* [**Search**](/pt-BR/features/search): pesquise na web e obtenha o conteúdo completo dos resultados
* [**Extract**](/pt-BR/features/extract): obtenha dados estruturados de uma única página, várias páginas ou sites inteiros com IA.

<div id="powerful-capabilities">
  ### Capacidades poderosas
</div>

* **Formatos prontos para LLM**: markdown, resumo, dados estruturados, captura de tela, HTML, links, metadados
* **O que é complicado**: proxies, mecanismos antibot, conteúdo dinâmico (renderizado em JS), análise de saída, orquestração
* **Personalização**: excluir tags, suporte a cabeçalhos personalizados, profundidade máxima de rastreamento, etc...
* **Análise de mídia**: PDFs, DOCX, imagens
* **Confiabilidade em primeiro lugar**: projetado para obter os dados de que você precisa — não importa o quão difícil seja
* **Ações**: clicar, rolar, digitar, esperar e mais, antes de extrair dados

Você encontra todas as capacidades do Firecrawl e como usá-las na nossa [documentação](https://docs.firecrawl.dev/api-reference/v2-introduction)

<div id="installing-firecrawl">
  ## Instalação do Firecrawl
</div>

<CodeGroup>
  <InstallationPython />

  <InstallationNode />

  <InstallationGo />

  <InstallationRust />
</CodeGroup>

<div id="scraping">
  ## Scraping
</div>

Para extrair dados de uma única URL, use o método `scrape_url`. Ele recebe a URL como parâmetro e retorna os dados extraídos como um dicionário.

<CodeGroup>
  <ScrapePython />

  <ScrapeNode />

  <ScrapeGo />

  <ScrapeRust />

  <ScrapeCURL />
</CodeGroup>

### Resposta

Os SDKs retornam o objeto de dados diretamente. O cURL retorna o payload exatamente como mostrado abaixo.

<ScrapeResponse />

<div id="crawling">
  ## Rastreamento
</div>

O recurso de rastreamento permite descobrir e extrair automaticamente conteúdo de uma URL e de todas as suas subpáginas acessíveis. Com nossos SDKs, basta chamar o método crawl — isso enviará uma tarefa de rastreamento, aguardará sua conclusão e retornará os resultados completos de todo o site.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <CrawlPython />

  <CrawlNode />

  <CrawlGo />

  <CrawlRust />

  <CrawlCURL />
</CodeGroup>

Se você estiver usando nossa API diretamente, o cURL ou as funções `start crawl` nos SDKs, será retornado um `ID` que você pode usar para verificar o status do crawl.

<CrawlAsyncOutput />

<div id="check-crawl-job">
  ### Verificar job de crawl
</div>

Usado para checar o status de um job de crawl e obter seu resultado.

<CodeGroup>
  <CheckCrawlJobPython />

  <CheckCrawlJobNode />

  <CheckCrawlJobGo />

  <CheckCrawlJobRust />

  <CheckCrawlJobCURL />
</CodeGroup>

<div id="response">
  #### Resposta
</div>

A resposta varia conforme o status do crawl. Para respostas ainda não concluídas ou grandes que excedam 10 MB, é fornecido um parâmetro de URL `next`. Você deve solicitar essa URL para obter os próximos 10 MB de dados. Se o parâmetro `next` estiver ausente, isso indica o fim dos dados do crawl.

<CodeGroup>
  <CheckCrawlJobOutputScraping />

  <CheckCrawlJobOutputCompleted />
</CodeGroup>

<div id="json-mode">
  ## modo JSON
</div>

Com o modo JSON, você pode extrair dados estruturados de qualquer URL com facilidade. Também oferecemos suporte a esquemas Pydantic para simplificar seu trabalho. Veja como usá-lo:

<CodeGroup>
  <ExtractPython />

  <ExtractNode />

  <ExtractCURL />
</CodeGroup>

Resultado:

<ExtractOutput />

<div id="extracting-without-schema">
  ### Extraindo sem esquema
</div>

Agora você pode extrair sem um esquema apenas passando um `prompt` para o endpoint. O LLM define a estrutura dos dados.

<CodeGroup>
  <ExtractNoSchemaCURL />
</CodeGroup>

Resultado:

<ExtractNoSchemaOutput />

<div id="interacting-with-the-page-with-actions">
  ## Interagindo com a página com ações
</div>

O Firecrawl permite executar várias ações em uma página da web antes de fazer o scraping do conteúdo. Isso é especialmente útil para interagir com conteúdo dinâmico, navegar entre páginas ou acessar conteúdo que exige interação do usuário.

Veja um exemplo de como usar ações para acessar google.com, pesquisar por Firecrawl, clicar no primeiro resultado e tirar uma captura de tela.

É importante, na maioria dos casos, usar a ação `wait` antes e/ou depois de executar outras ações para dar tempo suficiente para a página carregar.

<div id="example">
  ### Exemplo
</div>

<CodeGroup>
  <ScrapeActionsPython />

  <ScrapeActionsNode />

  <ScrapeActionsCURL />
</CodeGroup>

<div id="output">
  ### Resultado
</div>

<CodeGroup>
  <ScrapeActionsOutput />
</CodeGroup>

<div id="open-source-vs-cloud">
  ## Open Source vs Cloud
</div>

Firecrawl é open source e está disponível sob a [licença AGPL-3.0](https://github.com/firecrawl/firecrawl/blob/main/LICENSE).

Para oferecer o melhor produto possível, disponibilizamos uma versão hospedada do Firecrawl junto com nossa oferta open source. A solução em nuvem nos permite inovar continuamente e manter um serviço de alta qualidade e sustentável para todos os usuários.

O Firecrawl Cloud está disponível em [firecrawl.dev](https://firecrawl.dev) e oferece uma variedade de recursos que não estão disponíveis na versão open source:

![Firecrawl Cloud vs Open Source](./images/open-source-cloud.png)

<div id="contributing">
  ## Contribuindo
</div>

Adoramos contribuições! Leia nosso [guia de contribuição](https://github.com/firecrawl/firecrawl/blob/main/CONTRIBUTING.md) antes de abrir um pull request.