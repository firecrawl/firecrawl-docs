---
title: "Python"
description: "O SDK do Firecrawl para Python é um wrapper da API do Firecrawl que ajuda você a converter sites em Markdown com facilidade."
icon: "python"
og:title: "SDK Python | Firecrawl"
og:description: "O SDK do Firecrawl para Python é um wrapper da API do Firecrawl que ajuda você a converter sites em Markdown com facilidade."
---

import InstallationPython from '/snippets/pt-BR/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/pt-BR/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/pt-BR/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/pt-BR/v1/crawl-status/short/python.mdx'
import CrawlAsyncPythonShort from '/snippets/pt-BR/v1/crawl-async/short/python.mdx'
import CancelCrawlPythonShort from '/snippets/pt-BR/v1/crawl-delete/short/python.mdx'
import MapPythonShort from '/snippets/pt-BR/v1/map/short/python.mdx'
import ExtractPythonShort from '/snippets/pt-BR/v1/extract/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/pt-BR/v1/scrape-and-crawl/python.mdx'
import CrawlWebSocketPythonBase from '/snippets/pt-BR/v1/crawl-websocket/base/python.mdx'
import AsyncPythonShort from '/snippets/pt-BR/v1/async/short/python.mdx'


<div id="installation">
  ## Instalação
</div>

Para instalar o SDK do Firecrawl para Python, você pode usar o pip:

<InstallationPython />

<div id="usage">
  ## Uso
</div>

1. Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev)
2. Configure a chave de API como uma variável de ambiente chamada `FIRECRAWL_API_KEY` ou passe-a como parâmetro para a classe `FirecrawlApp`.

Veja um exemplo de como usar o SDK:

<ScrapeAndCrawlExamplePython />

<div id="scraping-a-url">
  ### Extraindo dados de uma URL
</div>

Para extrair dados de uma única URL, use o método `scrape_url`. Ele recebe a URL como parâmetro e retorna os dados extraídos como um dicionário.

<ScrapePythonShort />

<div id="crawling-a-website">
  ### Rastreamento de um site
</div>

Para rastrear um site, use o método `crawl_url`. Ele recebe a URL inicial e parâmetros opcionais. O argumento `params` permite definir opções adicionais para a tarefa de rastreamento, como o número máximo de páginas, domínios permitidos e o formato de saída.

<CrawlPythonShort />

<div id="asynchronous-crawling">
  ### Rastreamento assíncrono
</div>

<Tip>Procurando operações assíncronas? Confira a seção [Classe Assíncrona](#async-class) abaixo.</Tip>

Para rastrear um site de forma assíncrona, use o método `crawl_url_async`. Ele retorna o `ID` do rastreamento, que você pode usar para verificar o status da tarefa de rastreamento. Ele recebe a URL inicial e parâmetros opcionais como argumentos. O argumento `params` permite especificar opções adicionais para a tarefa de rastreamento, como o número máximo de páginas a rastrear, domínios permitidos e o formato de saída.

<CrawlAsyncPythonShort />

<div id="checking-crawl-status">
  ### Verificando o status do crawl
</div>

Para verificar o status de um job de crawl, use o método `check_crawl_status`. Ele recebe o ID do job como parâmetro e retorna o status atual do job de crawl.

<CheckCrawlStatusPythonShort />

<div id="cancelling-a-crawl">
  ### Cancelando um crawl
</div>

Para cancelar um trabalho de crawl assíncrono, use o método `cancel_crawl`. Ele recebe o ID do trabalho assíncrono como parâmetro e retorna o status do cancelamento.

<CancelCrawlPythonShort />

<div id="map-a-website">
  ### Mapear um site
</div>

Use `map_url` para gerar uma lista de URLs de um site. O argumento `params` permite personalizar o mapeamento, incluindo opções para excluir subdomínios ou usar o sitemap.

<MapPythonShort />

{/* ### Extração de dados estruturados de sites

Para extrair dados estruturados de sites, use o método `extract`. Ele recebe as URLs das quais extrair os dados, um prompt e um esquema como argumentos. O esquema é um modelo Pydantic que define a estrutura dos dados extraídos.

<ExtractPythonShort /> */}

<div id="crawling-a-website-with-websockets">
  ### Rastreamento de um site com WebSockets
</div>

Para rastrear um site com WebSockets, use o método `crawl_url_and_watch`. Ele recebe a URL inicial e parâmetros opcionais como argumentos. O parâmetro `params` permite especificar opções adicionais para a tarefa de rastreamento, como o número máximo de páginas a rastrear, domínios permitidos e o formato de saída.

<CrawlWebSocketPythonBase />

<div id="error-handling">
  ## Tratamento de erros
</div>

O SDK trata os erros retornados pela API do Firecrawl e lança exceções apropriadas. Se ocorrer um erro durante uma requisição, uma exceção será lançada com uma mensagem descritiva.

<div id="async-class">
  ## Classe assíncrona
</div>

Para operações assíncronas, você pode usar a classe `AsyncFirecrawlApp`. Seus métodos são os mesmos da classe `FirecrawlApp`, mas não bloqueiam a thread principal.

<AsyncPythonShort />