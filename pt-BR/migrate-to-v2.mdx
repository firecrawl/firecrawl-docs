---
title: Migração da v1 para a v2
description: "Principais mudanças, mapeamentos e exemplos de antes e depois para atualizar sua integração para a v2."
og:title: "Migração da v1 para a v2 | Firecrawl"
og:description: "Principais mudanças, mapeamentos e exemplos de antes e depois para atualizar sua integração para a v2."
---

<div id="overview">
  ## Visão geral
</div>

<div id="key-improvements">
  ### Melhorias principais
</div>

- **Mais rápido por padrão**: As requisições são armazenadas em cache com `maxAge` definido para 2 dias, e padrões sensatos como `blockAds`, `skipTlsVerification` e `removeBase64Images` vêm habilitados.

- **Novo formato de resumo**: Agora você pode especificar `"summary"` como um formato para receber diretamente um resumo conciso do conteúdo da página.

- **Extração JSON atualizada**: A extração JSON e o rastreamento de alterações agora usam um formato de objeto: `{ type: "json", prompt, schema }`. O antigo formato `"extract"` foi renomeado para `"json"`.

- **Opções de captura de tela aprimoradas**: Use o formato de objeto: `{ type: "screenshot", fullPage, quality, viewport }`.

- **Novas fontes de pesquisa**: Pesquise em `"news"` e `"images"`, além dos resultados da web, definindo o parâmetro `sources`.

- **Rastreamento inteligente com prompts**: Forneça um `prompt` em linguagem natural para o crawl e o sistema derivará caminhos/limites automaticamente. Use o novo endpoint /crawl/params-preview para inspecionar as opções derivadas antes de iniciar um job.

<div id="quick-migration-checklist">
  ## Lista de verificação rápida de migração
</div>

- Substitua o uso do cliente v1 pelos clientes v2:
  - JS: `const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' })`
  - Python: `firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')`
  - API: use os novos endpoints em `https://api.firecrawl.dev/v2/`.
- Atualize os formatos:
  - Use "summary" quando necessário
  - modo JSON: use `{ type: "json", prompt, schema }` para extração em JSON
  - Screenshot e Screenshot@fullPage: use o formato de objeto de screenshot ao especificar opções
- Adote fluxos assíncronos padronizados nos SDKs:
  - Crawls: `startCrawl` + `getCrawlStatus` (ou o waiter `crawl`)
  - Batch: `startBatchScrape` + `getBatchScrapeStatus` (ou o waiter `batchScrape`)
  - Extract: `startExtract` + `getExtractStatus` (ou o waiter `extract`)
- Mapeamento de opções de crawl (veja abaixo)
- Verifique o `prompt` do crawl com `/crawl/params-preview`

<div id="sdk-surface-v2">
  ## Interface do SDK (v2)
</div>

<div id="jsts">
  ### JS/TS
</div>

<div id="method-name-changes-v1-v2">
  #### Mudanças nos nomes dos métodos (migração v1 → v2)
</div>

**Scrape, Search e Map**

| v1 (FirecrawlApp)     | v2 (Firecrawl)           |
|-----------------------|--------------------------|
| `scrapeUrl(url, ...)` | `scrape(url, options?)`  |
| `search(query, ...)`  | `search(query, options?)`|
| `mapUrl(url, ...)`    | `map(url, options?)`     |

**Crawling**

| v1                        | v2                        |
|---------------------------|---------------------------|
| `crawlUrl(url, ...)`      | `crawl(url, options?)` (waiter) |
| `asyncCrawlUrl(url, ...)` | `startCrawl(url, options?)`     |
| `checkCrawlStatus(id, ...)` | `getCrawlStatus(id)`          |
| `cancelCrawl(id)`         | `cancelCrawl(id)`              |
| `checkCrawlErrors(id)`    | `getCrawlErrors(id)`           |

**Batch Scraping**

| v1                                 | v2                                 |
|------------------------------------|------------------------------------|
| `batchScrapeUrls(urls, ...)`       | `batchScrape(urls, opts?)` (waiter)|
| `asyncBatchScrapeUrls(urls, ...)`  | `startBatchScrape(urls, opts?)`    |
| `checkBatchScrapeStatus(id, ...)`  | `getBatchScrapeStatus(id)`         |
| `checkBatchScrapeErrors(id)`       | `getBatchScrapeErrors(id)`         |

**Extração**

| v1                          | v2                  |
|-----------------------------|---------------------|
| `extract(urls?, params?)`   | `extract(args)`     |
| `asyncExtract(urls, params?)` | `startExtract(args)` |
| `getExtractStatus(id)`      | `getExtractStatus(id)` |

**Outros / Removidos**

| v1                                 | v2                |
|------------------------------------|-------------------|
| `generateLLMsText(...)`            | (não está no SDK v2)   |
| `checkGenerateLLMsTextStatus(id)`  | (não está no SDK v2)   |
| `crawlUrlAndWatch(...)`            | `watcher(jobId, ...)` |
| `batchScrapeUrlsAndWatch(...)`     | `watcher(jobId, ...)` |

---

<div id="python-sync">
  ### Python (sincrono)
</div>

<div id="method-name-changes-v1-v2">
  #### Mudanças nos nomes dos métodos (migração v1 → v2)
</div>

**Scrape, Search e Map**

| v1                | v2             |
|-------------------|----------------|
| `scrape_url(...)` | `scrape(...)`  |
| `search(...)`     | `search(...)`  |
| `map_url(...)`    | `map(...)`     |

**Crawling**

| v1                         | v2                      |
|----------------------------|-------------------------|
| `crawl_url(...)`           | `crawl(...)` (waiter)   |
| `async_crawl_url(...)`     | `start_crawl(...)`      |
| `check_crawl_status(...)`  | `get_crawl_status(...)` |
| `cancel_crawl(...)`        | `cancel_crawl(...)`     |

**Scraping em lote**

| v1                             | v2                             |
|--------------------------------|--------------------------------|
| `batch_scrape_urls(...)`       | `batch_scrape(...)` (waiter)   |
| `async_batch_scrape_urls(...)` | `start_batch_scrape(...)`      |
| `get_batch_scrape_status(...)` | `get_batch_scrape_status(...)` |
| `get_batch_scrape_errors(...)` | `get_batch_scrape_errors(...)` |

**Extração**

| v1                    | v2                    |
|-----------------------|-----------------------|
| `extract(...)`        | `extract(...)`        |
| `start_extract(...)`  | `start_extract(...)`  |
| `get_extract_status(...)` | `get_extract_status(...)` |

**Outros / Removidos**

| v1                                | v2                   |
|-----------------------------------|----------------------|
| `generate_llms_text(...)`         | (não disponível no SDK v2)   |
| `get_generate_llms_text_status(...)` | (não disponível no SDK v2) |
| `watch_crawl(...)`                | `watcher(job_id, ...)` |

---

<div id="python-async">
  ### Python (assíncrono)
</div>

- `AsyncFirecrawl` oferece os mesmos métodos (todos aguardáveis).

<div id="formats-and-scrape-options">
  ## Formatos e opções de scraping
</div>

- Use formatos de string para o básico: `"markdown"`, `"html"`, `"rawHtml"`, `"links"`, `"summary"`, `"images"`.
- Em vez de `parsePDF`, use `parsers: [ { "type": "pdf" } | "pdf" ]`.
- Use formatos de objeto para JSON, controle de alterações e capturas de tela:

<div id="json-format">
  ### Formato JSON
</div>

<CodeGroup>
```js Node
const formats = [ {
  "type": "json",
  "prompt": "Extraia a missão da empresa presente na página."
}];

doc = firecrawl.scrape(url, { formats });
```

```python Python
formats = [ { "type": "json", "prompt": "Extraia a missão da empresa presente na página." } ];

doc = firecrawl.scrape(url, formats=formats);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "formats": [{
        "type": "json",
        "prompt": "Extraia a missão da empresa presente na página."
      }]
    }'
```
</CodeGroup>

<div id="screenshot-format">
  ### Formato de captura de tela
</div>

<CodeGroup>

```js Node
// Formato de captura de tela (JS)
const formats = [ { "type": "screenshot", "fullPage": true, "quality": 80, "viewport": { "width": 1280, "height": 800 } } ];

doc = firecrawl.scrape(url, { formats });
```

```python Python
# Formato de captura de tela (Python)
formats = [ { "type": "screenshot", "fullPage": true, "quality": 80, "viewport": { "width": 1280, "height": 800 } } ]
doc = firecrawl.scrape(url, formats=formats);
```

```bash cURL
# Formato de captura de tela (cURL)
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "formats": [{
        "type": "screenshot",
        "fullPage": true,
        "quality": 80,
        "viewport": { "width": 1280, "height": 800 }
      }]
    }'
```

</CodeGroup>

<div id="crawl-options-mapping-v1-v2">
  ## Mapeamento de opções de rastreamento (v1 → v2)
</div>

| v1                     | v2                 |
|------------------------|--------------------|
| `allowBackwardCrawling`| (removido) use `crawlEntireDomain`|
| `maxDepth`             | (removido) use `maxDiscoveryDepth`|
| `ignoreSitemap` (bool) | `sitemap` (por exemplo, "only", "skip" ou "include") |
| (nenhum) | `prompt` |

<div id="crawl-prompt-params-preview">
  ## Visualização de prompt de crawl + parâmetros
</div>

Veja exemplos de visualização de parâmetros de crawl:

<CodeGroup>
```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR-API-KEY" });

const params = await firecrawl.crawlParamsPreview('https://docs.firecrawl.dev', 'Extrair docs e blog');
console.log(params);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')
preview = firecrawl.crawl_params_preview(url='https://docs.firecrawl.dev', prompt='Extrair docs e blog')
print(preview)
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "prompt": "Extrair docs e blog"
    }'
```
</CodeGroup>