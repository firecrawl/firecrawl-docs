---
title: "Extração"
description: "Extraia dados estruturados de páginas usando LLMs"
og:title: "Extração | Firecrawl"
og:description: "Extraia dados estruturados de páginas usando LLMs"
icon: "barcode-read"
sidebarTitle: "Extração"
---

import ExtractCURL from "/snippets/pt-BR/v2/extract/base/curl.mdx";
import ExtractPython from "/snippets/pt-BR/v2/extract/base/python.mdx";
import ExtractNode from "/snippets/pt-BR/v2/extract/base/js.mdx";
import ExtractOutput from "/snippets/pt-BR/v2/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/pt-BR/v2/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/pt-BR/v2/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/pt-BR/v2/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/pt-BR/v2/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/pt-BR/v2/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/pt-BR/v2/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/pt-BR/v2/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/pt-BR/v2/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/pt-BR/v2/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/pt-BR/v2/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/pt-BR/v2/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/pt-BR/v2/extract/status/pending.mdx";
import ExtractStatusDone from "/snippets/pt-BR/v2/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/pt-BR/v2/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/pt-BR/v2/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/pt-BR/v2/extract/base/curl.mdx";

O endpoint `/extract` simplifica a coleta de dados estruturados de qualquer número de URLs ou de domínios inteiros. Forneça uma lista de URLs, opcionalmente com curingas (por exemplo, `example.com/*`), e um prompt ou esquema descrevendo as informações desejadas. O Firecrawl cuida dos detalhes de rastrear, analisar e agregar conjuntos de dados, grandes ou pequenos.

<Info>Simplificamos a cobrança: agora o Extract usa créditos, assim como os outros endpoints. Cada crédito equivale a 15 tokens.</Info>

<div id="using-extract">
  ## Usando `/extract`
</div>

Você pode extrair dados estruturados de uma ou várias URLs, incluindo curingas:

- **Página única**  
  Exemplo: `https://firecrawl.dev/some-page`
- **Múltiplas páginas / Domínio completo**  
  Exemplo: `https://firecrawl.dev/*`

Ao usar `/*`, o Firecrawl rastreia e processa automaticamente todas as URLs que conseguir descobrir nesse domínio e, em seguida, extrai os dados solicitados. Este recurso é experimental; envie um e-mail para [help@firecrawl.com](mailto:help@firecrawl.com) se tiver problemas.

<div id="example-usage">
  ### Exemplo de uso
</div>

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

**Parâmetros principais:**

- **urls**: Uma lista com um ou mais URLs. Suporta curingas (`/*`) para uma varredura mais ampla.
- **prompt** (Opcional, exceto se não houver schema): Um prompt em linguagem natural descrevendo os dados desejados ou como você quer que esses dados sejam estruturados.
- **schema** (Opcional, exceto se não houver prompt): Uma estrutura mais rígida caso você já conheça o layout JSON.
- **enableWebSearch** (Opcional): Quando `true`, a extração pode seguir links fora do domínio especificado.

Consulte a [referência da API](https://docs.firecrawl.dev/api-reference/endpoint/extract) para mais detalhes.

<div id="response-sdks">
  ### Resposta (SDKs)
</div>

<ExtractOutput />

<div id="job-status-and-completion">
  ## Status do job e conclusão
</div>

Ao enviar um job de extração — diretamente pela API ou pelos métodos de inicialização — você receberá um ID de job. Você pode usar esse ID para:

- Obter o status do job: Envie uma solicitação para o endpoint /extract/{ID} para ver se o job ainda está em execução ou se foi concluído.
- Aguardar resultados: Se você usar o método padrão `extract` (Python/Node), o SDK aguarda e retorna os resultados finais.
- Iniciar e depois consultar: Se você usar os métodos de início — `start_extract` (Python) ou `startExtract` (Node) — o SDK retorna um ID de job imediatamente. Use `get_extract_status` (Python) ou `getExtractStatus` (Node) para verificar o progresso.

<Note>
  Este endpoint só funciona para jobs em andamento ou concluídos recentemente (nas últimas 24 horas).
</Note>

Abaixo estão exemplos de código para verificar o status de um job de extração usando Python, Node.js e cURL:

<CodeGroup>

<CheckExtractJobPython />
<CheckExtractJobJS />
<CheckExtractJobCURL />

</CodeGroup>

<div id="possible-states">
  ### Estados possíveis
</div>

- **completed**: A extração foi concluída com sucesso.
- **processing**: O Firecrawl ainda está processando sua solicitação.
- **failed**: Ocorreu um erro; os dados não foram totalmente extraídos.
- **cancelled**: A tarefa foi cancelada pelo usuário.

<div id="pending-example">
  #### Exemplo pendente
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### Exemplo concluído
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## Extraindo sem um esquema
</div>

Se você preferir não definir uma estrutura rígida, pode simplesmente fornecer um `prompt`. O modelo subjacente escolherá uma estrutura para você, o que pode ser útil para solicitações mais exploratórias ou flexíveis.

<CodeGroup>

<ExtractNoSchemaPython />
<ExtractNoSchemaJS />
<ExtractNoSchemaCURL />

</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## Melhorando os resultados com busca na web
</div>

Definir `enableWebSearch = true` na sua requisição expandirá o crawl além do conjunto de URLs fornecido. Isso pode capturar informações de suporte ou relacionadas a partir de páginas linkadas.

Veja um exemplo que extrai informações sobre dash cams, enriquecendo os resultados com dados de páginas relacionadas:

<CodeGroup>

<ExtractWebSearchPython />
<ExtractWebSearchJS />
<ExtractWebSearchCURL />

</CodeGroup>

<div id="example-response-with-web-search">
  ### Exemplo de resposta com pesquisa na web
</div>

<ExtractWebSearchOutput />

A resposta inclui contexto adicional obtido de páginas relacionadas, oferecendo informações mais completas e precisas.

<div id="extracting-without-urls">
  ## Extração sem URLs
</div>

O endpoint /extract agora permite extrair dados estruturados usando um prompt, sem a necessidade de URLs específicas. Isso é útil para pesquisa ou quando as URLs exatas são desconhecidas. Atualmente em alpha.

<CodeGroup>

<ExtractWithoutURLsPython />
<ExtractWithoutURLsJS />
<ExtractWithoutURLsCURL />

</CodeGroup>

<div id="known-limitations-beta">
  ## Limitações Conhecidas (Beta)
</div>

1. **Cobertura de Sites em Grande Escala**  
   A cobertura completa de sites muito grandes (por exemplo, “todos os produtos da Amazon”) em uma única requisição ainda não é suportada.

2. **Consultas Lógicas Complexas**  
   Pedidos como “encontrar todas as postagens de 2025” podem não retornar de forma confiável todos os dados esperados. Capacidades de consulta mais avançadas estão em desenvolvimento.

3. **Inconsistências Ocasionais**  
   Os resultados podem variar entre execuções, especialmente em sites muito grandes ou dinâmicos. Geralmente os detalhes essenciais são capturados, mas alguma variação é possível.

4. **Estado Beta**  
   Como o endpoint `/extract` ainda está em Beta, recursos e desempenho continuarão evoluindo. Agradecemos relatos de bugs e feedback para nos ajudar a melhorar.

<div id="using-fire-1">
  ## Usando o FIRE-1
</div>

O FIRE-1 é um agente de IA que amplia as capacidades de scraping do Firecrawl. Ele pode controlar ações do navegador e navegar por estruturas complexas de sites para viabilizar a extração de dados além do scraping tradicional.

Você pode usar o agente FIRE-1 com o endpoint `/extract` para tarefas de extração complexas que exigem navegar por várias páginas ou interagir com elementos.

**Exemplo (cURL):**

```bash
curl -X POST https://api.firecrawl.dev/v2/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer SUA_CHAVE_DE_API' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "Extraia todos os comentários de usuários deste tópico do fórum.",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> O FIRE-1 já está disponível e em versão de prévia.

<div id="billing-and-usage-tracking">
  ## Cobrança e acompanhamento de uso
</div>

Simplificamos a cobrança: o Extract agora usa créditos, assim como os demais endpoints. Cada crédito equivale a 15 tokens.

Você pode acompanhar o uso do Extract pelo [dashboard](https://www.firecrawl.dev/app/extract).

Tem alguma sugestão ou precisa de ajuda? Envie um e-mail para [help@firecrawl.com](mailto:help@firecrawl.com).