---
title: "Modo stealth"
description: "Use proxies stealth para sites com soluções avançadas de anti-bot"
og:title: "Modo stealth | Firecrawl"
og:description: "Use proxies stealth para sites com soluções avançadas de anti-bot"
---

import ProxyPython from "/snippets/pt-BR/v2/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/pt-BR/v2/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/pt-BR/v2/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/pt-BR/v2/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/pt-BR/v2/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/pt-BR/v2/scrape/proxy-retry/curl.mdx";

A Firecrawl oferece diferentes tipos de proxy para ajudar você a extrair dados de sites com variados níveis de proteção contra bots. O tipo de proxy pode ser especificado usando o parâmetro `proxy`.


<div id="proxy-types">
  ### Tipos de proxy
</div>

Firecrawl oferece suporte a três tipos de proxy:

- **basic**: Proxies para fazer scraping de sites sem ou com soluções anti-bot básicas. Rápido e geralmente funciona.
- **stealth**: Proxies stealth para fazer scraping de sites com soluções anti-bot avançadas. Mais lento, mas mais confiável em certos sites.
- **auto**: O Firecrawl tentará automaticamente novamente com proxies stealth se o proxy basic falhar. Se a nova tentativa com stealth for bem-sucedida, 5 créditos serão cobrados pelo scraping. Se a primeira tentativa com basic for bem-sucedida, apenas o custo regular será cobrado.

Se você não especificar um proxy, o Firecrawl usará auto por padrão.

<div id="using-stealth-mode">
  ### Usando o modo stealth
</div>

Ao fazer scraping de sites com proteção anti-bot avançada, você pode usar o modo de proxy stealth para aumentar a taxa de sucesso.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Observação:** Requisições com proxy stealth custam 5 créditos cada vez que forem usadas.

<div id="using-stealth-as-a-retry-mechanism">
  ## Usando o modo stealth como mecanismo de nova tentativa
</div>

Um padrão comum é primeiro tentar o scraping com as configurações padrão de proxy e, em seguida, refazer a tentativa no modo stealth se você receber códigos de status de erro específicos (401, 403 ou 500) no campo `metadata.statusCode` da resposta. Esses códigos podem indicar que o site está bloqueando sua solicitação.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Essa abordagem ajuda a otimizar o uso de créditos, utilizando o modo stealth apenas quando necessário.