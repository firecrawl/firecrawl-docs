---
title: "Agente"
description: "Reúna dados em qualquer lugar da web."
og:title: "Agente | Firecrawl"
og:description: "Reúna dados em qualquer lugar da web."
sidebarTitle: "Agente"
---

import AgentPython from "/snippets/pt-BR/v2/agent/base/python.mdx";
import AgentJS from "/snippets/pt-BR/v2/agent/base/js.mdx";
import AgentCURL from "/snippets/pt-BR/v2/agent/base/curl.mdx";
import AgentOutput from "/snippets/pt-BR/v2/agent/base/output.mdx";
import AgentWithSchemaPython from "/snippets/pt-BR/v2/agent/with-schema/python.mdx";
import AgentWithSchemaJS from "/snippets/pt-BR/v2/agent/with-schema/js.mdx";
import AgentWithSchemaCURL from "/snippets/pt-BR/v2/agent/with-schema/curl.mdx";
import AgentWithSchemaOutput from "/snippets/pt-BR/v2/agent/with-schema/output.mdx";
import AgentWithURLsPython from "/snippets/pt-BR/v2/agent/with-urls/python.mdx";
import AgentWithURLsJS from "/snippets/pt-BR/v2/agent/with-urls/js.mdx";
import AgentWithURLsCURL from "/snippets/pt-BR/v2/agent/with-urls/curl.mdx";
import AgentStatusPython from "/snippets/pt-BR/v2/agent/status/python.mdx";
import AgentStatusJS from "/snippets/pt-BR/v2/agent/status/js.mdx";
import AgentStatusCURL from "/snippets/pt-BR/v2/agent/status/curl.mdx";
import AgentStatusPending from "/snippets/pt-BR/v2/agent/status/pending.mdx";
import AgentStatusCompleted from "/snippets/pt-BR/v2/agent/status/completed.mdx";
import AgentWithModelPython from "/snippets/pt-BR/v2/agent/with-model/python.mdx";
import AgentWithModelJS from "/snippets/pt-BR/v2/agent/with-model/js.mdx";
import AgentWithModelCURL from "/snippets/pt-BR/v2/agent/with-model/curl.mdx";

Firecrawl `/agent` é uma API mágica que pesquisa, navega e coleta dados da mais ampla variedade de sites, encontrando dados em locais de difícil acesso e descobrindo dados de maneiras que nenhuma outra API consegue. Ele realiza em poucos minutos o que levaria muitas horas para um humano — coleta de dados de ponta a ponta, sem scripts ou trabalho manual.
Seja para obter um único dado ou conjuntos de dados completos em escala, o Firecrawl `/agent` trabalha para obter seus dados.

**Pense no `/agent` como uma pesquisa profunda por dados, onde quer que eles estejam!**

<Info>
  **Prévia de pesquisa**: Agent está em acesso antecipado. Espere algumas imperfeições. Ele ficará significativamente melhor com o tempo. [Compartilhe feedback →](mailto:product@firecrawl.com)
</Info>

Agent aproveita tudo o que há de melhor no `/extract` e leva isso além:

* **Nenhuma URL necessária**: Basta descrever o que você precisa via parâmetro `prompt`. URLs são opcionais
* **Pesquisa aprofundada na web**: Pesquisa e navega autonomamente em profundidade em sites para encontrar seus dados
* **Confiável e preciso**: Funciona com uma grande variedade de consultas e casos de uso
* **Mais rápido**: Processa múltiplas fontes em paralelo para resultados mais rápidos

<div id="using-agent">
  ## Usando `/agent`
</div>

O único parâmetro obrigatório é `prompt`. Basta descrever quais dados deseja extrair. Para obter uma saída estruturada, forneça um schema JSON. Os SDKs oferecem suporte a Pydantic (Python) e Zod (Node) para definições de schema com segurança de tipos:

<CodeGroup>
  <AgentWithSchemaPython />

  <AgentWithSchemaJS />

  <AgentWithSchemaCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

<AgentWithSchemaOutput />

<div id="providing-urls-optional">
  ## Fornecendo URLs (Opcional)
</div>

Opcionalmente, você pode fornecer URLs para que o agente se concentre em páginas específicas:

<CodeGroup>
  <AgentWithURLsPython />

  <AgentWithURLsJS />

  <AgentWithURLsCURL />
</CodeGroup>

<div id="job-status-and-completion">
  ## Status e conclusão de jobs
</div>

Jobs de agente são executados de forma assíncrona. Ao enviar um job, você recebe um Job ID que pode usar para verificar o status:

* **Método padrão**: `agent()` aguarda e retorna os resultados finais
* **Iniciar e depois consultar**: use `start_agent` (Python) ou `startAgent` (Node) para obter um Job ID imediatamente e depois verificar o status com `get_agent_status` / `getAgentStatus`

<Note>Os resultados do job ficam disponíveis via API por 24 horas após a conclusão. Após esse período, você ainda pode ver o histórico do seu agente e os resultados nos [logs de atividade](https://www.firecrawl.dev/app/logs).</Note>

<CodeGroup>
  <AgentStatusPython />

  <AgentStatusJS />

  <AgentStatusCURL />
</CodeGroup>

<div id="possible-states">
  ### Estados possíveis
</div>

| Status | Descrição |
|--------|-------------|
| `processing` | O agente ainda está trabalhando na sua solicitação |
| `completed` | Extração concluída com sucesso |
| `failed` | Ocorreu um erro durante a extração |

<div id="pending-example">
  #### Exemplo pendente
</div>

<AgentStatusPending />

<div id="completed-example">
  #### Exemplo concluído
</div>

<AgentStatusCompleted />

<div id="model-selection">
  ## Seleção de modelos
</div>

O Firecrawl Agent oferece dois modelos. **O Spark 1 Mini é 60% mais barato** e é o padrão — perfeito para a maioria dos casos de uso. Atualize para o Spark 1 Pro quando precisar de máxima precisão em tarefas complexas.

| Model | Cost | Accuracy | Best For |
|-------|------|----------|----------|
| `spark-1-mini` | **60% mais barato** | Padrão | A maioria das tarefas (padrão) |
| `spark-1-pro` | Padrão | Mais alta | Pesquisa complexa, extrações críticas |

<Tip>
  **Comece com o Spark 1 Mini** (padrão) — ele lida bem com a maioria das tarefas de extração com um custo 60% menor. Altere para o Pro apenas para pesquisas complexas em múltiplos domínios ou quando a precisão for crítica.
</Tip>

<div id="spark-1-mini-default">
  ### Spark 1 Mini (Padrão)
</div>

`spark-1-mini` é nosso modelo eficiente, ideal para tarefas simples de extração de dados.

**Use o Mini quando:**

* Extraindo dados simples (informações de contato, preços, etc.)
* Trabalhando com sites bem estruturados
* Custo-benefício é uma prioridade
* Executando trabalhos de extração em grande escala

<div id="spark-1-pro">
  ### Spark 1 Pro
</div>

`spark-1-pro` é o nosso principal modelo, projetado para máxima precisão em tarefas complexas de extração.

**Use o Pro quando:**

* Realizar análises competitivas complexas
* Extrair dados que exigem raciocínio profundo
* A precisão for crítica para o seu caso de uso
* Lidar com dados ambíguos ou difíceis de encontrar

<div id="specifying-a-model">
  ### Especificando um modelo
</div>

Informe o parâmetro `model` para selecionar qual modelo usar:

<CodeGroup>
  <AgentWithModelPython />

  <AgentWithModelJS />

  <AgentWithModelCURL />
</CodeGroup>

<div id="parameters">
  ## Parâmetros
</div>

| Parâmetro | Tipo | Obrigatório | Descrição |
|-----------|------|-------------|-----------|
| `prompt` | string | **Sim** | Descrição em linguagem natural dos dados que você quer extrair (máx. 10.000 caracteres) |
| `model` | string | Não | Modelo a ser utilizado: `spark-1-mini` (padrão) ou `spark-1-pro` |
| `urls` | array | Não | Lista opcional de URLs para direcionar a extração |
| `schema` | object | Não | Esquema JSON opcional para saída estruturada |
| `maxCredits` | number | Não | Número máximo de créditos a serem usados nesta tarefa de agente. O padrão é **2.500** se não for definido. Se o limite for atingido, a tarefa falha e **nenhum dado é retornado**, mas os créditos consumidos pelo trabalho já realizado ainda serão cobrados. |

<div id="agent-vs-extract-whats-improved">
  ## Agent vs Extract: O que melhorou
</div>

| Recurso | Agent (Novo) | Extract |
|---------|-------------|---------|
| URLs obrigatórias | Não | Sim |
| Velocidade | Mais rápida | Padrão |
| Custo | Mais baixo | Padrão |
| Confiabilidade | Maior | Padrão |
| Flexibilidade das consultas | Alta | Moderada |

<div id="example-use-cases">
  ## Exemplos de Casos de Uso
</div>

* **Pesquisa**: &quot;Encontre as 5 principais startups de IA e seus valores de financiamento&quot;
* **Análise de concorrência**: &quot;Compare os planos de preços do Slack e do Microsoft Teams&quot;
* **Coleta de dados**: &quot;Extraia informações de contato de sites de empresas&quot;
* **Resumo de conteúdo**: &quot;Resuma as postagens de blog mais recentes sobre web scraping&quot;

<div id="csv-upload-in-agent-playground">
  ## Upload de CSV no Agent Playground
</div>

O [Agent Playground](https://www.firecrawl.dev/app/agent) oferece suporte a upload de CSV para processamento em lote. Envie um arquivo CSV contendo seus dados de entrada (por exemplo, nomes de empresas, URLs ou quaisquer entidades), escreva um prompt descrevendo quais dados deseja que o agente encontre para cada linha, defina seus campos de saída e execute — o agente processa cada linha em paralelo e preenche os resultados.

<div id="api-reference">
  ## Referência da API
</div>

Confira a [referência da Agent API](/pt-BR/api-reference/endpoint/agent) para mais detalhes.

Tem alguma sugestão ou precisa de ajuda? Envie um e-mail para [help@firecrawl.com](mailto:help@firecrawl.com).

<div id="pricing">
  ## Preços
</div>

O Firecrawl Agent usa **cobrança dinâmica**, que acompanha a complexidade da sua solicitação de extração de dados. Você paga com base no trabalho efetivamente realizado pelo Agent, garantindo preços justos tanto ao extrair dados simples quanto informações estruturadas complexas de múltiplas fontes.

<div id="how-agent-pricing-works">
  ### Como funciona o preço do Agent
</div>

Os preços do Agent são **dinâmicos e baseados em créditos** durante o Research Preview:

* **Extrações simples** (como informações de contato de uma única página) normalmente consomem menos créditos e custam menos
* **Tarefas de pesquisa complexas** (como análise de concorrência em vários domínios) consomem mais créditos, mas refletem o esforço total envolvido
* **Uso transparente** mostra exatamente quantos créditos cada requisição consumiu
* **Conversão de créditos** converte automaticamente o uso de créditos do Agent em créditos para facilitar a cobrança

<Info>
  O uso de créditos varia de acordo com a complexidade do seu prompt, a quantidade de dados processados e a estrutura do resultado solicitado. Como orientação geral, a maioria das execuções do Agent consome **algumas centenas de créditos**, embora tarefas simples em uma única página possam usar menos e pesquisas complexas em vários domínios possam usar mais.
</Info>

<div id="parallel-agents-pricing">
  ### Preços para Agentes em Paralelo
</div>

Se você estiver executando vários agentes em paralelo com o Spark-1 Fast, o custo se torna muito mais previsível: 10 créditos por célula.

<div id="getting-started">
  ### Começando
</div>

**Todos os usuários** recebem **5 execuções gratuitas por dia** para explorar os recursos do Agent sem nenhum custo.

O uso adicional é cobrado com base no consumo de créditos e convertido em créditos.

<div id="managing-costs">
  ### Gerenciando custos
</div>

Agent pode ser caro, mas há algumas maneiras de reduzir o custo:

* **Comece com execuções gratuitas**: Use suas 5 solicitações gratuitas diárias para entender os preços
* **Defina o parâmetro `maxCredits`**: Limite seus gastos definindo um número máximo de créditos que você está disposto a usar
* **Otimize os prompts**: Prompts mais específicos geralmente usam menos créditos
* **Monitore o uso**: Acompanhe seu consumo pelo painel
* **Ajuste expectativas**: Pesquisas complexas em múltiplos domínios vão consumir mais créditos do que extrações simples de uma única página

Teste o Agent agora em [firecrawl.dev/app/agent](https://www.firecrawl.dev/app/agent) para ver como o uso de créditos escala com seus casos de uso específicos.

<Note>
  Os preços estão sujeitos a alteração à medida que avançamos de Research Preview para disponibilidade geral. Usuários atuais receberão aviso antecipado sobre quaisquer atualizações de preços.
</Note>