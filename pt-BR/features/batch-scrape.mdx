---
title: 'Raspagem em lote'
description: 'Raspe várias URLs em lote'
og:title: 'Raspagem em lote | Firecrawl'
og:description: 'Raspe várias URLs em lote'
---

import BatchScrapePython from '/snippets/pt-BR/v2/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/pt-BR/v2/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/pt-BR/v2/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/pt-BR/v2/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/pt-BR/v2/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/pt-BR/v2/batch-scrape/json/python.mdx';
import BatchScrapeExtractNode from '/snippets/pt-BR/v2/batch-scrape/json/js.mdx';
import BatchScrapeExtractCURL from '/snippets/pt-BR/v2/batch-scrape/json/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/pt-BR/v2/batch-scrape/json/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/pt-BR/v2/batch-scrape/json/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/pt-BR/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## Coleta em lote de várias URLs
</div>

Agora você pode coletar em lote várias URLs simultaneamente. A função recebe as URLs iniciais e parâmetros opcionais como argumentos. O argumento params permite especificar opções adicionais para a tarefa de coleta em lote, como os formatos de saída.

<div id="how-it-works">
  ### Como funciona
</div>

Funciona de forma muito semelhante ao endpoint `/crawl`. Você pode iniciar o lote e aguardar a conclusão ou iniciá-lo e lidar com a conclusão por conta própria.

* `batchScrape` (JS) / `batch_scrape` (Python): inicia um job em lote e aguarda a conclusão, retornando os resultados.
* `startBatchScrape` (JS) / `start_batch_scrape` (Python): inicia um job em lote e retorna o ID do job para que você possa fazer polling ou usar webhooks.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

Chamar `batchScrape`/`batch_scrape` retorna os resultados completos quando o lote é concluído.

<BatchScrapeOutput />

Chamar `startBatchScrape`/`start_batch_scrape` retorna
um ID de job que você pode acompanhar via `getBatchScrapeStatus`/`get_batch_scrape_status`, usando
o endpoint da API `/batch/scrape/{id}` ou webhooks. Os resultados do job ficam disponíveis via API por 24 horas após a conclusão. Depois desse período, você ainda pode visualizar o histórico e os resultados dos seus batch scrapes nos [activity logs](https://www.firecrawl.dev/app/logs).

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-structured-extraction">
  ## Coleta em lote com extração estruturada
</div>

Você também pode usar o endpoint de coleta em lote para extrair dados estruturados das páginas. Isso é útil se você quiser obter os mesmos dados estruturados de uma lista de URLs.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

`batchScrape`/`batch_scrape` retorna resultados completos:

<BatchScrapeExtractOutput />

`startBatchScrape`/`start_batch_scrape` retorna um ID de tarefa:

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Raspagem em lote com webhooks
</div>

Você pode configurar webhooks para receber notificações em tempo real conforme cada URL do seu lote é raspada. Isso permite processar os resultados imediatamente, em vez de esperar a conclusão de todo o lote.

<BatchScrapeWebhookCURL />

<div id="quick-reference">
  ### Referência rápida
</div>

**Tipos de eventos:**

* `batch_scrape.started` - Quando a raspagem em lote começa
* `batch_scrape.page` - Para cada URL raspada com sucesso
* `batch_scrape.completed` - Quando todas as URLs são processadas
* `batch_scrape.failed` - Se a raspagem em lote encontrar um erro

**Payload básico:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Dados da página para eventos 'page'
  "metadata": {}, // Your custom metadata
  "error": null
}
```

<div id="security-verifying-webhook-signatures">
  ### Segurança: Verificando Assinaturas de Webhook
</div>

Toda requisição de webhook do Firecrawl inclui o cabeçalho `X-Firecrawl-Signature` contendo uma assinatura HMAC-SHA256. **Sempre verifique essa assinatura** para garantir que o webhook é autêntico e não foi adulterado.

**Como funciona:**

1. Obtenha o segredo do seu webhook na [aba Advanced](https://www.firecrawl.dev/app/settings?tab=advanced) das configurações da sua conta
2. Extraia a assinatura do cabeçalho `X-Firecrawl-Signature`
3. Calcule o HMAC-SHA256 do corpo bruto da requisição usando o seu segredo
4. Compare com o cabeçalho de assinatura usando uma função segura contra ataques de timing

<Warning>
  Nunca processe um webhook sem verificar sua assinatura antes. O cabeçalho `X-Firecrawl-Signature` contém a assinatura no formato: `sha256=abc123def456...`
</Warning>

Para exemplos completos de implementação em JavaScript e Python, consulte a [documentação de Segurança de Webhooks](/pt-BR/webhooks/security).

<div id="full-documentation">
  ### Documentação completa
</div>

Para uma documentação completa sobre webhooks, incluindo payloads de eventos detalhados, configurações avançadas e solução de problemas, consulte a [documentação de webhooks](/pt-BR/webhooks/overview).