---
title: 'Raspagem em lote'
description: 'Raspe várias URLs em lote'
og:title: 'Raspagem em lote | Firecrawl'
og:description: 'Raspe várias URLs em lote'
---

import BatchScrapePython from '/snippets/pt-BR/v2/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/pt-BR/v2/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/pt-BR/v2/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/pt-BR/v2/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/pt-BR/v2/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/pt-BR/v2/batch-scrape/json/python.mdx';
import BatchScrapeExtractNode from '/snippets/pt-BR/v2/batch-scrape/json/js.mdx';
import BatchScrapeExtractCURL from '/snippets/pt-BR/v2/batch-scrape/json/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/pt-BR/v2/batch-scrape/json/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/pt-BR/v2/batch-scrape/json/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/pt-BR/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## Coleta em lote de várias URLs
</div>

Agora você pode coletar em lote várias URLs simultaneamente. A função recebe as URLs iniciais e parâmetros opcionais como argumentos. O argumento params permite especificar opções adicionais para a tarefa de coleta em lote, como os formatos de saída.

<div id="how-it-works">
  ### Como funciona
</div>

Funciona de forma muito semelhante ao endpoint `/crawl`. Você pode iniciar o lote e aguardar a conclusão ou iniciá-lo e lidar com a conclusão por conta própria.

* `batchScrape` (JS) / `batch_scrape` (Python): inicia um job em lote e aguarda a conclusão, retornando os resultados.
* `startBatchScrape` (JS) / `start_batch_scrape` (Python): inicia um job em lote e retorna o ID do job para que você possa fazer polling ou usar webhooks.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

Chamar `batchScrape`/`batch_scrape` retorna os resultados completos quando o lote é concluído.

<BatchScrapeOutput />

Chamar `startBatchScrape`/`start_batch_scrape` retorna
um ID de job que você pode acompanhar via `getBatchScrapeStatus`/`get_batch_scrape_status`, usando
o endpoint da API `/batch/scrape/{id}` ou webhooks. Esse endpoint é indicado para
consultas em andamento ou imediatamente após a conclusão, **pois jobs em lote expiram após
24 horas**.

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-structured-extraction">
  ## Coleta em lote com extração estruturada
</div>

Você também pode usar o endpoint de coleta em lote para extrair dados estruturados das páginas. Isso é útil se você quiser obter os mesmos dados estruturados de uma lista de URLs.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Resposta
</div>

`batchScrape`/`batch_scrape` retorna resultados completos:

<BatchScrapeExtractOutput />

`startBatchScrape`/`start_batch_scrape` retorna um ID de tarefa:

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Raspagem em lote com webhooks
</div>

Você pode configurar webhooks para receber notificações em tempo real conforme cada URL do seu lote é raspada. Isso permite processar os resultados imediatamente, em vez de esperar a conclusão de todo o lote.

<BatchScrapeWebhookCURL />

Para uma documentação completa sobre webhooks, incluindo tipos de eventos, estrutura do payload e exemplos de implementação, consulte a [documentação de webhooks](/pt-BR/webhooks/overview).

<div id="quick-reference">
  ### Referência rápida
</div>

**Tipos de eventos:**

* `batch_scrape.started` - Quando a raspagem em lote começa
* `batch_scrape.page` - Para cada URL raspada com sucesso
* `batch_scrape.completed` - Quando todas as URLs são processadas
* `batch_scrape.failed` - Se a raspagem em lote encontrar um erro

**Payload básico:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Dados da página para eventos 'page'
  "metadata": {}, // Seus metadados customizados
  "error": null
}
```

<Note>
  Para configurações detalhadas de webhooks, práticas recomendadas de segurança e
  solução de problemas, acesse a [documentação de Webhooks](/pt-BR/webhooks/overview).
</Note>
