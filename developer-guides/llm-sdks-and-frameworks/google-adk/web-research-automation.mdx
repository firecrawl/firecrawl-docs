---
title: "Automate Web Research with Firecrawl and Google Calendar"
description: "Learn how to build an AI agent using Google ADK that scrapes web data with Firecrawl and automatically schedules calendar reminders"
---

## What You'll Build

![Firecrawl and Google ADK agent automating web research and calendar scheduling](/images/guides/google-adk-cookbook/firecrawl-google-adk-research-automation.png)

In this tutorial, you'll build an intelligent research assistant that combines **Firecrawl's powerful web scraping capabilities** with **Google Calendar automation** to help you stay organized and informed. The agent can:

- Search and scrape web content on any topic using Firecrawl's MCP server
- Extract key information, news, and data from websites automatically
- Schedule calendar events and reminders for follow-ups, meetings, or deadlines
- Organize your research workflow intelligently based on your preferences

This is perfect for researchers, analysts, project managers, developers, or anyone who needs to track information and schedule time for important tasks.

## Getting Started

### Prerequisites

Before you begin, make sure you have:

- **Python 3.9 or later** installed on your system
- **pip** for installing packages
- A **Google AI Studio API key** (for Gemini)
- A **Firecrawl API key** (for web scraping)
- **Google OAuth credentials** (for Calendar access)

### Step 1: Install Google ADK

We recommend creating and activating a Python virtual environment first:

```bash
# Create a virtual environment
python -m venv .venv

# Activate the virtual environment
# On Windows CMD:
.venv\Scripts\activate.bat

# On Windows PowerShell:
.venv\Scripts\Activate.ps1

# On macOS/Linux:
source .venv/bin/activate
```

Install the Agent Development Kit:

```bash
pip install google-adk
```

### Step 2: Create Your Agent Project

Run the `adk create` command to start a new agent project:

```bash
adk create my_research_agent
cd my_research_agent
```

This creates a project structure with:
- `agent.py` - Main agent code
- `.env` - API keys and credentials
- `__init__.py`

## Getting Your API Keys

### Google AI Studio API Key

1. Visit [Google AI Studio](https://aistudio.google.com/app/api-keys)
2. Sign in with your Google account
3. Click "Create API Key" or "Get API Key"
4. Copy the generated API key

### Firecrawl API Key

1. Visit [Firecrawl API Keys](https://www.firecrawl.dev/app/api-keys)
2. Sign up or log in to your Firecrawl account
3. Navigate to the API Keys section
4. Copy your API key or create a new one

Add both keys to your `.env` file:

```bash
GOOGLE_GENAI_USE_VERTEXAI=0
GOOGLE_API_KEY=your_google_api_key_here

FIRECRAWL_API_KEY=your_firecrawl_api_key_here
```

## Testing Firecrawl Integration

At this point, you can test your agent with just Firecrawl capabilities. Update your `agent.py` with the basic Firecrawl setup:

```python
from google.adk.agents.llm_agent import Agent
from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
from mcp import StdioServerParameters
from dotenv import load_dotenv
import os

load_dotenv()

FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")

root_agent = Agent(
    model="gemini-2.5-pro",
    name="firecrawl_agent",
    description="A helpful assistant for scraping websites with Firecrawl",
    instruction="Help the user search for website content",
    tools=[
        MCPToolset(
            connection_params=StdioConnectionParams(
                server_params=StdioServerParameters(
                    command="npx",
                    args=[
                        "-y",
                        "firecrawl-mcp",
                    ],
                    env={
                        "FIRECRAWL_API_KEY": FIRECRAWL_API_KEY,
                    }
                ),
                timeout=30,
            ),
        )
    ],
)
```

Run your agent in development mode:

```bash
adk dev
```

Try asking it to search for and scrape content on a topic. The agent now has access to all Firecrawl tools including search, scrape, crawl, and extract.

## Adding Google Calendar Integration

Now let's add Google Calendar functionality to automatically schedule events and reminders based on your research findings.

### Getting Google OAuth Credentials

To integrate with Google Calendar, you need OAuth 2.0 credentials:

1. Go to the [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select an existing one
3. Enable the **Google Calendar API**:
   - Navigate to "APIs & Services" > "Library"
   - Search for "Google Calendar API"
   - Click "Enable"
4. Create OAuth 2.0 credentials:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Select "Desktop app" as the application type
   - Click "Create"
5. Copy your **Client ID** and **Client Secret**

Add these credentials to your `.env` file:

```bash
GOOGLE_GENAI_USE_VERTEXAI=0
GOOGLE_API_KEY=your_google_api_key_here

FIRECRAWL_API_KEY=your_firecrawl_api_key_here

OAUTH_CLIENT_ID=your_oauth_client_id_here
OAUTH_CLIENT_SECRET=your_oauth_client_secret_here
```

<Warning>
**Security Note**: Never commit your `.env` file to version control. Make sure `.env` is listed in your `.gitignore` file.
</Warning>

### Understanding ADK Tools

Google ADK provides two types of tools for building agents:

1. **[Google Cloud Tools](https://google.github.io/adk-docs/tools/google-cloud-tools/)** - Official Google services
   - Gmail, Calendar, Drive, Sheets, and more
   - We'll use the **Calendar Toolset** for this cookbook

2. **[Third-Party Tools](https://google.github.io/adk-docs/tools/third-party/)** - External integrations
   - [Firecrawl](https://google.github.io/adk-docs/tools/third-party/firecrawl/) - Web scraping and crawling
   - We're using Firecrawl's MCP Server for data extraction

Learn more about all available tools in the [ADK Tools documentation](https://google.github.io/adk-docs/tools/).

## Complete Implementation

Here's the complete script that combines Firecrawl for web research and Google Calendar for scheduling:

```python
from google.adk.agents import LlmAgent
from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
from google.adk.tools.google_api_tool import CalendarToolset
from mcp import StdioServerParameters
from dotenv import load_dotenv
import os
from pathlib import Path

# Load .env file from the same directory as this file
env_path = Path(__file__).parent / '.env'
load_dotenv(env_path)

# Load configuration from environment variables
FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")
OAUTH_CLIENT_ID = os.getenv("OAUTH_CLIENT_ID")
OAUTH_CLIENT_SECRET = os.getenv("OAUTH_CLIENT_SECRET")
MODEL = "gemini-2.5-pro"

tools = [
    # Firecrawl MCP Tool
    MCPToolset(
        connection_params=StdioConnectionParams(
            server_params=StdioServerParameters(
                command="npx",
                args=["-y", "firecrawl-mcp"],
                env={"FIRECRAWL_API_KEY": FIRECRAWL_API_KEY}
            ),
            timeout=30,
        ),
    ),
    # Google Calendar Toolset with OAuth
    CalendarToolset(
        client_id=OAUTH_CLIENT_ID,
        client_secret=OAUTH_CLIENT_SECRET
    ),
]

# Create the agent
root_agent = LlmAgent(
    model=MODEL,
    name="firecrawl_calendar_agent",
    description="A helpful AI assistant that scrapes websites with Firecrawl and manages your Google Calendar using natural language.",
    instruction="You are a helpful AI assistant that can scrape websites with Firecrawl and manage Google Calendar events. Help users research topics and schedule events based on their needs.",
    tools=tools,
)
```

### Environment Variables

Your complete `.env` file should look like this:

```bash
# Google AI Configuration
GOOGLE_GENAI_USE_VERTEXAI=0
GOOGLE_API_KEY=your_google_api_key_here

# Firecrawl API Key
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# Google OAuth Credentials
OAUTH_CLIENT_ID=your_oauth_client_id_here
OAUTH_CLIENT_SECRET=your_oauth_client_secret_here
```

<Warning>
Replace all placeholder values (`your_*_here`) with your actual credentials. Never share these credentials publicly.
</Warning>

## Running Your Agent

Once you've set up all the credentials and implemented the agent:

1. Make sure your virtual environment is activated
2. Run the agent in development mode:

```bash
adk dev
```

3. Try prompts like:
   - "Search for the latest news about artificial intelligence and schedule a meeting for tomorrow to discuss it with my team"
   - "Find articles about Python 3.13 features and add a reminder to my calendar for next week to review them"
   - "Research recent developments in quantum computing and block off time on Friday for me to dive deeper"
   - "Look up upcoming tech conferences and add deadlines for registration to my calendar"

The agent will:
- Use Firecrawl's search tool to find relevant content across the web
- Scrape and extract key information from web pages automatically
- Create Google Calendar events with detailed descriptions based on your preferences
- Provide summaries and insights about the content it discovered

## Troubleshooting

### Firecrawl Search Tool Schema Issues

If you encounter errors when the agent tries to use the `firecrawl_search` tool, it's likely due to incorrect parameter formatting. The "sources" parameter **must be an array of objects**, not an array of strings.

**Common Error:**
The agent might try to use:
```json
{
  "query": "search terms",
  "sources": ["web", "news", "images"]
}
```

**Correct Format:**
Update your agent's instruction to specify the correct format:

```python
instruction="""You are a helpful AI assistant that can scrape websites with Firecrawl and manage Google Calendar events.

IMPORTANT: When using the firecrawl_search tool, the "sources" parameter MUST be an array of objects, NOT strings.

**CORRECT format:**
{
  "query": "search terms",
  "sources": [
    {"type": "web"},
    {"type": "news"},
    {"type": "images"}
  ]
}

Available source types:
- {"type": "web"} - for web search (can include optional "tbs" and "location" fields)
- {"type": "news"} - for news search
- {"type": "images"} - for image search

When the user asks you to scrape content and add it to their calendar:
1. First, use Firecrawl to fetch the content
2. Then, use the calendar tools to create an appropriate calendar event

Always be helpful, clear, and concise. When working with dates and times, clarify any ambiguities with the user.
""",
```

This explicitly instructs the agent on the correct schema format for Firecrawl's search tool.

## Example Use Cases

Here are some practical ways to use this automation:

- **Research Tracking**: Monitor industry news and schedule regular review sessions
- **Competitive Analysis**: Track competitor updates and set reminders to analyze changes
- **Project Management**: Scrape project-related resources and schedule follow-up tasks
- **Learning & Development**: Find tutorials or courses and block calendar time for studying
- **Event Planning**: Research venues, speakers, or topics and coordinate scheduling
- **Data Collection**: Gather market data and schedule analysis meetings

## Next Steps

Now that you have a working research automation agent, you can extend it further:

- Add more sophisticated scheduling logic (e.g., recurring events, different calendars for different topics)
- Integrate additional tools like Gmail to send yourself summaries or notifications
- Use Firecrawl's extract tool for structured data extraction (prices, dates, contacts, etc.)
- Create multi-agent workflows for complex research and coordination tasks
- Add filters to prioritize certain types of content or sources

## Related Resources

<CardGroup cols={2}>
  <Card title="Google ADK Overview" href="/developer-guides/llm-sdks-and-frameworks/google-adk/overview">
    Learn about all Firecrawl + Google ADK integration features and setup options
  </Card>
  <Card title="Building AI Agents with Google ADK and Firecrawl" href="https://www.firecrawl.dev/blog/google-adk-multi-agent-tutorial">
    Comprehensive guide to building powerful multi-agent AI systems
  </Card>
  <Card title="Firecrawl MCP Server" href="https://docs.firecrawl.dev/mcp-server">
    Deep dive into Firecrawl's Model Context Protocol integration
  </Card>
  <Card title="Google ADK Tools Documentation" href="https://google.github.io/adk-docs/tools/">
    Explore all available tools for your ADK agents
  </Card>
</CardGroup>
