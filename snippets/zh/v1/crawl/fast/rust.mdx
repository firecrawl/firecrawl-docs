```rust Rust
use firecrawl::FirecrawlApp;
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let app = FirecrawlApp::new("fc-YOUR_API_KEY").expect("FirecrawlApp 初始化失败");

    // 使用缓存抓取进行爬取——对最近访问过的页面可快 500%
    let mut scrape_options = HashMap::new();
    scrape_options.insert("formats", vec!["markdown"]);
    scrape_options.insert("maxAge", 3600000); // 若数据生成时间少于 1 小时则使用缓存

    let mut crawl_params = HashMap::new();
    crawl_params.insert("limit", 100);
    crawl_params.insert("scrapeOptions", scrape_options);

    let crawl_result = app.crawl_url("https://firecrawl.dev", Some(crawl_params)).await?;

    for page in crawl_result.data {
        println!("URL: {}", page.metadata.get("sourceURL").unwrap_or(&"未知".to_string()));
        let content = page.markdown.unwrap_or_default();
        if content.len() > 200 {
            println!("内容：{}...", &content[..200]);
        } else {
            println!("内容：{}", content);
        }
    }

    Ok(())
}
```
