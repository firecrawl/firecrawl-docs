```js Node
import FirecrawlApp, { ScrapeResponse } from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Define un esquema para extraer el contenido
const schema = {
  type: "object",
  properties: {
    title: { type: "string" },
    description: { type: "string" }
  },
  required: ["title", "description"]
};

// Extrae varios sitios web (sincrónico):
const batchScrapeResult = await app.batchScrapeUrls(['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], { 
  formats: ['json'],
  jsonOptions: {
    prompt: "Extrae el título y la descripción de la página.",
    schema: schema
  }
});

if (!batchScrapeResult.success) {
  throw new Error(`Failed to scrape: ${batchScrapeResult.error}`)
}
// Muestra todos los resultados de la extracción por lotes:
console.log(batchScrapeResult)

// O puedes usar el método asíncrono:
const batchScrapeJob = await app.asyncBulkScrapeUrls(['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], { 
  formats: ['json'],
  jsonOptions: {
    prompt: "Extrae el título y la descripción de la página.",
    schema: schema
  }
});
console.log(batchScrapeJob)

// (asíncrono) Luego puedes usar el ID del trabajo para comprobar el estado de la extracción por lotes:
const batchScrapeStatus = await app.checkBatchScrapeStatus(batchScrapeJob.id);
console.log(batchScrapeStatus)
```
