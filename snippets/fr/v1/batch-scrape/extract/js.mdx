```js Node.js
import FirecrawlApp, { ScrapeResponse } from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Définissez le schéma dans lequel extraire le contenu
const schema = {
  type: "object",
  properties: {
    title: { type: "string" },
    description: { type: "string" }
  },
  required: ["title", "description"]
};

// Scrape multiple websites (synchronous):
const batchScrapeResult = await app.batchScrapeUrls(['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], { 
  formats: ['json'],
  jsonOptions: {
    prompt: "Extrait le titre et la description de la page.",
    schema: schema
  }
});

if (!batchScrapeResult.success) {
  throw new Error(`Échec du scraping : ${batchScrapeResult.error}`)
}
// Affiche tous les résultats du scraping par lot :
console.log(batchScrapeResult)

// Vous pouvez aussi utiliser la méthode asynchrone :
const batchScrapeJob = await app.asyncBulkScrapeUrls(['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], { 
  formats: ['json'],
  jsonOptions: {
    prompt: "Extrait le titre et la description de la page.",
    schema: schema
  }
});
console.log(batchScrapeJob)

// (async) Vous pouvez ensuite utiliser l’ID du job pour vérifier le statut du scraping par lot :
const batchScrapeStatus = await app.checkBatchScrapeStatus(batchScrapeJob.id);
console.log(batchScrapeStatus)
```
