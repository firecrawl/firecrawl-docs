```python Python
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Extraire plusieurs sites web :
batch_scrape_result = app.batch_scrape_urls(
    ['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], 
    formats=['json'],
    jsonOptions={
        'prompt': 'Extrait le titre et la description de la page.',
        'schema': {
            'type': 'object',
            'properties': {
                'title': {'type': 'string'},
                'description': {'type': 'string'}
            },
            'required': ['title', 'description']
        }
    }
)
print(batch_scrape_result)

# Vous pouvez aussi utiliser la méthode asynchrone :
batch_scrape_job = app.async_batch_scrape_urls(
    ['https://docs.firecrawl.dev', 'https://docs.firecrawl.dev/sdks/overview'], 
    formats=['json'],
    jsonOptions={
    'prompt': 'Extrait le titre et la description de la page.',
    'schema': {
        'type': 'object',
            'properties': {
                'title': {'type': 'string'},
                'description': {'type': 'string'}
            },
            'required': ['title', 'description']
        }
    }
)
print(batch_scrape_job)

# (async) Vous pouvez ensuite utiliser l’ID de la tâche pour vérifier l’état de l’extraction par lots :
batch_scrape_status = app.check_batch_scrape_status(batch_scrape_job.id)
print(batch_scrape_status)
```
