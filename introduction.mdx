---
title: Quickstart
description: "Firecrawl allows you to turn entire websites into LLM-ready markdown"
og:title: "Quickstart | Firecrawl"
og:description: "Firecrawl allows you to turn entire websites into LLM-ready markdown"
---

import InstallationPython from "/snippets/v2/installation/python.mdx";
import InstallationNode from "/snippets/v2/installation/js.mdx";
import InstallationCLI from "/snippets/v2/installation/cli.mdx";
import ScrapePython from "/snippets/v2/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v2/scrape/base/js.mdx";
import ScrapeCURL from "/snippets/v2/scrape/base/curl.mdx";
import ScrapeCLI from "/snippets/v2/scrape/base/cli.mdx";
import ScrapeResponse from "/snippets/v2/scrape/base/output.mdx";
import CrawlPython from "/snippets/v2/crawl/base/python.mdx";
import CrawlNode from "/snippets/v2/crawl/base/js.mdx";
import CrawlCURL from "/snippets/v2/crawl/base/curl.mdx";
import CrawlCLI from "/snippets/v2/crawl/base/cli.mdx";
import CrawlAsyncOutput from "/snippets/v2/start-crawl/base/output.mdx";
import GetCrawlJobPython from "/snippets/v2/crawl-status/short/python.mdx";
import GetCrawlJobNode from "/snippets/v2/crawl-status/short/js.mdx";
import GetCrawlJobCURL from "/snippets/v2/crawl-status/short/curl.mdx";
import GetCrawlJobCLI from "/snippets/v2/crawl-status/short/cli.mdx";
import GetCrawlJobOutputScraping from "/snippets/v2/crawl-status/base/output-scraping.mdx";
import GetCrawlJobOutputCompleted from "/snippets/v2/crawl-status/base/output-completed.mdx";
import ScrapeJsonCURL from "/snippets/v2/scrape/json/base/curl.mdx";
import ScrapeJsonPython from "/snippets/v2/scrape/json/base/python.mdx";
import ScrapeJsonNode from "/snippets/v2/scrape/json/base/js.mdx";
import ScrapeJsonOutput from "/snippets/v2/scrape/json/base/output.mdx";
import ScrapeJsonNoSchemaCURL from "/snippets/v2/scrape/json/no-schema/curl.mdx";
import ScrapeJsonNoSchemaPython from "/snippets/v2/scrape/json/no-schema/python.mdx";
import ScrapeJsonNoSchemaNode from "/snippets/v2/scrape/json/no-schema/js.mdx";
import ScrapeJsonNoSchemaOutput from "/snippets/v2/scrape/json/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/v2/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/v2/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/v2/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/v2/scrape/actions/output.mdx";
import SearchPython from "/snippets/v2/search/base/python.mdx";
import SearchNode from "/snippets/v2/search/base/js.mdx";
import SearchCURL from "/snippets/v2/search/base/curl.mdx";
import SearchCLI from "/snippets/v2/search/base/cli.mdx";
import SearchResponse from "/snippets/v2/search/base/output.mdx";

## Scrape your first website

Turn any website into clean, LLM-ready data with a single API call.

<CardGroup cols={2}>
  <Card title="Get your API key" icon="key" href="https://www.firecrawl.dev/app/api-keys">
    Sign up and get your API key to start scraping
  </Card>
  <Card title="Try it in the Playground" icon="play" href="https://www.firecrawl.dev/playground">
    Test the API instantly without writing any code
  </Card>
</CardGroup>

### Make your first request

Copy the code below, replace `fc-YOUR-API-KEY` with your API key, and run it:

<CodeGroup>

```bash cURL
curl -X POST 'https://api.firecrawl.dev/v2/scrape' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -H 'Content-Type: application/json' \
  -d '{"url": "https://example.com"}'
```

```python Python
from firecrawl import Firecrawl

app = Firecrawl(api_key="fc-YOUR-API-KEY")
result = app.scrape("https://example.com")
print(result)
```

```javascript Node
import Firecrawl from '@mendable/firecrawl-js';

const app = new Firecrawl({ apiKey: "fc-YOUR-API-KEY" });
const result = await app.scrape("https://example.com");
console.log(result);
```

</CodeGroup>

<Accordion title="Example response">
```json
{
  "success": true,
  "data": {
    "markdown": "# Example Domain\n\nThis domain is for use in illustrative examples...",
    "metadata": {
      "title": "Example Domain",
      "sourceURL": "https://example.com"
    }
  }
}
```
</Accordion>

### Install the SDK (optional)

For a better developer experience, install our official SDKs:

<CodeGroup>

  <InstallationPython />

  <InstallationNode />

  <InstallationCLI />

</CodeGroup>

---

## What can Firecrawl do?

<CardGroup cols={2}>
  <Card title="Scrape" icon="file-lines" href="#scraping">
    Extract content from any URL in markdown, HTML, or structured JSON
  </Card>
  <Card title="Crawl" icon="spider" href="#crawling">
    Scrape all pages of a website automatically
  </Card>
  <Card title="Search" icon="magnifying-glass" href="#search">
    Search the web and get full page content from results
  </Card>
  <Card title="Extract" icon="wand-magic-sparkles" href="/features/extract">
    Get structured data from websites using AI
  </Card>
</CardGroup>

### Why Firecrawl?

- **LLM-ready output**: Get clean markdown, structured JSON, screenshots, and more
- **Handles the hard stuff**: Proxies, anti-bot, JavaScript rendering, and dynamic content
- **Reliable**: Built for production with high uptime and consistent results
- **Fast**: Get results in seconds, optimized for high-throughput

---

## Scraping

Scrape any URL and get its content in markdown, HTML, or other formats. See the [Scrape feature docs](/features/scrape) for all options.

<CodeGroup>

  <ScrapePython />

  <ScrapeNode />

  <ScrapeCURL />

  <ScrapeCLI />

</CodeGroup>

<Accordion title="Response">

SDKs will return the data object directly. cURL will return the payload exactly as shown below.

<ScrapeResponse />

</Accordion>


## Crawling

The crawl feature allows you to automatically discover and extract content from a URL and all of its accessible subpages. With our SDKs, simply call the crawl methodâ€”this will submit a crawl job, wait for it to finish, and return the complete results for the entire site.



### Usage

<CodeGroup>

<CrawlPython />
<CrawlNode />
<CrawlCURL />
<CrawlCLI />

</CodeGroup>

If you're using our API directly, cURL or `start crawl` functions on SDKs, this will return an `ID` where you can use to check the status of the crawl.

<CrawlAsyncOutput />

### Get Crawl Status

Used to check the status of a crawl job and get its result.

<CodeGroup>

<GetCrawlJobPython />
<GetCrawlJobNode />
<GetCrawlJobCURL />
<GetCrawlJobCLI />

</CodeGroup>

#### Response

The response will be different depending on the status of the crawl. For not completed or large responses exceeding 10MB, a `next` URL parameter is provided. You must request this URL to retrieve the next 10MB of data. If the `next` parameter is absent, it indicates the end of the crawl data.

<CodeGroup>
  <GetCrawlJobOutputScraping />
  <GetCrawlJobOutputCompleted />
</CodeGroup>


## JSON mode

With JSON mode, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:

<CodeGroup>

<ScrapeJsonPython />
<ScrapeJsonNode />
<ScrapeJsonCURL />

</CodeGroup>

Output:

<ScrapeJsonOutput />


## Search

Firecrawl's search API allows you to perform web searches and optionally scrape the search results in one operation.

- Choose specific output formats (markdown, HTML, links, screenshots)
- Choose specific sources (web, news, images)
- Search the web with customizable parameters (location, etc.)

For details, see the [Search Endpoint API Reference](/api-reference/endpoint/search).

<CodeGroup>

<SearchPython />
<SearchNode />
<SearchCURL />
<SearchCLI />

</CodeGroup>

### Response

SDKs will return the data object directly. cURL will return the complete payload.

<SearchResponse />


### Extracting without schema

You can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.

<CodeGroup>
  <ScrapeJsonNoSchemaPython />
  <ScrapeJsonNoSchemaNode />
  <ScrapeJsonNoSchemaCURL />
</CodeGroup>

Output:

<ScrapeJsonNoSchemaOutput />

## Interacting with the page with Actions

Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.

Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.

It is important to almost always use the `wait` action before/after executing other actions to give enough time for the page to load.

### Example

<CodeGroup>

<ScrapeActionsPython />
<ScrapeActionsNode /> 
<ScrapeActionsCURL />

</CodeGroup>

### Output

<CodeGroup>

<ScrapeActionsOutput />

</CodeGroup>

---

## Resources

<CardGroup cols={2}>
  <Card title="API Reference" icon="code" href="/api-reference/v2-introduction">
    Complete API documentation with interactive examples
  </Card>
  <Card title="SDKs" icon="boxes-stacked" href="/sdks/overview">
    Python, Node.js, CLI, and community SDKs
  </Card>
  <Card title="Open Source" icon="github" href="/contributing/open-source-or-cloud">
    Self-host Firecrawl or contribute to the project
  </Card>
  <Card title="Integrations" icon="puzzle-piece" href="/developer-guides/llm-sdks-and-frameworks/openai">
    LangChain, LlamaIndex, OpenAI, and more
  </Card>
</CardGroup>

