---
title: 'CLI'
description: 'Firecrawl CLI 是一个命令行界面，可让你直接在终端中对 Web 进行抓取、爬取、映射和搜索。'
icon: 'terminal'
og:title: "CLI | Firecrawl"
og:description: "Firecrawl CLI 是一个命令行界面，可让你直接在终端中对 Web 进行抓取、爬取、映射和搜索。"
---

import InstallationCLI from '/snippets/zh/v2/cli/installation/bash.mdx'
import AuthLogin from '/snippets/zh/v2/cli/auth/login.mdx'
import AuthLogout from '/snippets/zh/v2/cli/auth/logout.mdx'
import AuthConfig from '/snippets/zh/v2/cli/auth/config.mdx'
import ScrapeBasic from '/snippets/zh/v2/cli/scrape/basic.mdx'
import ScrapeFormats from '/snippets/zh/v2/cli/scrape/formats.mdx'
import ScrapeOptions from '/snippets/zh/v2/cli/scrape/options.mdx'
import CrawlBasic from '/snippets/zh/v2/cli/crawl/basic.mdx'
import CrawlStatus from '/snippets/zh/v2/cli/crawl/status.mdx'
import CrawlOptions from '/snippets/zh/v2/cli/crawl/options.mdx'
import MapBasic from '/snippets/zh/v2/cli/map/basic.mdx'
import MapOptions from '/snippets/zh/v2/cli/map/options.mdx'
import SearchBasic from '/snippets/zh/v2/cli/search/basic.mdx'
import SearchOptions from '/snippets/zh/v2/cli/search/options.mdx'


<div id="installation">
  ## 安装
</div>

使用 npm 全局安装 Firecrawl CLI：

<InstallationCLI />

<div id="authentication">
  ## 身份验证
</div>

在使用 CLI 之前，你需要先使用 Firecrawl API 密钥完成身份验证。

<div id="login">
  ### 登录
</div>

<AuthLogin />

<div id="view-configuration">
  ### 查看配置
</div>

<AuthConfig />

<div id="logout">
  ### 退出登录
</div>

<AuthLogout />

<div id="commands">
  ## 命令
</div>

<div id="scrape">
  ### Scrape
</div>

抓取单个 URL，并以多种 formats 输出其内容。

<ScrapeBasic />

<div id="output-formats">
  #### 输出 formats 类型
</div>

<ScrapeFormats />

<div id="scrape-options">
  #### 抓取选项
</div>

<ScrapeOptions />

**可用选项：**

| 选项 | 简写 | 描述 |
|--------|-------|-------------|
| `--url <url>` | `-u` | 要抓取的 URL（位置参数的替代方式） |
| `--format <formats>` | `-f` | 输出 formats（逗号分隔）：`markdown`, `html`, `rawHtml`, `links`, `images`, `screenshot`, `json` |
| `--html` | `-H` | `--format html` 的快捷方式 |
| `--only-main-content` | | 仅提取主要内容 |
| `--wait-for <ms>` | | 等待 JS 渲染的时间（毫秒） |
| `--screenshot` | | 生成页面截图 |
| `--include-tags <tags>` | | 要包含的 HTML 标签（逗号分隔） |
| `--exclude-tags <tags>` | | 要排除的 HTML 标签（逗号分隔） |
| `--output <path>` | `-o` | 将输出保存到文件 |
| `--pretty` | | 对 JSON 输出进行格式化打印 |

---

<div id="crawl">
  ### Crawl
</div>

从单个 URL 出发爬取整个网站。

<CrawlBasic />

<div id="check-crawl-status">
  #### 查看抓取状态
</div>

<CrawlStatus />

<div id="crawl-options">
  #### Crawl 选项
</div>

<CrawlOptions />

**可用选项：**

| 选项 | 描述 |
|--------|-------------|
| `--url <url>` | 要爬取的 URL（位置参数的替代方式） |
| `--wait` | 等待爬取完成 |
| `--progress` | 等待期间显示进度指示器 |
| `--poll-interval <seconds>` | 轮询间隔（默认：5 秒） |
| `--timeout <seconds>` | 等待时的超时时长 |
| `--status` | 检查已有爬取任务的状态 |
| `--limit <number>` | 最大爬取页面数 |
| `--max-depth <number>` | 最大爬取深度 |
| `--include-paths <paths>` | 要包含的路径（逗号分隔） |
| `--exclude-paths <paths>` | 要排除的路径（逗号分隔） |
| `--allow-subdomains` | 包含子域名 |
| `--allow-external-links` | 跟随外部链接 |
| `--output <path>` | 将输出保存到文件 |
| `--pretty` | 以更易读的格式输出 JSON |

---

<div id="map">
  ### Map
</div>

快速发现站点中的所有 URL。

<MapBasic />

<div id="map-options">
  #### Map 命令选项
</div>

<MapOptions />

**可用选项：**

| 选项 | 描述 |
|--------|-------------|
| `--url <url>` | 要映射的 URL（可替代位置参数） |
| `--limit <number>` | 要发现的最大 URL 数量 |
| `--search <query>` | 根据搜索查询筛选 URL |
| `--sitemap <mode>` | Sitemap 处理模式：`include`、`skip`、`only` |
| `--include-subdomains` | 包含子域名 |
| `--ignore-query-parameters` | 将带有不同参数的 URL 视为同一 URL |
| `--json` | 以 JSON 格式输出 |
| `--output <path>` | 将输出保存到文件 |
| `--pretty` | 以易读格式打印 JSON 输出 |

---

<div id="search">
  ### 搜索
</div>

搜索网页，并按需抓取结果。

<SearchBasic />

<div id="search-options">
  #### 搜索选项
</div>

<SearchOptions />

**可用选项：**

| 选项 | 描述 |
|--------|-------------|
| `--limit <number>` | 结果数量上限（默认：5，最大：100） |
| `--sources <sources>` | 要搜索的数据源：`web`、`images`、`news`（逗号分隔） |
| `--categories <categories>` | 按类别过滤：`github`、`research`、`pdf`（逗号分隔） |
| `--tbs <value>` | 时间过滤：`qdr:h`（小时）、`qdr:d`（天）、`qdr:w`（周）、`qdr:m`（月）、`qdr:y`（年） |
| `--location <location>` | 地域定向（例如："Berlin,Germany"） |
| `--country <code>` | ISO 国家代码（默认：US） |
| `--scrape` | 抓取搜索结果 |
| `--scrape-formats <formats>` | 抓取内容的 formats（默认：markdown） |
| `--only-main-content` | 抓取时仅包含主要内容 |
| `--json` | 以 JSON 格式输出 |
| `--output <path>` | 将输出保存到文件 |
| `--pretty` | 以易读格式打印 JSON 输出 |

---

<div id="credit-usage">
  ### 额度使用情况
</div>

查看你团队的额度余额和使用明细。

```bash CLI
# View credit usage
firecrawl credit-usage

# 以 JSON 格式输出
firecrawl credit-usage --json --pretty
```

***


<div id="version">
  ### Version
</div>

显示 CLI 的版本。

```bash CLI
firecrawl version
# 或
firecrawl --version
```


<div id="global-options">
  ## 全局选项
</div>

以下选项适用于所有命令：

| 选项 | 简写 | 说明 |
|--------|-------|-------------|
| `--api-key <key>` | `-k` | 在此命令中临时覆盖已保存的 API 密钥 |
| `--help` | `-h` | 显示命令帮助信息 |
| `--version` | `-V` | 显示 CLI 版本 |

<div id="output-handling">
  ## 输出处理
</div>

CLI 默认将结果输出到 stdout，便于通过管道或重定向进行处理：

```bash CLI
# 将 Markdown 通过管道传递给另一个命令
firecrawl https://example.com | head -50

# 重定向到文件
firecrawl https://example.com > output.md

# 保存格式化后的 JSON
firecrawl https://example.com --format markdown,links --pretty -o data.json
```


<div id="examples">
  ## 示例
</div>

<div id="quick-scrape">
  ### 快速抓取
</div>

```bash CLI
# 从 URL 获取 Markdown 内容
firecrawl https://docs.firecrawl.dev

# Get HTML content
firecrawl https://example.com --html -o page.html
```


<div id="full-site-crawl">
  ### 整站爬取
</div>

```bash CLI
# 爬取文档站点并设置限制
firecrawl crawl https://docs.example.com --limit 50 --max-depth 2 --wait --progress -o docs.json
```


<div id="site-discovery">
  ### 站点发现
</div>

```bash CLI
# 查找所有博客文章
firecrawl map https://example.com --search "blog" -o blog-urls.txt
```


<div id="research-workflow">
  ### 研究工作流
</div>

```bash CLI
# 搜索并抓取结果用于研究
firecrawl search "machine learning best practices 2024" --scrape --scrape-formats markdown --pretty
```
