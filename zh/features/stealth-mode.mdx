---
title: "隐身模式"
description: "为采用高级反机器人方案的网站使用隐身代理"
og:title: "隐身模式 | Firecrawl"
og:description: "为采用高级反机器人方案的网站使用隐身代理"
---

import ProxyPython from "/snippets/zh/v2/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/zh/v2/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/zh/v2/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/zh/v2/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/zh/v2/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/zh/v2/scrape/proxy-retry/curl.mdx";

Firecrawl 提供多种代理类型，帮助你在面对不同强度的反爬虫措施时抓取网站。可以通过 `proxy` 参数指定代理类型。


<div id="proxy-types">
  ### 代理类型
</div>

Firecrawl 支持三种代理类型：

- **basic**：适用于无反爬或仅有基础反爬的网站。速度快，通常可行。
- **stealth**：适用于有高级反爬的网站的隐身代理。速度较慢，但在某些站点更可靠。
- **auto**：若 basic 代理失败，Firecrawl 会自动使用隐身代理重试抓取。若隐身重试成功，该次抓取计费 5 点额度；若首次使用 basic 即成功，则仅收取常规费用。

如果未指定代理，Firecrawl 默认使用 auto。

<div id="using-stealth-mode">
  ### 使用 stealth 模式
</div>

在抓取具备高级反机器人保护的网站时，可以使用 stealth 代理模式来提高成功率。

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**注意：** 使用 stealth 代理时，每次请求消耗 5 个积分。

<div id="using-stealth-as-a-retry-mechanism">
  ## 将 Stealth 用作重试机制
</div>

一种常见做法是先使用默认代理设置进行抓取；如果在响应的 `metadata.statusCode` 字段中遇到特定错误状态码（401、403 或 500），则改用 stealth 模式重试。这些状态码可能表明网站正在拦截你的请求。

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

这种方法可以让你仅在必要时启用 stealth 模式，从而更高效地使用额度。