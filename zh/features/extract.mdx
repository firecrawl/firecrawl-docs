---
title: "抽取"
description: "使用大语言模型从页面中抽取结构化数据"
og:title: "抽取 | Firecrawl"
og:description: "使用大语言模型从页面中抽取结构化数据"
icon: "barcode-read"
sidebarTitle: "抽取"
---

import ExtractCURL from "/snippets/zh/v2/extract/base/curl.mdx";
import ExtractPython from "/snippets/zh/v2/extract/base/python.mdx";
import ExtractNode from "/snippets/zh/v2/extract/base/js.mdx";
import ExtractOutput from "/snippets/zh/v2/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/zh/v2/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/zh/v2/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/zh/v2/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/zh/v2/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/zh/v2/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/zh/v2/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/zh/v2/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/zh/v2/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/zh/v2/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/zh/v2/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/zh/v2/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/zh/v2/extract/status/pending.mdx";
import ExtractStatusDone from "/snippets/zh/v2/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/zh/v2/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/zh/v2/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/zh/v2/extract/without-urls/curl.mdx";

<Note>
  **全新推出 Agent：Extract 的下一代形态**
  我们正在发布 [`/agent`](/zh/features/agent) —— `/extract` 的继任者。它更快、更可靠，而且不需要提供 URL。你只需描述你的需求，让 AI agent 为你自动查找并抽取数据。[立即试用 Agent →](/zh/features/agent)
</Note>

`/extract` 端点可简化从任意数量的 URL 或整个域名收集结构化数据的流程。你只需提供一个 URL 列表（可选使用通配符，如 `example.com/*`），以及用于描述所需信息的提示或 schema。Firecrawl 将负责爬取、解析与汇总，不论数据集大小。

<Info>我们已简化计费：Extract 现在与其他端点一样使用积分。每个积分相当于 15 个 token。</Info>

<div id="using-extract">
  ## 使用 `/extract`
</div>

你可以从一个或多个 URL 中提取结构化数据，也可以使用通配符：

* **单个页面**\
  示例：`https://firecrawl.dev/some-page`
* **多个页面 / 整个域名**\
  示例：`https://firecrawl.dev/*`

当你使用 `/*` 时，Firecrawl 会自动爬取并解析该域名下它能发现的所有 URL，然后提取所需数据。该功能目前为实验性功能；如果你遇到问题，请发送邮件至 [help@firecrawl.com](mailto:help@firecrawl.com)。

<div id="example-usage">
  ### 示例用法
</div>

<CodeGroup>
  <ExtractPython />

  <ExtractNode />

  <ExtractCURL />
</CodeGroup>

**关键参数：**

* **urls**：一个或多个 URL 的数组。支持通配符（`/*`）以进行更广泛的爬取。
* **prompt**（可选，若无 schema 则必填）：用自然语言描述所需数据，或说明数据应如何结构化。
* **schema**（可选，若无 prompt 则必填）：当已知 JSON 结构时使用的更严格定义。
* **enableWebSearch**（可选）：设为 `true` 时，提取可跟随链接跳出指定域名。

更多详情见 [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/extract)。

<div id="response-sdks">
  ### 响应（SDK）
</div>

<ExtractOutput />

<div id="job-status-and-completion">
  ## 作业状态与完成
</div>

当你提交一次提取作业（通过 API 或入门方法），会收到一个 Job ID。你可以用该 ID：

* 获取作业状态：向 /extract/{ID} 端点发送请求，查看作业是否仍在运行或已完成。
* 等待结果：如果你使用默认的 `extract` 方法（Python/Node），SDK 会等待并返回最终结果。
* 先启动再轮询：如果你使用启动方法——`start_extract`（Python）或 `startExtract`（Node），SDK 会立即返回一个 Job ID。使用 `get_extract_status`（Python）或 `getExtractStatus`（Node）检查进度。

<Note>
  此端点仅对进行中或最近完成（24 小时内）的作业有效。
</Note>

以下是使用 Python、Node.js 和 cURL 检查提取作业状态的代码示例：

<CodeGroup>
  <CheckExtractJobPython />

  <CheckExtractJobJS />

  <CheckExtractJobCURL />
</CodeGroup>

<div id="possible-states">
  ### 可能的状态
</div>

* **completed**: 提取已成功完成。
* **processing**: Firecrawl 仍在处理你的请求。
* **failed**: 发生错误，数据未完整提取。
* **cancelled**: 该任务已被用户取消。

<div id="pending-example">
  #### 处理中示例
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### 完成示例
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## 无需 Schema 的提取
</div>

如果你不想定义严格的结构，只需提供一个 `prompt`。底层模型会自动为你选择结构，这在进行探索性或更灵活的请求时很有用。

<CodeGroup>
  <ExtractNoSchemaPython />

  <ExtractNoSchemaJS />

  <ExtractNoSchemaCURL />
</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## 通过网页搜索提升结果
</div>

在请求中将 `enableWebSearch = true` 启用后，抓取范围会扩展到所提供的 URL 集合之外，从而获取来自相关链接页面的支撑性或关联信息。

下面是一个示例：它提取有关行车记录仪的信息，并使用相关页面的数据来充实结果：

<CodeGroup>
  <ExtractWebSearchPython />

  <ExtractWebSearchJS />

  <ExtractWebSearchCURL />
</CodeGroup>

<div id="example-response-with-web-search">
  ### 含网页搜索的示例响应
</div>

<ExtractWebSearchOutput />

该响应包含从相关页面收集的补充上下文，从而提供更全面、更准确的信息。

<div id="extracting-without-urls">
  ## 无需提供 URL 的提取
</div>

`/extract` 端点现已支持在不提供特定 URL 的情况下，基于提示提取结构化数据。适用于研究场景或在确切 URL 不确定时使用。目前处于 Alpha 阶段。

<CodeGroup>
  <ExtractWithoutURLsPython />

  <ExtractWithoutURLsJS />

  <ExtractWithoutURLsCURL />
</CodeGroup>

<div id="known-limitations-beta">
  ## 已知限制（Beta）
</div>

1. **大规模站点覆盖**\
   目前尚不支持在单个请求中完整覆盖超大型网站（例如“Amazon 上的所有产品”）。

2. **复杂逻辑查询**\
   类似“查找 2025 年的所有帖子”的请求可能无法稳定返回全部预期数据。更高级的查询能力正在开发中。

3. **偶发不一致**\
   不同运行的结果可能有所差异，尤其是在非常大型或动态的网站上。通常能捕获核心信息，但可能存在一定差异。

4. **Beta 状态**\
   由于 `/extract` 仍处于 Beta，功能和性能将持续演进。欢迎提交问题与反馈，帮助我们改进。

<div id="using-fire-1">
  ## 使用 FIRE-1
</div>

FIRE-1 是一款 AI 代理，可增强 Firecrawl 的抓取能力。它能够控制浏览器 actions，并在复杂的网站结构中导航，从而实现超越传统抓取方式的全面数据提取。

对于需要在多个页面之间导航或与页面元素交互的复杂抽取任务，你可以通过 `/extract` 端点使用 FIRE-1 代理。

**示例（cURL）：**

```bash
curl -X POST https://api.firecrawl.dev/v2/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "提取该论坛帖中的所有用户评论。",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> FIRE-1 已上线，目前处于预览可用状态。

<div id="billing-and-usage-tracking">
  ## 计费与用量跟踪
</div>

我们已简化计费：现在 Extract 与其他所有端点一样采用额度计费。每个额度相当于 15 个 token。

你可以通过[仪表板](https://www.firecrawl.dev/app/extract)监控 Extract 的用量。

有反馈或需要帮助？请发送邮件至 [help@firecrawl.com](mailto:help@firecrawl.com)。