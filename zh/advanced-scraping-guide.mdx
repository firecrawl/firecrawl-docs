---
title: "高级抓取指南"
description: "了解如何通过高级选项优化你的 Firecrawl 抓取。"
og:title: "高级抓取指南 | Firecrawl"
og:description: "了解如何通过高级选项优化你的 Firecrawl 抓取。"
---

本指南将带你了解 Firecrawl 的各个端点，并讲解如何结合所有参数充分发挥其功能。

<div id="basic-scraping-with-firecrawl">
  ## 使用 Firecrawl 进行基础抓取
</div>

要抓取单个页面并获取干净的 Markdown 内容，可以使用 `/scrape` 端点。

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## 抓取 PDF
</div>

Firecrawl 支持 PDF。需要确保解析 PDF 时，请使用 `parsers` 选项（例如 `parsers: ["pdf"]`）。

<div id="scrape-options">
  ## 抓取选项
</div>

使用 `/scrape` 端点时，你可以通过以下选项定制抓取。

<div id="formats-formats">
  ### formats（`formats`）
</div>

- **类型**: `array`
- **字符串**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **对象 formats**:
  - JSON: `{ type: "json", prompt, schema }`
  - 截图: `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - 变更跟踪: `{ type: "changeTracking", modes?, prompt?, schema?, tag? }`（需要 `markdown`）
- **默认值**: `["markdown"]`

<div id="full-page-content-vs-main-content-onlymaincontent">
  ### 全页内容 vs 主内容（`onlyMainContent`）
</div>

- **类型**: `boolean`
- **描述**: 默认仅返回主内容。将其设为 `false` 可返回全页内容。
- **默认值**: `true`

<div id="include-tags-includetags">
  ### 包含标签（`includeTags`）
</div>

- **类型**: `array`
- **描述**: 抓取时要包含的 HTML 标签/类名/ID。

<div id="exclude-tags-excludetags">
  ### 排除标签（`excludeTags`）
</div>

- **类型**: `array`
- **描述**: 在抓取时需要排除的 HTML 标签/类名/ID。

<div id="wait-for-page-readiness-waitfor">
  ### 等待页面就绪（`waitFor`）
</div>

- **类型**: `integer`
- **描述**: 抓取前额外等待的毫秒数（尽量少用）。该等待时间是在 Firecrawl 智能等待功能基础上的额外延时。
- **默认值**: `0`

<div id="freshness-and-cache-maxage">
  ### 新鲜度与缓存（`maxAge`）
</div>

- **类型**: `integer`（毫秒）
- **描述**: 如果页面的缓存版本在 `maxAge` 内仍然有效，Firecrawl 会立即返回；否则将抓取最新内容并更新缓存。将其设为 `0` 可始终获取最新内容。
- **默认值**: `172800000`（2 天）

<div id="request-timeout-timeout">
  ### 请求超时（`timeout`）
</div>

- **类型**: `integer`
- **描述**: 在中止前的最长时长（毫秒）。
- **默认值**: `30000`（30 秒）

<div id="pdf-parsing-parsers">
  ### PDF 解析（`parsers`）
</div>

- **类型**: `array`
- **描述**: 用于控制解析行为。要解析 PDF，请设置 `parsers: ["pdf"]`。
- **费用**: PDF 解析按每页收取 1 个积分。若要跳过 PDF 解析并以 base64 格式接收文件（统一收取 1 个积分），请设置 `parsers: []`。
- **限制页数**: 若要将 PDF 解析限制在指定页数内，请使用 `parsers: [{"type": "pdf", "maxPages": 10}]`。

<div id="actions-actions">
  ### actions（`actions`）
</div>

使用 /scrape 端点时，Firecrawl 允许你在抓取页面内容之前，在网页上执行一系列 actions。这在需要与动态内容交互、在页面之间导航，或访问依赖用户操作才能显示的内容时尤其有用。

- **Type**: `array`
- **Description**: 抓取前要运行的一系列浏览器步骤。
- **Supported actions**:
    - `wait` - 等待页面加载：`{ type: "wait", milliseconds: number }` 或 `{ type: "wait", selector: string }`
    - `click` - 点击元素：`{ type: "click", selector: string, all?: boolean }`
    - `write` - 向输入字段中键入文本：`{ type: "write", text: string }`（元素必须先通过 click 获得焦点）
    - `press` - 模拟键盘按键：`{ type: "press", key: string }`
    - `scroll` - 滚动页面：`{ type: "scroll", direction: "up" | "down", selector?: string }`
    - `screenshot` - 捕获页面截图：`{ type: "screenshot", fullPage?: boolean, quality?: number, viewport?: { width: number, height: number } }`
    - `scrape` - 抓取子元素内容：`{ type: "scrape" }`
    - `executeJavascript` - 执行 JS 代码：`{ type: "executeJavascript", script: string }`
    - `pdf` - 生成 PDF 文件：`{ type: "pdf", format?: string, landscape?: boolean, scale?: number }`

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  'actions': [
    { 'type': 'wait', 'milliseconds': 1000 },
    { 'type': 'click', 'selector': '#accept' },
    { 'type': 'scroll', 'direction': 'down' },
    { 'type': 'click', 'selector': '#q' },
    { 'type': 'write', 'text': 'firecrawl' },
    { 'type': 'press', 'key': 'Enter' },
    { 'type': 'wait', 'milliseconds': 2000 }
  ],
  'formats': ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'click', selector: '#q' },
    { type: 'write', text: 'firecrawl' },
    { type: 'press', key: 'Enter' },
    { type: 'wait', milliseconds: 2000 }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "click", "selector": "#q" },
      { "type": "write", "text": "firecrawl" },
      { "type": "press", "key": "Enter" },
      { "type": "wait", "milliseconds": 2000 }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

<div id="action-execution-notes">
  ### actions 执行注意事项
</div>

- **Write action**：在使用 `write` 之前，必须先通过一个 `click` action 使目标元素获得焦点。文本会逐字输入，以模拟键盘输入。
- **Scroll selector**：如果你只想滚动某个特定元素而不是整个页面，请在 `scroll` 中提供 `selector` 参数。
- **Wait with selector**：你可以在 `wait` 中使用 `selector` 参数来等待特定元素变为可见，或者使用 `milliseconds` 来等待固定时长。
- **actions 按顺序执行**：actions 会按顺序执行，Firecrawl 会在当前页面交互完成后再继续执行下一个 action。

<div id="advanced-action-examples">
  ### 高级操作示例
</div>

**执行截图操作：**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "click", "selector": "#load-more" },
      { "type": "wait", "milliseconds": 1000 },
      { "type": "screenshot", "fullPage": true, "quality": 80 }
    ]
  }'
```

**点击多个元素：**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "click", "selector": ".expand-button", "all": true },
      { "type": "wait", "milliseconds": 500 }
    ],
    "formats": ["markdown"]
  }'
```

**生成 PDF 文件：**

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "pdf", "format": "A4", "landscape": false }
    ]
  }'
```


<div id="example-usage">
  ### 示例用法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

在此示例中，scraper 将：

* 以 Markdown 返回完整页面内容。
* 在响应中包含 Markdown、原始 HTML、HTML、链接以及截图。
* 仅包含 HTML 标签 `<h1>`、`<p>`、`<a>`，以及类名为 `.main-content` 的元素，同时排除任何 ID 为 `#ad` 和 `#footer` 的元素。
* 在开始抓取前等待 1000 毫秒（1 秒），以便页面加载。
* 将抓取请求的最长持续时间设置为 15000 毫秒（15 秒）。
* 通过 `parsers: ["pdf"]` 显式解析 PDF。

API 参考： [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

<div id="json-extraction-via-formats">
  ## 通过 formats 进行 JSON 提取
</div>

在 `formats` 中使用 JSON 格式对象，一次性提取结构化数据：

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "Extract the features of the product",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```


<div id="extract-endpoint">
  ## Extract 接口
</div>

当你需要通过轮询状态来进行异步提取时，请使用专门的 Extract 任务 API。

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// Start extract job
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extract title',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// Poll status
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract title",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extract title",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

<div id="crawling-multiple-pages">
  ## 抓取多个页面
</div>

要抓取多个页面，请使用 `/v2/crawl` 端点。

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

返回一个 ID

```json
{ "id": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### 检查抓取任务
</div>

用于查看抓取任务的状态并获取其结果。

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY'
```


<div id="paginationnext-url">
  #### 分页/下一页 URL
</div>

如果内容大小超过 10MB，或者爬取任务仍在运行，响应中可能会包含一个 `next` 参数，即指向下一页结果的 URL。

<div id="crawl-prompt-and-params-preview">
  ### 爬取提示与参数预览
</div>

你可以提供自然语言的 `prompt`，让 Firecrawl 自动推导爬取设置。请先预览结果：

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "提取文档与博客"
  }'
```

<div id="crawler-options">
  ### 爬虫选项
</div>

当使用 `/v2/crawl` 端点时，你可以使用以下选项来自定义爬取行为：

<div id="includepaths">
  #### includePaths
</div>

- **类型**: `array`
- **说明**: 要包含的正则表达式模式。
- **示例**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### excludePaths
</div>

- **类型**: `array`
- **描述**: 用于排除的正则表达式模式。
- **示例**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdiscoverydepth">
  #### maxDiscoveryDepth
</div>

- **类型**: `integer`
- **描述**: 查找新 URL 的最大发现深度。

<div id="limit">
  #### limit
</div>

- **类型**: `integer`
- **描述**: 爬取的最大页面数量。
- **默认值**: `10000`

<div id="crawlentiredomain">
  #### crawlEntireDomain
</div>

- **类型**: `boolean`
- **描述**: 跨同级/父级页面扩展爬取以覆盖整个域名。
- **默认值**: `false`

<div id="allowexternallinks">
  #### allowExternalLinks
</div>

- **类型**: `boolean`
- **描述**: 跟随指向外部域名的链接。
- **默认值**: `false`

<div id="allowsubdomains">
  #### allowSubdomains
</div>

- **类型**: `boolean`
- **描述**: 允许跟踪主域的子域名。
- **默认值**: `false`

<div id="delay">
  #### delay
</div>

- **Type**: `number`
- **Description**: 每次抓取之间的延迟（单位：秒）。
- **Default**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

- **类型**: `object`
- **描述**: 抓取器选项（参见上面的 格式）。
- **示例**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **默认值**: `formats: ["markdown"]`，默认启用缓存（maxAge 约 2 天）

<div id="example-usage">
  ### 示例用法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-你的-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```

<div id="mapping-website-links">
  ## 网站链接映射
</div>

`/v2/map` 端点用于查找与指定网站相关的 URL。

<div id="usage">
  ### 使用方法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

<div id="map-options">
  ### 映射选项
</div>

<div id="search">
  #### search
</div>

- **类型**: `string`
- **描述**: 过滤包含指定文本的链接。

<div id="limit">
  #### limit
</div>

- **类型**: `integer`
- **描述**: 返回的链接数量最大值。
- **默认值**: `100`

<div id="sitemap">
  #### sitemap
</div>

- **类型**: `"only" | "include" | "skip"`
- **描述**: 控制在映射时对 sitemap 的使用。
- **默认值**: `"include"`

<div id="includesubdomains">
  #### includeSubdomains
</div>

- **类型**: `boolean`
- **说明**: 是否包含该网站的子域名。
- **默认值**: `true`

相关 API 参考：[/map 端点文档](https://docs.firecrawl.dev/api-reference/endpoint/map)

感谢阅读！