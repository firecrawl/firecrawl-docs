---
title: "高级抓取指南"
description: "了解如何通过高级选项优化你的 Firecrawl 抓取。"
og:title: "高级抓取指南 | Firecrawl"
og:description: "了解如何通过高级选项优化你的 Firecrawl 抓取。"
---

本指南将带你了解 Firecrawl 的各个端点，并讲解如何结合所有参数充分发挥其功能。

<div id="basic-scraping-with-firecrawl">
  ## 使用 Firecrawl 进行基础抓取
</div>

要抓取单个页面并获取干净的 Markdown 内容，可以使用 `/scrape` 端点。

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## 抓取 PDF
</div>

Firecrawl 支持 PDF。需要确保解析 PDF 时，请使用 `parsers` 选项（例如 `parsers: ["pdf"]`）。

<div id="scrape-options">
  ## 抓取选项
</div>

使用 `/scrape` 端点时，你可以通过以下选项定制抓取。

<div id="formats-formats">
  ### formats（`formats`）
</div>

- **类型**: `array`
- **字符串**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **对象 formats**:
  - JSON: `{ type: "json", prompt, schema }`
  - 截图: `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - 变更跟踪: `{ type: "changeTracking", modes?, prompt?, schema?, tag? }`（需要 `markdown`）
- **默认值**: `["markdown"]`

<div id="full-page-content-vs-main-content-onlymaincontent">
  ### 全页内容 vs 主内容（`onlyMainContent`）
</div>

- **类型**: `boolean`
- **描述**: 默认仅返回主内容。将其设为 `false` 可返回全页内容。
- **默认值**: `true`

<div id="include-tags-includetags">
  ### 包含标签（`includeTags`）
</div>

- **类型**: `array`
- **描述**: 抓取时要包含的 HTML 标签/类名/ID。

<div id="exclude-tags-excludetags">
  ### 排除标签（`excludeTags`）
</div>

- **类型**: `array`
- **描述**: 在抓取时需要排除的 HTML 标签/类名/ID。

<div id="wait-for-page-readiness-waitfor">
  ### 等待页面就绪（`waitFor`）
</div>

- **类型**: `integer`
- **描述**: 抓取前额外等待的毫秒数（尽量少用）。该等待时间是在 Firecrawl 智能等待功能基础上的额外延时。
- **默认值**: `0`

<div id="freshness-and-cache-maxage">
  ### 新鲜度与缓存（`maxAge`）
</div>

- **类型**: `integer`（毫秒）
- **描述**: 如果页面的缓存版本在 `maxAge` 内仍然有效，Firecrawl 会立即返回；否则将抓取最新内容并更新缓存。将其设为 `0` 可始终获取最新内容。
- **默认值**: `172800000`（2 天）

<div id="request-timeout-timeout">
  ### 请求超时（`timeout`）
</div>

- **类型**: `integer`
- **描述**: 在中止前的最长时长（毫秒）。
- **默认值**: `30000`（30 秒）

<div id="pdf-parsing-parsers">
  ### PDF 解析（`parsers`）
</div>

- **类型**: `array`
- **描述**: 用于控制解析行为。要解析 PDF，请设置 `parsers: ["pdf"]`。

<div id="actions-actions">
  ### Actions (`actions`)
</div>

使用 /scrape 端点时，Firecrawl 允许你在抓取页面内容之前对网页执行各类 actions。这对于与动态内容交互、在页面间导航，或访问需要用户交互才能显示的内容特别有用。

- **Type**: `array`
- **Description**: 抓取前执行的一系列浏览器步骤。
- **Supported actions**:
    - `wait` `{ milliseconds }`
    - `click` `{ selector }`
    - `write` `{ selector, text }`
    - `press` `{ key }`
    - `scroll` `{ direction: "up" | "down" }`
    - `scrape` `{ selector }`（抓取子元素）
    - `executeJavascript` `{ script }`
    - `pdf`（在部分流程中触发 PDF 渲染）

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "write", "selector": "#q", "text": "firecrawl" },
      { "type": "press", "key": "Enter" }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

<div id="example-usage">
  ### 示例用法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

在此示例中，scraper 将：

* 以 Markdown 返回完整页面内容。
* 在响应中包含 Markdown、原始 HTML、HTML、链接以及截图。
* 仅包含 HTML 标签 `<h1>`、`<p>`、`<a>`，以及类名为 `.main-content` 的元素，同时排除任何 ID 为 `#ad` 和 `#footer` 的元素。
* 在开始抓取前等待 1000 毫秒（1 秒），以便页面加载。
* 将抓取请求的最长持续时间设置为 15000 毫秒（15 秒）。
* 通过 `parsers: ["pdf"]` 显式解析 PDF。

API 参考： [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

<div id="json-extraction-via-formats">
  ## 通过格式进行 JSON 提取
</div>

在 `formats` 中使用 JSON 格式对象，一次完成结构化数据的提取：

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "提取该产品的功能",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```

<div id="extract-endpoint">
  ## /extract 端点
</div>

当你需要通过状态轮询进行异步抽取时，请使用专用的抽取作业 API。

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// 启动抽取作业
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extract title',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// 轮询状态
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract title",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extract title",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

<div id="crawling-multiple-pages">
  ## 抓取多个页面
</div>

要抓取多个页面，请使用 `/v2/crawl` 端点。

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

返回一个 ID

```json
{ "id": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### 检查爬取任务
</div>

用于查看爬取任务的状态并获取其结果。

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-你的API密钥'
```

<div id="paginationnext-url">
  #### 分页/下一页 URL
</div>

如果内容超过 10MB，或爬取任务仍在运行，响应可能包含一个 `next` 参数，即指向下一页结果的 URL。

<div id="crawl-prompt-and-params-preview">
  ### 爬取提示与参数预览
</div>

你可以提供自然语言的 `prompt`，让 Firecrawl 自动推导爬取设置。请先预览结果：

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "提取文档与博客"
  }'
```

<div id="crawler-options">
  ### 爬虫选项
</div>

使用 `/v2/crawl` 端点时，可以通过以下方式自定义爬取行为：

<div id="includepaths">
  #### includePaths
</div>

- **类型**: `array`
- **说明**: 要包含的正则表达式模式。
- **示例**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### excludePaths
</div>

- **类型**: `array`
- **描述**: 用于排除的正则表达式模式。
- **示例**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdiscoverydepth">
  #### maxDiscoveryDepth
</div>

- **类型**: `integer`
- **描述**: 查找新 URL 的最大发现深度。

<div id="limit">
  #### limit
</div>

- **类型**: `integer`
- **描述**: 爬取的最大页面数量。
- **默认值**: `10000`

<div id="crawlentiredomain">
  #### crawlEntireDomain
</div>

- **类型**: `boolean`
- **描述**: 跨同级/父级页面扩展爬取以覆盖整个域名。
- **默认值**: `false`

<div id="allowexternallinks">
  #### allowExternalLinks
</div>

- **类型**: `boolean`
- **描述**: 跟随指向外部域名的链接。
- **默认值**: `false`

<div id="allowsubdomains">
  #### allowSubdomains
</div>

- **类型**: `boolean`
- **描述**: 允许跟踪主域的子域名。
- **默认值**: `false`

<div id="delay">
  #### delay
</div>

- **Type**: `number`
- **Description**: 每次抓取之间的延迟（单位：秒）。
- **Default**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

- **类型**: `object`
- **描述**: 抓取器选项（参见上面的 格式）。
- **示例**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **默认值**: `formats: ["markdown"]`，默认启用缓存（maxAge 约 2 天）

<div id="example-usage">
  ### 示例用法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-你的-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```

<div id="mapping-website-links">
  ## 映射网站链接
</div>

`/v2/map` 端点用于识别与指定网站相关的 URL。

<div id="usage">
  ### 使用方法
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

<div id="map-options">
  ### Map 选项
</div>

<div id="search">
  #### search
</div>

- **类型**: `string`
- **描述**: 过滤包含指定文本的链接。

<div id="limit">
  #### limit
</div>

- **类型**: `integer`
- **描述**: 返回的链接数量最大值。
- **默认值**: `100`

<div id="sitemap">
  #### sitemap
</div>

- **类型**: `"only" | "include" | "skip"`
- **描述**: 控制在映射时对 sitemap 的使用。
- **默认值**: `"include"`

<div id="includesubdomains">
  #### includeSubdomains
</div>

- **类型**: `boolean`
- **说明**: 是否包含该网站的子域名。
- **默认值**: `true`

相关 API 参考：[/map 端点文档](https://docs.firecrawl.dev/api-reference/endpoint/map)

感谢阅读！