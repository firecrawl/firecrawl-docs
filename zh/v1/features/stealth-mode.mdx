---
title: "隐身模式"
description: "在采用高级反机器人方案的网站上使用隐身代理"
og:title: "隐身模式 | Firecrawl"
og:description: "在采用高级反机器人方案的网站上使用隐身代理"
---

import ProxyPython from "/snippets/zh/v1/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/zh/v1/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/zh/v1/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/zh/v1/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/zh/v1/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/zh/v1/scrape/proxy-retry/curl.mdx";

Firecrawl 提供多种代理类型，帮助你应对不同强度的反机器人（反爬）保护来抓取网站。可通过 `proxy` 参数指定代理类型。

<div id="proxy-types">
  ### 代理类型
</div>

Firecrawl 支持三种代理类型：

- **basic**：适用于抓取没有或仅有基础反爬措施的网站。速度快，通常有效。
- **stealth**：适用于抓取具备高级反爬措施的网站的隐身代理。速度较慢，但在某些网站上更可靠。
- **auto**：如果 basic 代理失败，Firecrawl 将自动使用 stealth 代理重试抓取。若使用 stealth 重试成功，该次抓取计费 5 个额度；若首次使用 basic 即成功，则仅按常规成本计费。

如果未指定代理，Firecrawl 默认为 basic。

<div id="using-stealth-mode">
  ### 使用 stealth 模式
</div>

在抓取具备高级反爬虫防护的网站时，你可以使用 stealth 代理模式来提高成功率。

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**注意：** 自 5 月 8 日起，stealth 代理每次请求消耗 5 个积分。

<div id="using-stealth-as-a-retry-mechanism">
  ## 将 Stealth 用作重试机制
</div>

一个常见的做法是先使用默认代理设置进行抓取；如果在响应的 `metadata.statusCode` 字段中遇到特定错误状态码（401、403 或 500），则改用 Stealth 模式重试。这些状态码可能表明网站正在阻止你的请求。

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

这种方法通过仅在必要时启用 Stealth 模式来优化你的额度使用。