---
title: "高级抓取指南"
description: "了解如何通过高级选项提升 Firecrawl 的抓取能力。"
og:title: "高级抓取指南 | Firecrawl"
og:description: "了解如何通过高级选项提升 Firecrawl 的抓取能力。"
---

本指南将介绍 Firecrawl 的各个端点，并讲解如何结合所有参数充分发挥其功能。

<div id="basic-scraping-with-firecrawl-scrape">
  ## 使用 Firecrawl 进行基础抓取（/scrape）
</div>

要抓取单个页面并获取干净的 Markdown 内容，可以使用 `/scrape` 端点。

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR_API_KEY")

content = app.scrape_url("https://docs.firecrawl.dev")
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { FirecrawlApp } from 'firecrawl-js';

const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

const content = await app.scrapeUrl('https://docs.firecrawl.dev');
```

```go Go
// go get github.com/mendableai/firecrawl-go

import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
    log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
  }

  content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
  if err != nil {
    log.Fatalf("Failed)
  }
}
```

```rust Rust
// 使用 Cargo 安装 firecrawl_rs crate

use firecrawl_rs::FirecrawlApp;
#[tokio::main]
async fn main() {
  // 使用 API 密钥初始化 FirecrawlApp
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
    Err(e) => eprintln!("Scrape failed: {}", e),
  }
}
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## 抓取 PDF
</div>

**Firecrawl 默认支持抓取 PDF。** 你可以使用 `/scrape` 端点抓取 PDF 链接并获取其中的文本内容。你也可以通过将 `parsePDF` 设置为 `false` 来禁用该功能。

<div id="scrape-options">
  ## 抓取选项
</div>

使用 `/scrape` 端点时，你可以通过多种参数自定义抓取行为。以下是可用的选项：

<div id="setting-the-content-formats-on-response-with-formats">
  ### 使用 `formats` 设置响应中的内容格式
</div>

- **类型**: `array`
- **枚举**: `["markdown", "links", "html", "rawHtml", "screenshot", "json"]`
- **描述**: 指定响应中要包含的 formats。可选项包括：
  - `markdown`: 以 Markdown 格式返回抓取的内容。
  - `links`: 包含页面上发现的所有超链接。
  - `html`: 以 HTML 格式提供内容。
  - `rawHtml`: 提供未经处理的原始 HTML 内容。
  - `screenshot`: 包含页面在浏览器中的截图。
  - `json`: 使用 LLM 从页面提取结构化信息。
- **默认值**: `["markdown"]`

<div id="getting-the-full-page-content-as-markdown-with-onlymaincontent">
  ### 使用 `onlyMainContent` 以 markdown 获取整页内容
</div>

- **Type**: `boolean`
- **Description**: 默认情况下，抓取器只返回页面的主体内容，不包括页眉、导航栏、页脚等。将其设为 `false` 可返回整页内容。
- **Default**: `true`

<div id="setting-the-tags-to-include-with-includetags">
  ### 使用 `includeTags` 设置要包含的标签
</div>

- **类型**: `array`
- **描述**: 指定在响应中需要包含的 HTML 标签、class 和 id。
- **默认值**: 未定义

<div id="setting-the-tags-to-exclude-with-excludetags">
  ### 使用 `excludeTags` 设置要排除的标签
</div>

- **类型**: `array`
- **描述**: 指定要在响应中排除的 HTML 标签、类名和 ID。
- **默认值**: 未定义

<div id="waiting-for-the-page-to-load-with-waitfor">
  ### 使用 `waitFor` 等待页面加载
</div>

- **类型**: `integer`
- **描述**: 仅在不得已时使用。在获取内容之前，按指定的毫秒数等待页面加载。
- **默认值**: `0`

<div id="setting-the-maximum-timeout">
  ### 设置最大 `timeout`
</div>

- **类型**: `integer`
- **描述**: 设置抓取器在中止操作前等待页面响应的最长时间（毫秒）。
- **默认值**: `30000`（30 秒）

<div id="parsing-pdf-files-with-parsepdf">
  ### 使用 `parsePDF` 解析 PDF 文件
</div>

- **类型**: `boolean`
- **描述**: 控制抓取时如何处理 PDF 文件。为 `true` 时，将提取 PDF 内容并转换为 Markdown 格式，按页计费（每页 1 个 credit）。为 `false` 时，将以 base64 编码返回 PDF 文件，按固定费率计费（共 1 个 credit）。
- **默认值**: `true`

<div id="example-usage">
  ### 使用示例
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": ["markdown", "links", "html", "rawHtml", "screenshot"],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsePDF": false
    }'
```

在此示例中，scraper 将：

* 以 markdown 返回完整页面内容。
* 在响应中包含 markdown、rawHtml、html、links 和 screenshot。
* 响应将只保留 HTML 标签 `<h1>`、`<p>`、`<a>`，以及具有类 `.main-content` 的元素，并排除具有 ID `#ad` 和 `#footer` 的任何元素。
* 在获取内容前等待 1000 毫秒（1 秒）以完成页面加载。
* 将抓取请求的最长持续时间设置为 15000 毫秒（15 秒）。
* 以 base64 格式返回 PDF 文件，而不是将其转换为 markdown。

这是该功能的 API 参考：[Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


<div id="extractor-options">
  ## 提取器选项
</div>

使用 `/scrape` 端点时，你可以通过 `extract` 参数为从页面内容中**提取结构化信息**设置选项。以下是可用的选项：

<div id="using-the-llm-extraction">
  ### 使用 LLM 提取功能
</div>

<div id="schema">
  ### schema
</div>

- **类型**: `object`
- **必填**: 若提供了 prompt，则为 False
- **描述**: 提取数据所用的 schema，定义了输出数据的结构。

<div id="system-prompt">
  ### system prompt
</div>

- **Type**: `string`
- **Required**: False
- **Description**: LLM 的系统级提示词。

<div id="prompt">
  ### prompt
</div>

- **类型**: `string`
- **是否必填**: 如果提供了 schema，则为 False
- **描述**: 提示 LLM 按正确的结构提取数据。
- **示例**: `"Extract the features of the product"`

<div id="example-usage">
  ### 示例用法
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "formats": ["markdown", "json"],
      "json": {
        "prompt": "提取该产品的功能"
      }
    }'
```

```json
{
  "success": true,
  "data": {
    "content": "原始内容",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable 让你轻松构建 AI 聊天应用。先摄取与自定义，然后只需一行代码即可随处部署。由 SideGuide 提供",
      "robots": "follow, index",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable 让你轻松构建 AI 聊天应用。先摄取与自定义，然后只需一行代码即可随处部署。由 SideGuide 提供",
      "ogUrl": "https://docs.firecrawl.dev/",
      "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://docs.firecrawl.dev/",
      "statusCode": 200
    },
    "extract": {
      "product": "Firecrawl",
      "features": {
        "general": {
          "description": "将网站转化为可直接供 LLM 使用的数据。",
          "openSource": true,
          "freeCredits": 500,
          "useCases": [
            "AI applications",
            "Data science",
            "Market research",
            "Content aggregation",
          ]
        },
        "crawlingAndScraping": {
          "crawlAllAccessiblePages": true,
          "noSitemapRequired": true,
          "dynamicContentHandling": true,
          "dataCleanliness": {
            "process": "高级算法",
            "outputFormat": "Markdown"
          }
        },
        ...
      }
    }
  }
}
```


<div id="actions">
  ## Actions
</div>

在使用 `/scrape` 端点时，Firecrawl 允许你在抓取内容前对网页执行各类 actions。这对于与动态内容交互、分页导航，或访问需要用户操作的内容尤其有用。

<div id="available-actions">
  ### 可用 actions
</div>

<div id="wait">
  #### wait
</div>

- **类型**: `object`
- **描述**: 等待指定时长（毫秒）。
- **属性**:
  - `type`: `"wait"`
  - `milliseconds`: 等待的毫秒数。
- **示例**:
  ```json
  {
    "type": "wait",
    "milliseconds": 2000
  }
  ```

<div id="screenshot">
  #### screenshot
</div>

- **类型**: `object`
- **描述**: 进行屏幕截图。
- **属性**:
  - `type`: `"screenshot"`
  - `fullPage`: 截图应为整页还是仅视口大小？（默认：`false`）
- **示例**:
  ```json
  {
    "type": "screenshot",
    "fullPage": true
  }
  ```

<div id="click">
  #### click
</div>

- **类型**: `object`
- **描述**: 点击元素。
- **属性**:
  - `type`: `"click"`
  - `selector`: 用于定位元素的查询选择器。
- **示例**:
  ```json
  {
    "type": "click",
    "selector": "#load-more-button"
  }
  ```

<div id="write">
  #### write
</div>

- **类型**: `object`
- **描述**: 向输入字段中输入文本。
- **属性**:
  - `type`: `"write"`
  - `text`: 要输入的文本。
  - `selector`: 输入字段的查询选择器。
- **示例**:
  ```json
  {
    "type": "write",
    "text": "Hello, world!",
    "selector": "#search-input"
  }
  ```

<div id="press">
  #### press
</div>

- **类型**: `object`
- **描述**: 在页面上按下某个键。
- **属性**:
  - `type`: `"press"`
  - `key`: 要按下的键。
- **示例**:
  ```json
  {
    "type": "press",
    "key": "Enter"
  }
  ```

<div id="scroll">
  #### scroll
</div>

- **类型**: `object`
- **描述**: 滚动页面。
- **属性**:
  - `type`: `"scroll"`
  - `direction`: 滚动方向（`"up"` 或 `"down"`）。
  - `amount`: 滚动的像素值。
- **示例**:
  ```json
  {
    "type": "scroll",
    "direction": "down",
    "amount": 500
  }
  ```

<div id="scrape">
  #### scrape
</div>

- **类型**: `object`
- **描述**: 抓取当前页面内容，返回该页面的 URL 和 HTML。抓取结果将出现在响应的 `actions.scrapes` 数组中。
- **属性**:
  - `type`: `"scrape"`
- **示例**:
  ```json
  {
    "type": "scrape"
  }
  ```

<div id="pdf">
  #### pdf
</div>

- **类型**: `object`
- **描述**: 生成当前页面的 PDF。PDF 将在响应的 `actions.pdfs` 数组中返回。
- **属性**:
  - `type`: `"pdf"`
  - `format`: 生成的 PDF 页面大小（默认：`"Letter"`）
  - `landscape`: 是否以横向生成 PDF（默认：`false`）
  - `scale`: 生成的 PDF 缩放倍数（默认：`1`）
- **示例**:
  ```json
  {
    "type": "pdf",
    "format": "A4",
    "landscape": true,
    "scale": 0.8
  }
  ```

<div id="executejavascript">
  #### executeJavascript
</div>

- **类型**: `object`
- **描述**: 在页面中执行 JavaScript 代码。其返回值会出现在响应的 `actions.javascriptReturns` 数组中。
- **属性**:
  - `type`: `"executeJavascript"`
  - `script`: 要执行的 JavaScript 代码。
- **示例**:
  ```json
  {
    "type": "executeJavascript",
    "script": "document.querySelector('.button').click();"
  }
  ```

有关 actions 参数的更多信息，请参见 [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape)。

<div id="crawling-multiple-pages">
  ## 爬取多个页面
</div>

要爬取多个页面，可使用 `/crawl` 端点。你可以指定要爬取的基准 URL，服务将爬取其所有可访问的子页面。

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

返回一个 ID

```json
{ "id": "1234-5678-9101" }
```


<div id="check-crawl-job">
  ### 检查抓取作业
</div>

用于查看抓取作业的状态并获取其结果。

```bash
curl -X GET https://api.firecrawl.dev/v1/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
```


<div id="paginationnext-url">
  #### 分页/下一页 URL
</div>

如果内容超过 10MB，或爬取任务仍在运行，响应会包含一个 `next` 参数。该参数是指向下一页结果的 URL。你可以使用该参数获取下一页的结果。

<div id="crawler-options">
  ### 爬取选项
</div>

使用 `/crawl` 端点时，你可以通过请求体参数自定义爬取行为。以下是可用的选项：

<div id="includepaths">
  #### `includePaths`
</div>

- **类型**: `array`
- **描述**: 爬取时要包含的正则表达式模式。只有与这些模式匹配的 URL 才会被爬取。例如，`^/blog/.*` 会匹配任何以 `/blog/` 开头的 URL。
- **示例**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### `excludePaths`
</div>

- **类型**: `array`
- **说明**: 在爬取过程中用于排除的正则表达式模式。匹配这些模式的 URL 将被跳过。例如，`^/admin/.*` 会排除所有以 `/admin/` 开头的 URL。
- **示例**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdepth">
  #### `maxDepth`
</div>

- **类型**: `integer`
- **描述**: 相对于输入 URL 的起始路径可爬取的最大绝对深度。例如，如果输入 URL 的路径为 `/features/feature-1`，除非将 `maxDepth` 设为至少 2，否则不会返回任何结果。
- **示例**: `2`

<div id="limit">
  #### `limit`
</div>

- **类型**: `integer`
- **描述**: 爬取的最大页面数量。
- **默认值**: `10000`

<div id="allowbackwardlinks">
  #### `allowBackwardLinks`
</div>

- **Type**: `boolean`
- **Description**: 允许爬虫不仅沿子路径，还可跟随内部链接到同级或父级 URL。
  - **false**: 仅爬取更深层（子级）URL。
    - 例如：/features/feature-1 → /features/feature-1/tips ✅
    - 不会跟随 /pricing 或 / ❌
  - **true**: 爬取任意内部链接，包括同级和父级。
    - 例如：/features/feature-1 → /pricing、/ 等 ✅
  - 若需超出嵌套路径的更广泛内部覆盖，请将其设为 true。
- **Default**: `false`

<div id="allowexternallinks">
  ### `allowExternalLinks`
</div>

- **类型**: `boolean`
- **描述**: 该选项允许爬虫跟随指向外部域的链接。使用此选项需谨慎，因为这可能会导致爬取仅根据 `limit` 和 `maxDepth` 的值而停止。
- **默认值**: `false`

<div id="allowsubdomains">
  ### `allowSubdomains`
</div>

- **类型**: `boolean`
- **描述**: 允许爬虫跟踪主域名的子域链接。比如在抓取 `example.com` 时，将允许继续访问指向 `blog.example.com` 或 `api.example.com` 的链接。
- **默认值**: `false`

<div id="delay">
  ### `delay`
</div>

- **类型**: `number`
- **描述**: 两次抓取之间的延迟（单位：秒）。有助于遵守网站的速率限制并避免给目标站点带来过载。如果未设置，爬虫可能会使用 robots.txt 中的 crawl-delay（若存在）。
- **默认值**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

作为爬虫选项的一部分，你也可以指定 `scrapeOptions` 参数。该参数用于为每个页面自定义抓取行为。

- **类型**: `object`
- **描述**: 抓取器选项。
- **示例**: `{"formats": ["markdown", "links", "html", "rawHtml", "screenshot"], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **默认值**: `{ "formats": ["markdown"] }`
- **参见**: [抓取选项](#setting-the-content-formats-on-response-with-formats)

<div id="example-usage">
  ### 使用示例
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDepth": 2,
      "limit": 1000
    }'
```

在此示例中，爬虫将：

* 仅爬取与模式 `^/blog/.*$` 和 `^/docs/.*$` 匹配的 URL。
* 跳过与模式 `^/admin/.*$` 和 `^/private/.*$` 匹配的 URL。
* 为每个页面返回完整的文档数据。
* 最大爬取深度为 2。
* 最多爬取 1000 个页面。


<div id="mapping-website-links-with-map">
  ## 使用 `/map` 进行网站链接映射
</div>

`/map` 端点善于发现与指定网站在语境上相关的 URL。此功能对于理解站点的上下文链接生态至关重要，可显著提升战略性站点分析与导航规划的效果。

<div id="usage">
  ### 使用方法
</div>

要使用 `/map` 端点，你需要发送一个包含目标页面 URL 的 GET 请求。下面是使用 `curl` 的示例：

```bash
curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

这将返回一个 JSON 对象，其中包含与该 URL 语境相关的链接。


<div id="example-response">
  ### 示例响应
</div>

```json
  {
    "success": true,
    "links": [
      "https://docs.firecrawl.dev",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-get",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-post",
      "https://docs.firecrawl.dev/api-reference/endpoint/map",
      "https://docs.firecrawl.dev/api-reference/endpoint/scrape",
      "https://docs.firecrawl.dev/api-reference/introduction",
      "https://docs.firecrawl.dev/articles/search-announcement",
      ...
    ]
  }
```


<div id="map-options">
  ### 映射选项
</div>

<div id="search">
  #### `search`
</div>

- **类型**: `string`
- **描述**: 搜索包含指定文本的链接。
- **示例**: `"blog"`

<div id="limit">
  #### `limit`
</div>

- **类型**: `integer`
- **描述**: 返回的链接数量上限。
- **默认值**: `100`

<div id="ignoresitemap">
  #### `ignoreSitemap`
</div>

- **类型**: `boolean`
- **描述**: 爬取时忽略网站的 sitemap
- **默认值**: `true`

<div id="includesubdomains">
  #### `includeSubdomains`
</div>

- **类型**: `boolean`
- **描述**: 是否包含该站点的子域名
- **默认值**: `true`

对应的 API 参考：[/map 端点文档](https://docs.firecrawl.dev/api-reference/endpoint/map)

感谢阅读！