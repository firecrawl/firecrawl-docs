---
title: "Python"
description: "Firecrawl Python SDK 是对 Firecrawl API 的封装，助你轻松将网站转换为 Markdown。"
icon: "python"
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK 是对 Firecrawl API 的封装，助你轻松将网站转换为 Markdown。"
---

import InstallationPython from '/snippets/zh/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/zh/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/zh/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/zh/v1/crawl-status/short/python.mdx'
import CrawlAsyncPythonShort from '/snippets/zh/v1/crawl-async/short/python.mdx'
import CancelCrawlPythonShort from '/snippets/zh/v1/crawl-delete/short/python.mdx'
import MapPythonShort from '/snippets/zh/v1/map/short/python.mdx'
import ExtractPythonShort from '/snippets/zh/v1/extract/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/zh/v1/scrape-and-crawl/python.mdx'
import CrawlWebSocketPythonBase from '/snippets/zh/v1/crawl-websocket/base/python.mdx'
import AsyncPythonShort from '/snippets/zh/v1/async/short/python.mdx'

<div id="installation">
  ## 安装
</div>

要安装 Firecrawl 的 Python SDK，可使用 pip：

<InstallationPython />

<div id="usage">
  ## 使用
</div>

1. 在 [firecrawl.dev](https://firecrawl.dev) 获取 API key
2. 将该 API key 设置为名为 `FIRECRAWL_API_KEY` 的环境变量，或作为参数传递给 `FirecrawlApp` 类。

以下示例展示如何使用该 SDK：

<ScrapeAndCrawlExamplePython />

<div id="scraping-a-url">
  ### 抓取单个 URL
</div>

要抓取单个 URL，请使用 `scrape_url` 方法。该方法接收该 URL 作为参数，并以字典形式返回抓取结果。

<ScrapePythonShort />

<div id="crawling-a-website">
  ### 爬取网站
</div>

要爬取网站，请使用 `crawl_url` 方法。它接收起始 URL 和可选参数。通过 `params` 参数，你可以为爬取任务指定其他选项，例如最大爬取页数、允许的域名以及输出格式。

<CrawlPythonShort />

<div id="asynchronous-crawling">
  ### 异步爬取
</div>

<Tip>在找异步操作？请查看下方的 [Async Class](#async-class) 部分。</Tip>

要以异步方式爬取网站，请使用 `crawl_url_async` 方法。它会返回爬取的 `ID`，可用于检查爬取任务的状态。该方法接收起始 URL 及可选参数。通过 `params` 参数，你可以为爬取任务指定更多选项，例如最大爬取页数、允许的域名，以及输出 formats。

<CrawlAsyncPythonShort />

<div id="checking-crawl-status">
  ### 检查爬取状态
</div>

要查看某次爬取任务的状态，请使用 `check_crawl_status` 方法。该方法接收作业 ID 作为参数，返回该爬取作业的当前状态。

<CheckCrawlStatusPythonShort />

<div id="cancelling-a-crawl">
  ### 取消爬取
</div>

要取消异步爬取作业，请使用 `cancel_crawl` 方法。该方法接收异步爬取的作业 ID 作为参数，并返回取消结果。

<CancelCrawlPythonShort />

<div id="map-a-website">
  ### 映射网站
</div>

使用 `map_url` 生成站点的 URL 列表。通过 `params` 参数可自定义映射过程，包括排除子域、利用 sitemap 等选项。

<MapPythonShort />

{/* ### 从网站提取结构化数据

要从网站提取结构化数据，使用 `extract` 方法。它接收要提取的 URL、提示词（prompt）和 schema 作为参数。该 schema 是用于定义提取数据结构的 Pydantic 模型。

<ExtractPythonShort /> */}

<div id="crawling-a-website-with-websockets">
  ### 使用 WebSocket 爬取网站
</div>

要通过 WebSocket 爬取网站，请使用 `crawl_url_and_watch` 方法。该方法接收起始 URL 和可选参数。通过 `params` 参数，你可以为爬取任务指定其他选项，例如最大爬取页数、允许的域名，以及输出格式。

<CrawlWebSocketPythonBase />

<div id="error-handling">
  ## 错误处理
</div>

SDK 会处理 Firecrawl API 返回的错误并抛出相应异常。若在请求过程中发生错误，将抛出带有详细说明的错误信息的异常。

<div id="async-class">
  ## 异步类
</div>

对于异步操作，你可以使用 `AsyncFirecrawlApp` 类。其方法与 `FirecrawlApp` 类相同，但不会阻塞主线程。

<AsyncPythonShort />