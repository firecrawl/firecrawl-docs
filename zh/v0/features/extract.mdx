---
title: 'LLM 提取'
description: '通过 LLM 从页面提取结构化数据'
icon: 'file-export'
og:title: "提取 | Firecrawl"
og:description: "通过 LLM 从页面提取结构化数据"
---

<div id="scrape-and-extract-structured-data-with-firecrawl">
  ## 使用 Firecrawl 抓取并提取结构化数据
</div>

Firecrawl 利用大型语言模型（LLM）高效从网页提取结构化数据。具体步骤如下：

1. **Schema 定义：**
   使用 JSON Schema（遵循 OpenAI 工具 schema）定义要抓取的 URL 和目标数据的 schema。该 schema 用于指定你期望从页面提取的数据结构。

2. **Scrape 端点：**
   将 URL 和 schema 传递给 /scrape 端点。该端点的文档如下：
   [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

3. **获取结构化数据：**
   按照你的 schema 定义的结构接收抓取结果。随后可在应用中按需使用或进一步处理这些数据。

此方法可简化数据提取，减少人工处理并提升效率。

<div id="extract-structured-data">
  ## 提取结构化数据
</div>

<div id="scrape-with-extract-endpoint">
  ### /scrape（携带 extract）端点
</div>

用于从抓取到的页面中提取结构化数据。

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "extractorOptions": {
        "mode": "llm-extraction",
        "extractionPrompt": "根据页面信息，从该 schema 提取所需信息。 "
        "extractionSchema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
```

```json
{
    "success": true,
    "data": {
      "content": "原始内容",
      "metadata": {
        "title": "Mendable",
        "description": "Mendable 让你轻松构建 AI 聊天应用。先导入，再自定义，随后用一行代码即可随处部署。由 SideGuide 推出",
        "robots": "follow, index",
        "ogTitle": "Mendable",
        "ogDescription": "Mendable 让你轻松构建 AI 聊天应用。先导入，再自定义，随后用一行代码即可随处部署。由 SideGuide 推出",
        "ogUrl": "https://docs.firecrawl.dev/",
        "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
        "ogLocaleAlternate": [],
        "ogSiteName": "Mendable",
        "sourceURL": "https://docs.firecrawl.dev/"
      },
      "llm_extraction": {
        "company_mission": "基于你的技术资源训练一套安全的 AI，回答客户和员工的问题，让你的团队无需亲自处理",
        "supports_sso": true,
        "is_open_source": false,
        "is_in_yc": true
      }
    }
}

```

<div id="using-python-sdk">
  ### 使用 Python SDK
</div>

```python
from firecrawl import FirecrawlApp

# 使用你的 API 密钥初始化 FirecrawlApp
app = FirecrawlApp(api_key='your_api_key', version='v0')

class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="前 5 篇热门文章")

data = app.scrape_url('https://news.ycombinator.com', {
    'extractorOptions': {
        'extractionSchema': TopArticlesSchema.model_json_schema(),
        'mode': 'llm-extraction'
    },
    'pageOptions':{
        'onlyMainContent': True
    }
})
print(data["llm_extraction"])
```

<div id="with-javascript-sdk">
  ### 使用 JavaScript SDK
</div>

```js
import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY",
  version: "v0"
});

// 定义用于承载提取结果的 schema
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Hacker News 上的前 5 条新闻"),
});

const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
  extractorOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["llm_extraction"]);
```

<div id="with-go-sdk">
  ### 使用 Go SDK
</div>

```go Go
import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
      log.Fatalf("FirecrawlApp 初始化失败：%v", err)
  }

  jsonSchema := map[string]any{
    "type": "object",
    "properties": map[string]any{
      "top": map[string]any{
        "type": "array",
        "items": map[string]any{
          "type": "object",
          "properties": map[string]any{
            "title":       map[string]string{"type": "string"},
            "points":      map[string]string{"type": "number"},
            "by":          map[string]string{"type": "string"},
            "commentsURL": map[string]string{"type": "string"},
          },
          "required": []string{"title", "points", "by", "commentsURL"},
        },
        "minItems":    5,
        "maxItems":    5,
        "description": "Hacker News 上排名前 5 的新闻",
      },
    },
    "required": []string{"top"},
  }

  llmExtractionParams := map[string]any{
    "extractorOptions": firecrawl.ExtractorOptions{
      ExtractionSchema: jsonSchema,
    },
  }

  scrapeResult, err := app.ScrapeURL("https://news.ycombinator.com", llmExtractionParams)
  if err != nil {
    log.Fatalf("LLM 提取执行失败：%v", err)
  }
  fmt.Println(scrapeResult)
}
```

<div id="with-rust-sdk">
  ### 使用 Rust SDK
</div>

```rust Rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
    // 使用 API 密钥初始化 FirecrawlApp
    let api_key = "YOUR_API_KEY";
    let api_url = "https://api.firecrawl.dev";
    let app = FirecrawlApp::new(api_key, api_url).expect("FirecrawlApp 初始化失败")

    // 定义用于提取内容的 JSON 模式
    let json_schema = json!({
        "type": "object",
        "properties": {
            "top": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "title": {"type": "string"},
                        "points": {"type": "number"},
                        "by": {"type": "string"},
                        "commentsURL": {"type": "string"}
                    },
                    "required": ["title", "points", "by", "commentsURL"]
                },
                "minItems": 5,
                "maxItems": 5,
                "description": "Hacker News 的前 5 条新闻"
            }
        },
        "required": ["top"]
    });

    let llm_extraction_params = json!({
        "extractorOptions": {
            "extractionSchema": json_schema,
            "mode": "llm-extraction"
        },
        "pageOptions": {
            "onlyMainContent": true
        }
    });

    let llm_extraction_result = app
        .scrape_url("https://news.ycombinator.com", Some(llm_extraction_params))
        .await;
    match llm_extraction_result {
        Ok(data) => println!("LLM 抽取结果：\n{}", data["llm_extraction"]),
        Err(e) => eprintln!("LLM 抽取失败：{}", e),
    }
}
```
