---
title: 'Rust'
description: 'Firecrawl Rust SDK 是一个库，帮助你轻松抓取与爬取网站，并以适用于大语言模型（LLM）的 formats 输出数据。'
icon: 'rust'
og:title: "Rust SDK | Firecrawl"
og:description: "Firecrawl Rust SDK 是一个库，帮助你轻松抓取与爬取网站，并以适用于大语言模型（LLM）的 formats 输出数据。"
---

> 注意：此内容使用的是即将弃用的 [Firecrawl API v0 版本](/zh/v0/introduction)。建议切换到 [v1](/zh/sdks/rust)。

<div id="installation">
  ## 安装
</div>

要安装 Firecrawl 的 Rust SDK，请将以下内容添加到你的 `Cargo.toml`：

```toml
[dependencies]
firecrawl = "^0.1"
tokio = { version = "^1", features = ["full"] }
serde = { version = "^1.0", features = ["derive"] }
serde_json = "^1.0"
uuid = { version = "^1.10", features = ["v4"] }

[build-dependencies]
tokio = { version = "1", features = ["full"] }
```

<div id="usage">
  ## 用法
</div>

1. 在 [firecrawl.dev](https://firecrawl.dev) 获取 API 密钥
2. 将该密钥设置为名为 `FIRECRAWL_API_KEY` 的环境变量，或作为参数传递给 `FirecrawlApp` 结构体。

以下是在 Rust 中使用该 SDK 的示例：

```rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("FirecrawlApp 初始化失败")

  // 抓取单个 URL
  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("抓取结果：{}", data),
    Err(e) => eprintln!("抓取出错：{}", e),
  }
  // 爬取整站
  let crawl_params = json!({
    "pageOptions": {
      "onlyMainContent": true
    }
  });

  let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;
  
  match crawl_result {
    Ok(data) => println!("爬取结果：{}", data),
    Err(e) => eprintln!("爬取出错：{}", e),
  }
}
```

<div id="scraping-a-url">
  ### 抓取 URL
</div>

要在包含错误处理的情况下抓取单个 URL，请使用 `scrape_url` 方法。该方法接收 URL 作为参数，并返回以 `serde_json::Value` 表示的抓取结果。

```rust
let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;

match scrape_result {
  Ok(data) => println!("抓取结果：{}", data),
  Err(e) => eprintln!("抓取 URL 失败：{}", e),
}
```

<div id="crawling-a-website">
  ### 爬取网站
</div>

要爬取网站，请使用 `crawl_url` 方法。它接受起始 URL 和可选参数。通过 `params` 参数，你可以为爬取任务指定其他选项，例如最大爬取页数、允许的域名以及输出格式。

```rust
let crawl_params = json!({
  "crawlerOptions": {
    "excludes": ["blog/"],
    "includes": [], // 为空则抓取所有页面
    "limit": 1000
  },
  "pageOptions": {
    "onlyMainContent": true
  }
});
let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;

match crawl_result {
  Ok(data) => println!("抓取结果：{}", data),
  Err(e) => eprintln!("抓取 URL 失败：{}", e),
}
```

<div id="checking-crawl-status">
  ### 检查爬取状态
</div>

要查看爬取任务的状态，请使用 `check_crawl_status` 方法。该方法接收任务 ID 作为参数，并返回该爬取任务的当前状态。

```rust
let job_id = "your_job_id_here";
let status = app.check_crawl_status(job_id).await;

match status {
  Ok(data) => println!("抓取状态：{}", data),
  Err(e) => eprintln!("检查抓取状态失败：{}", e),
}
```

<div id="canceling-a-crawl-job">
  ### 取消爬取作业
</div>

要取消爬取作业，请使用 `cancel_crawl_job` 方法。该方法接收作业 ID 作为参数，并返回该爬取作业的取消状态。

```rust
let job_id = "your_job_id_here";
let canceled = app.cancel_crawl_job(job_id).await;

match canceled {
  Ok(status) => println!("取消状态：{}", status),
  Err(e) => eprintln!("取消爬取作业失败：{}", e),
}
```

<div id="extracting-structured-data-from-a-url">
  ### 从 URL 提取结构化数据
</div>

借助 LLM 提取功能，你可以轻松从任何 URL 中提取结构化数据。以下是使用方法：

```rust
let json_schema = json!({
  "type": "object",
  "properties": {
    "top": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
        "title": {"type": "string"},
        "points": {"type": "number"},
        "by": {"type": "string"},
        "commentsURL": {"type": "string"}
      },
      "required": ["title", "points", "by", "commentsURL"]
      },
      "minItems": 5,
      "maxItems": 5,
      "description": "Hacker News 上的前 5 条新闻"
    }
  },
  "required": ["top"]
});

let llm_extraction_params = json!({
  "extractorOptions": {
    "extractionSchema": json_schema
  }
});

let scrape_result = app.scrape_url("https://news.ycombinator.com", Some(llm_extraction_params)).await;

match scrape_result {
  Ok(data) => println!("LLM 提取结果：{}", data),
  Err(e) => eprintln!("LLM 提取失败：{}", e),
}
```

<div id="search-for-a-query">
  ### 搜索查询
</div>

要在网页上搜索、获取最相关的结果、抓取每个页面并返回 markdown，请使用 `search` 方法。该方法接收查询作为参数并返回搜索结果。

```rust
let query = "什么是 Firecrawl？";
let search_result = app.search(query).await;

match search_result {
  Ok(data) => println!("搜索结果：{}", data),
  Err(e) => eprintln!("搜索失败：{}", e),
}
```

<div id="error-handling">
  ## 错误处理
</div>

SDK 会处理由 Firecrawl API 返回的错误，并抛出相应异常。如果在请求过程中发生错误，将抛出包含详细说明的错误信息的异常。