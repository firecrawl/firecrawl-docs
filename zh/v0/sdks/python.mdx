---
title: 'Python'
description: 'Firecrawl Python SDK 是 Firecrawl API 的封装，助你轻松将网站内容转换为 Markdown。'
icon: 'python'
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK 是 Firecrawl API 的封装，助你轻松将网站内容转换为 Markdown。"
---

> 注意：此页面使用的是即将弃用的 [Firecrawl API v0 版本](/zh/v0/introduction)。建议迁移至 [v1](/zh/sdks/python)。

<div id="installation">
  ## 安装
</div>

使用 pip 安装 Firecrawl 的 Python SDK：

```bash
pip install firecrawl-py==0.0.16
```

<div id="usage">
  ## 使用
</div>

1. 从 [firecrawl.dev](https://firecrawl.dev) 获取 API 密钥
2. 将该密钥设置为名为 `FIRECRAWL_API_KEY` 的环境变量，或作为参数传递给 `FirecrawlApp` 类。

下面是使用该 SDK 的示例：

```python
from firecrawl import FirecrawlApp

# 使用你的 API 密钥初始化 FirecrawlApp
app = FirecrawlApp(api_key='your_api_key')

# 抓取单个 URL
url = 'https://docs.firecrawl.dev'
scraped_data = app.scrape_url(url)

# 爬取整个网站
crawl_url = 'https://docs.firecrawl.dev'
params = {
    'pageOptions': {
        'onlyMainContent': True
    }
}
crawl_result = app.crawl_url(crawl_url, params=params)
```

<div id="scraping-a-url">
  ### 抓取 URL
</div>

要抓取单个 URL，请使用 `scrape_url` 方法。该方法接收 URL 作为参数，并以字典形式返回抓取结果。

```python
url = 'https://example.com'
scraped_data = app.scrape_url(url)
```

<div id="extracting-structured-data-from-a-url">
  ### 从 URL 提取结构化数据
</div>

借助 LLM 提取，您可以轻松从任意 URL 中提取结构化数据。我们也支持 Pydantic 架构，进一步简化集成。以下是使用方法：

```python
class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="前 5 篇热门文章")

data = app.scrape_url('https://news.ycombinator.com', {
    'extractorOptions': {
        'extractionSchema': TopArticlesSchema.model_json_schema(),
        'mode': 'llm-extraction'
    },
    'pageOptions':{
        'onlyMainContent': True
    }
})
print(data["llm_extraction"])
```

<div id="crawling-a-website">
  ### 爬取网站
</div>

要爬取网站，请使用 `crawl_url` 方法。该方法接受起始 URL 和可选参数。通过 `params` 参数，你可以为爬取任务指定更多选项，例如最大爬取页数、允许的域名以及输出格式。

`wait_until_done` 参数用于控制在返回结果前是否等待爬取任务完成。若设置为 `True`，方法会定期检查任务状态，直到完成或达到指定的 `timeout`（单位：秒）。若设置为 `False`，方法会立即返回任务 ID，你可以使用 `check_crawl_status` 方法手动检查任务状态。

```python
crawl_url = 'https://example.com'
params = {
    'crawlerOptions': {
        'excludes': ['blog/*'],
        'includes': [], # 留空表示包含所有页面
        'limit': 1000,
    },
    'pageOptions': {
        'onlyMainContent': True
    }
}
crawl_result = app.crawl_url(crawl_url, params=params, wait_until_done=True, timeout=5)
```

如果将 `wait_until_done` 设为 `True`，作业完成后 `crawl_url` 方法将返回爬取结果。若作业失败或被停止，将抛出异常。

<div id="checking-crawl-status">
  ### 检查爬取状态
</div>

要查看爬取任务的状态，请使用 `check_crawl_status` 方法。该方法接收任务 ID 作为参数，并返回该爬取任务的当前状态。

```python
job_id = crawl_result['jobId']
status = app.check_crawl_status(job_id)
```

<div id="search-for-a-query">
  ### 搜索查询
</div>

用于在网上搜索、获取最相关的结果、抓取每个页面并返回 Markdown。

```python
query = '什么是 Mendable？'
search_result = app.search(query)
```

<div id="error-handling">
  ## 错误处理
</div>

SDK 会处理 Firecrawl API 返回的错误，并抛出相应的异常。如果在请求过程中发生错误，将抛出包含详细说明的错误信息的异常。