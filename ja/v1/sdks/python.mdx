---
title: 'Python'
description: 'Firecrawl Python SDK は、Firecrawl API のラッパーで、ウェブサイトを簡単に Markdown に変換できます。'
icon: 'python'
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK は、Firecrawl API のラッパーで、ウェブサイトを簡単に Markdown に変換できます。"
---

import InstallationPython from '/snippets/ja/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/ja/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/ja/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/ja/v1/crawl-status/short/python.mdx'
import CrawlAsyncPythonShort from '/snippets/ja/v1/crawl-async/short/python.mdx'
import CancelCrawlPythonShort from '/snippets/ja/v1/crawl-delete/short/python.mdx'
import MapPythonShort from '/snippets/ja/v1/map/short/python.mdx'
import ExtractPythonShort from '/snippets/ja/v1/extract/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/ja/v1/scrape-and-crawl/python.mdx'
import CrawlWebSocketPythonBase from '/snippets/ja/v1/crawl-websocket/base/python.mdx'
import AsyncPythonShort from '/snippets/ja/v1/async/short/python.mdx'

<div id="installation">
  ## インストール
</div>

Firecrawl の Python SDK をインストールするには、pip を使用します。

<InstallationPython />

<div id="usage">
  ## 使い方
</div>

1. [firecrawl.dev](https://firecrawl.dev) から API キーを取得します
2. API キーを環境変数 `FIRECRAWL_API_KEY` に設定するか、`FirecrawlApp` クラスにパラメータとして渡します。

以下は SDK の使用例です:

<ScrapeAndCrawlExamplePython />

<div id="scraping-a-url">
  ### URLのスクレイピング
</div>

単一のURLをスクレイピングするには、`scrape_url` メソッドを使用します。URLを引数に取り、スクレイピング結果を辞書型で返します。

<ScrapePythonShort />

<div id="crawling-a-website">
  ### ウェブサイトのクロール
</div>

ウェブサイトをクロールするには、`crawl_url` メソッドを使用します。開始URLとオプションのパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可ドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。

<CrawlPythonShort />

<div id="asynchronous-crawling">
  ### 非同期クロール
</div>

<Tip>非同期処理をお探しですか？下の[Async Class](#async-class)セクションをご覧ください。</Tip>

ウェブサイトを非同期にクロールするには、`crawl_url_async` メソッドを使用します。クロールの `ID` が返され、その `ID` を使ってジョブのステータスを確認できます。開始URLと任意のパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可するドメイン、出力フォーマットなど、ジョブの追加オプションを指定できます。

<CrawlAsyncPythonShort />

<div id="checking-crawl-status">
  ### クロールステータスの確認
</div>

クロールジョブのステータスを確認するには、`check_crawl_status` メソッドを使用します。ジョブIDを引数に取り、クロールジョブの現在のステータスを返します。

<CheckCrawlStatusPythonShort />

<div id="cancelling-a-crawl">
  ### クローリングのキャンセル
</div>

非同期クローリングジョブをキャンセルするには、`cancel_crawl` メソッドを使用します。非同期クローリングのジョブIDを引数に取り、キャンセル結果のステータスを返します。

<CancelCrawlPythonShort />

<div id="map-a-website">
  ### ウェブサイトをマッピングする
</div>

`map_url` を使って、ウェブサイトから URL の一覧を生成します。`params` 引数で、サブドメインの除外やサイトマップの利用など、マッピング処理をカスタマイズできます。

<MapPythonShort />

{/* ### ウェブサイトから構造化データを抽出する

ウェブサイトから構造化データを抽出するには、`extract` メソッドを使用します。抽出対象の URL、プロンプト、スキーマを引数として受け取ります。スキーマは、抽出データの構造を定義する Pydantic モデルです。

<ExtractPythonShort /> */}

<div id="crawling-a-website-with-websockets">
  ### WebSockets を使ってサイトをクロールする
</div>

WebSockets でサイトをクロールするには、`crawl_url_and_watch` メソッドを使用します。開始 URL と任意のパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可ドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。

<CrawlWebSocketPythonBase />

<div id="error-handling">
  ## エラー処理
</div>

SDK は Firecrawl API から返されるエラーを処理し、適切な例外をスローします。リクエスト中にエラーが発生した場合、わかりやすいエラーメッセージとともに例外がスローされます。

<div id="async-class">
  ## 非同期クラス
</div>

非同期処理には `AsyncFirecrawlApp` クラスを使用できます。メソッドは `FirecrawlApp` クラスと同じですが、メインスレッドをブロックしません。

<AsyncPythonShort />