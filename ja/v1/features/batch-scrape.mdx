---
title: 'バッチスクレイピング'
description: '複数のURLをバッチでスクレイピングする'
og:title: 'バッチスクレイピング | Firecrawl'
og:description: '複数のURLをバッチでスクレイピングする'
---

import BatchScrapePython from '/snippets/ja/v1/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/ja/v1/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/ja/v1/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/ja/v1/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/ja/v1/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/ja/v1/batch-scrape/extract/python.mdx';
import BatchScrapeExtractNode from '/snippets/ja/v1/batch-scrape/extract/js.mdx';
import BatchScrapeExtractCURL from '/snippets/ja/v1/batch-scrape/extract/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/ja/v1/batch-scrape/extract/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/ja/v1/batch-scrape/extract/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/ja/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## 複数URLのバッチスクレイピング
</div>

複数のURLを同時にバッチスクレイピングできます。開始URLと任意のパラメータを引数に取ります。params 引数では、出力のフォーマットなど、バッチスクレイピングジョブの追加オプションを指定できます。

<div id="how-it-works">
  ### 仕組み
</div>

これは `/crawl` エンドポイントの動作と非常によく似ています。バッチスクレイプのジョブを送信し、ステータス確認用のジョブIDを返します。

SDK は同期・非同期の2種類のメソッドを提供します。同期メソッドはバッチスクレイプジョブの結果を返し、非同期メソッドはバッチスクレイプのステータスを確認するために使用できるジョブIDを返します。

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

SDK の同期メソッドを使用している場合は、バッチスクレイプジョブの結果が返されます。そうでない場合は、バッチスクレイプのステータスを確認するために使用できるジョブIDが返されます。

<div id="synchronous">
  #### 同期処理
</div>

<BatchScrapeOutput />

<div id="asynchronous">
  #### 非同期
</div>

その後、ジョブIDを使って `/batch/scrape/{id}` エンドポイントを呼び出し、バッチスクレイプのステータスを確認できます。**バッチスクレイプのジョブは24時間で失効するため**、このエンドポイントはジョブの実行中、または完了直後に使用することを想定しています。

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-extraction">
  ## 抽出を伴うバッチスクレイプ
</div>

バッチスクレイプのエンドポイントを使って、ページから構造化データを抽出することもできます。複数のURLから同一の構造化データを取得したい場合に便利です。

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

<div id="synchronous">
  #### 同期処理
</div>

<BatchScrapeExtractOutput />

<div id="asynchronous">
  #### 非同期
</div>

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Webhooks を使ったバッチスクレイプ
</div>

バッチ内の各 URL がスクレイプされるたびにリアルタイム通知を受け取れるように Webhook を設定できます。これにより、バッチ全体の完了を待たずに結果を即時に処理できます。

<BatchScrapeWebhookCURL />

イベントタイプ、ペイロード構造、実装例を含む詳細な Webhook のドキュメントは、[Webhooks のドキュメント](/ja/webhooks/overview)を参照してください。

<div id="quick-reference">
  ### クイックリファレンス
</div>

**イベントタイプ:**

* `batch_scrape.started` - バッチスクレイプの開始時
* `batch_scrape.page` - 各URLのスクレイプが成功したとき
* `batch_scrape.completed` - すべてのURLの処理が完了したとき
* `batch_scrape.failed` - バッチスクレイプでエラーが発生した場合

**基本ペイロード:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // 'page'イベントのページデータ
  "metadata": {}, // カスタムメタデータ
  "error": null
}
```

<Note>
  Webhook の詳細な設定方法、セキュリティのベストプラクティス、トラブルシューティングについては、[Webhook ドキュメント](/ja/webhooks/overview) を参照してください。
</Note>
