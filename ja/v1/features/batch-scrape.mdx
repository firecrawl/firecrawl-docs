---
title: 'バッチスクレイピング'
description: '複数のURLを一括スクレイピング'
og:title: 'バッチスクレイピング | Firecrawl'
og:description: '複数のURLを一括スクレイピング'
---

import BatchScrapePython from '/snippets/ja/v1/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/ja/v1/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/ja/v1/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/ja/v1/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/ja/v1/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/ja/v1/batch-scrape/extract/python.mdx';
import BatchScrapeExtractNode from '/snippets/ja/v1/batch-scrape/extract/js.mdx';
import BatchScrapeExtractCURL from '/snippets/ja/v1/batch-scrape/extract/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/ja/v1/batch-scrape/extract/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/ja/v1/batch-scrape/extract/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/ja/v1/batch-scrape-webhook/base/curl.mdx';

<div id='batch-scraping-multiple-urls'>## 複数URLのバッチスクレイピング</div>

複数の URL を同時にバッチスクレイピングできます。開始 URL と任意のパラメータを引数に取ります。params 引数では、出力のフォーマットなど、バッチスクレイピングジョブの追加オプションを指定できます。

<div id='how-it-works'>### 仕組み</div>

これは `/crawl` エンドポイントの動作と非常によく似ています。バッチスクレイプのジョブを送信し、その進行状況を確認するためのジョブ ID を返します。

SDK は同期と非同期の 2 つのメソッドを提供します。同期メソッドはバッチスクレイプジョブの結果を返し、非同期メソッドはバッチスクレイプの進行状況を確認するために使用できるジョブ ID を返します。

<div id='usage'>### 使い方</div>

<CodeGroup>
  <BatchScrapePython />

{' '}
<BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id='response'>### レスポンス</div>

SDK の同期メソッドを使用している場合は、バッチスクレイプジョブの結果が返されます。そうでない場合は、バッチスクレイプのステータスを確認するために使用できるジョブ ID が返されます。

<div id='synchronous'>#### 同期処理</div>

<BatchScrapeOutput />

<div id='asynchronous'>#### 非同期</div>

その後、ジョブ ID を使って `/batch/scrape/{id}` エンドポイントを呼び出し、バッチスクレイプのステータスを確認できます。**バッチスクレイプのジョブは 24 時間で失効するため**、このエンドポイントはジョブの実行中、または完了直後に使用することを想定しています。

<BatchScrapeAsyncOutput />

<div id='batch-scrape-with-extraction'>## 抽出を伴うバッチスクレイプ</div>

バッチスクレイプのエンドポイントを使って、ページから構造化データを抽出することもできます。複数の URL から同一の構造化データを取得したい場合に便利です。

<CodeGroup>
  <BatchScrapeExtractPython />

{' '}
<BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id='response'>### レスポンス</div>

<div id='synchronous'>#### 同期処理</div>

<BatchScrapeExtractOutput />

<div id='asynchronous'>#### 非同期</div>

<BatchScrapeExtractAsyncOutput />

<div id='batch-scrape-with-webhooks'>## Webhook を使ったバッチスクレイプ</div>

バッチ内の各 URL がスクレイプされるたびにリアルタイム通知を受け取れるよう、Webhook を設定できます。これにより、バッチ全体の完了を待たずに結果を即時に処理できます。

<BatchScrapeWebhookCURL />

イベントタイプ、ペイロード構造、実装例など、Webhook に関する詳細なドキュメントは [Webhooks ドキュメント](/ja/webhooks/overview)を参照してください。

<div id='quick-reference'>### クイックリファレンス</div>

**イベントタイプ:**

- `batch_scrape.started` - バッチスクレイプが開始されたとき
- `batch_scrape.page` - 各 URL のスクレイプが成功したとき
- `batch_scrape.completed` - すべての URL の処理が完了したとき
- `batch_scrape.failed` - バッチスクレイプでエラーが発生した場合

**基本ペイロード:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // 'page' イベントのページデータ
  "metadata": {}, // カスタムメタデータ
  "error": null
}
```

<Note>
  Webhook
  の詳細な設定方法、セキュリティのベストプラクティス、トラブルシューティングについては、[Webhooks
  ドキュメント](/ja/webhooks/overview)をご覧ください。
</Note>
