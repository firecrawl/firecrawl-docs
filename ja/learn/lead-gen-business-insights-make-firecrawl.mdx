---
title: "LLM抽出による顧客インサイトの活用"
description: "Make と Firecrawl を用いたインサイト獲得とリード創出のための LLM 抽出の活用。"
og:title: "LLM抽出による顧客インサイトの活用 | Firecrawl"
og:description: "Make と Firecrawl を用いたインサイト獲得とリード創出のための LLM 抽出の活用。"
---

> 注: この例は [Firecrawl API の v0 版](/ja/v0/introduction) を使用しています。Python SDK は 0.0.20、Node SDK は 0.0.36 をインストールできます。

<div id="introduction">
  ### はじめに
</div>

お客様を理解すること――彼らが誰かだけでなく、何をしているのか――は、製品やサービスを的確に最適化するうえで極めて重要です。セルフサービス型の導線では、多くのお客様がほとんど情報のない状態で入ってくるため、把握できることが限られます。これらの方々が誰なのかを先回りして理解する作業は、従来、実用的なインサイトを得るための手作業のデータ収集と分析を伴い、時間がかかるものでした。

しかし、LLMの強力な高度抽出能力によって、このプロセスを自動化しました。顧客データをLLMで抽出・分析することで、作業負荷を大幅に削減し、これまで以上に効果的に顧客基盤を理解・支援できるようになりました。

技術的な知識が限られていても、プロダクトの方向性策定やリード獲得を目的に、顧客に関する必要な情報を取得する自動化を構築できます。ここでは、[Make](https://make.com/) と [Firecrawl](https://www.firecrawl.dev/) を使って、自分で実装する方法を紹介します。

***

<div id="overview-of-the-tools">
  ### ツールの概要
</div>

**Firecrawl**

Firecrawl はスクレイピング、検索、抽出のためのプラットフォームです。ウェブ上のデータを取得し、LLM が解釈しやすい Markdown や構造化データへ変換できます。

顧客に関する情報を取得したい場合は、Firecrawl の LLM 抽出機能を使って、各社のウェブサイトから必要な情報を具体的に指定して取り出せます。

**Make.com（旧 Integromat）**

Make は、深い技術知識がなくてもさまざまなアプリやサービスを連携し、カスタムワークフローを作成できるオートメーションプラットフォームです。ユーザーはビジュアルインターフェースで要素をドラッグ＆ドロップして自動化を設計できます。

Make を使ってユーザーデータのスプレッドシートを Firecrawl に接続し、少量の JSON で抽出を実行できます。

<div id="preparing-our-data">
  ### シナリオのセットアップ
</div>

* データ抽出プロセスのセットアップ手順ガイド
* **Google Sheets を Make.com に接続**
  * ユーザーデータの初期収集と保存方法
* **Make.com での HTTP リクエスト設定**
  * Firecrawl への API リクエストの設定方法
  * これらのリクエストの目的（例：企業情報の抽出）

### データの準備

始める前に、Firecrawl に渡すデータを準備しておきます。ここでは、データベースから取り込んだユーザーの簡単なスプレッドシートを作成しました。ユーザーのメールのドメインを取り出し、https:// 形式でリンクに変換します:

![](https://i.imgur.com/gssynZa.png)

また、これらの企業について把握したい属性も追加します。私は企業の概要、業種、顧客層を知りたいので、次の列を用意しました:
company&#95;description
company&#95;type
who&#95;they&#95;serve

データの準備が整ったので、Make で自動化の設定を始めましょう！

## 自動化の設定

自動化を稼働させるには、Makeで3つの手順に従うだけです。ここでは、シナリオ内で3つのアプリを選択します。

Googleスプレッドシート - 範囲の値を取得
HTTP - APIキー認証リクエストを送信
Googleスプレッドシート - 行を更新

エラーが発生した場合に備えて、「フロー制御を無視」ツールも追加しておきます。これで自動化を継続できます。

![](https://i.imgur.com/MdCWv30.png)

この自動化により、スプレッドシートからリンク一式を取り出してFirecrawlに送信し、データを抽出したのち、目的の情報でスプレッドシートを再入力できます。

まずは最初のアプリを設定しましょう。目的は、すべてのURLをエクスポートして、抽出のためにFirecrawlへ送ることです。これらのURLを取得するための設定は次のとおりです。

![](https://i.imgur.com/WHa91kY.png)

**重要* — データの取得は2行目から開始してください。ヘッダーを含めると最終的にエラーになります。

***

すばらしい。設定が完了したので、HTTPリクエストの準備を進めます。まず https://firecrawl.dev にアクセスしてサインアップし、APIキーを取得します（無料で始められます）。サインアップ後は https://firecrawl.dev/account にアクセスすると、APIキーを確認できます。

Firecrawl の /scrape エンドポイントを使用します。このエンドポイントを使うと、単一のURLから情報を取得し、クリーンなMarkdownに変換し、必要なデータを抽出できます。必要な条件はすべて、ドキュメントのAPIリファレンスを参照しながら、MakeのHTTPリクエストに入力します。

Make で、Firecrawl のドキュメントに従って API コールを設定します。HTTP メソッドは POST を使用し、ヘッダーは 2 つ設定します。

```
ヘッダー 1:
名前: Authorization
値: Bearer your-API-key

ヘッダー 2:
名前: Content-Type
値: application/json
```

![](https://i.imgur.com/LJ8g142.png)
リクエストボディとコンテンツタイプも設定します。ここでは次のようにします。

```
ボディタイプ: Raw
コンテンツタイプ: JSON（application/json）
```

応答の解析についても「はい」をクリックします。これにより、応答は自動的にJSONとして解析されます。

達成したいことの要はリクエスト内容です。以下がこのユースケースで使用するリクエスト内容です：

```
{
  "url": "1. url(B)"

"pageOptions": {
    "onlyMainContent": true
  },
  "extractorOptions": {
    "mode": "llm-extraction"
    "extractionPrompt": "会社の説明（何をする会社かを1文で）、会社の業界（ソフトウェア、サービス、AI など。ここは数個のキーワードからなるタグで十分）、提供先（顧客は誰か）を抽出してください。質問に答えるための明確な情報がない場合は「no info」と記載してください。"
    "extractionSchema": {
      "type": "object"
      "properties": {
        "company_description": {
          "type": "string"
        },
        "company_industry": {
          "type": "string"
        },
        "who_they_serve": {
          "type": "string"
        }
      },
      "required": [
        "company_description",
        "company_industry",
        "who_they_serve"
      ]
    }
  }
}
```

![](https://i.imgur.com/DrMc1g2.png)

**注* スクリーンショットの緑色のフィールドは、Make の UI で選択できる動的項目です。`url (B)` の代わりに、そのブロックがデータ内の最初の URL になることがあります。

![](https://i.imgur.com/D4HCBNe.png)

素晴らしい！これでHTTPリクエストの設定が完了しました。すべてが期待どおりに動作するか確認するため、テストしてみましょう。Makeで「run once」をクリックすると、データが返ってくるはずです。

![](https://i.imgur.com/QuQZs0U.png)

実行したら、まず最初の処理を確認しましょう。出力に「status code: 200」が表示されていれば、APIリクエストは成功です。出力内の data をクリックして、必要なデータが取得できているか確認してください。

![](https://i.imgur.com/pm614VA.png)

出力はうまくいったようです！ llm&#95;extraction には、ウェブサイトから取得したかったデータの3つの属性が確認できます。

**注* 最初の操作で `500` エラーが発生し、その後の操作で `200` が返る場合、処理がデータの先頭行（ヘッダー行）に対して実行されている可能性があります。これはデータをシートに再インポートする際に問題の原因になります。前述のとおり、必ず2行目から開始してください。

HTTP リクエストが正しく動作していることが確認できたので、あとは Firecrawl の出力 JSON をスプレッドシートに戻すだけです。

***

次に、抽出したデータをスプレッドシートへ戻します。これには、HTTP リクエストの出力 JSON を取り込み、該当するテーブルにテキストとして書き出します。

まずは同じ Google シートに接続し、Row Number の条件を指定します。ここでは Make の UI で「row number」を選択します。

![](https://i.imgur.com/BYpPabk.png)

次に、どの列にどの LLM 抽出データを入れるかを指定します。これは Make の UI で簡単に設定できます。

![](https://i.imgur.com/219tft2.png)

これで準備完了です。自動化をテストしましょう。

***

Make の UI で「run once」をクリックし、すべてが問題なく動いているか確認します。自動化はリンクごとに反復処理を行い、リアルタイムでスプレッドシートを更新するはずです。

![](https://i.imgur.com/vU1CJlt.png)

成功しました！Make と Firecrawl を使えば、各サイトに手動でアクセスすることなく、顧客に関する特定の情報を抽出できます。

データを見ると、顧客への理解が深まっていることがわかります。とはいえ、これらの特性に限定される必要はありません。必要に応じて JSON と抽出プロンプトをカスタマイズして、これらの企業に関する別の情報も取得できます。

<div id="going-a-step-further">
  ### ユースケース
</div>

LLM抽出を使えば、ビジネスに関連する特定情報をウェブから素早く取得できます。こうした自動化を活用して、さまざまなタスクを実行できます。

**プロダクト:**
特にセルフサーブ型の企業では、自社プロダクトを通じて業界トレンドを把握できます。私たちの技術を使っている上位2〜3の業界はどこで、どんな用途で使われているのか。これにより、注力すべき顧客の優先順位付けが可能になり、より良いプロダクト判断につながります。

**ビジネスデベロップメント:**
ユーザー像を理解することで、同様に私たちのプロダクトから価値を得られる類似企業を特定できます。同様の自動化により、見込み客からポジティブなシグナルを抽出できます。

また、このデータを活用して、個々の見込み客により最適化された効果的なアウトリーチメールを作成できます。

**市場調査:**
市場調査会社は、特にニッチ分野で二次情報収集に多大な時間を費やしています。多様なソースからのデータ抽出と整理を自動化することで、収集プロセスを効率化できます。こうした自動化は効率を高め、増大するデータ需要にスケールし、変化の速い業界における戦略的意思決定の有効なツールとなります。

### さらに踏み込む

これは、静的なスプレッドシートを使い、LLMでウェブサイトから関連データを抽出するシンプルな例にすぎません。サインアップフローと動的に連携させれば、さらに高度化できます。加えて、ほかのツールと組み合わせて生産性を一層高めることも可能です。たとえば、抽出したコンテンツを活用して、見込み客向けによりパーソナライズされたコピーを生成する、といった使い方です。

役に立ったと感じたら、ぜひ教えてください。フィードバックや、皆さんの取り組みについて聞けると嬉しいです。eric@mendable.ai までご連絡ください。健闘を祈ります。ものづくりを楽しんでください！