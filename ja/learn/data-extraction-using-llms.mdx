---
title: "LLMでウェブサイトのデータを抽出する"
description: "数行のコードで Firecrawl と Groq を使って、ウェブページから構造化データを抽出する方法を学びます。"
"og:image": "/images/og.png"
"twitter:image": "/images/og.png"
og:title: "LLMでウェブサイトのデータを抽出する | Firecrawl"
og:description: "数行のコードで Firecrawl と Groq を使って、ウェブページから構造化データを抽出する方法を学びます。"
---

> 注: この例は [Firecrawl API の v0 版](/ja/v0/introduction) を使用しています。Python SDK は 0.0.20、Node SDK は 0.0.36 をインストールできます。

<div id="setup">
  ## セットアップ
</div>

groq と firecrawl-py を含む Python の依存関係をインストールします。

```bash
pip install groq firecrawl-py
```

<div id="getting-your-groq-and-firecrawl-api-keys">
  ## Groq と Firecrawl の API キーを取得する
</div>

Groq と Firecrawl を利用するには、API キーが必要です。Groq の API キーは[こちら](https://groq.com)、Firecrawl の API キーは[こちら](https://firecrawl.dev)から取得できます。

<div id="load-website-with-firecrawl">
  ## Firecrawl でウェブサイトを読み込む
</div>

ウェブページからすべてのデータを取得し、最もクリーンなフォーマットで出力するために、[Firecrawl](https://firecrawl.dev) を使用します。Firecrawl は、JS でブロックされたサイトの回避、主要コンテンツの抽出、そして精度向上のための LLM が読み取り可能なフォーマットでの出力を処理します。

以下では、Firecrawl を使ってウェブサイトの URL をスクレイピングする方法を示します。ページの主要コンテンツのみを抽出し（ナビゲーションやフッターなどを除外）、`pageOptions` で `onlyMainContent: True` を設定します。

```python
from firecrawl import FirecrawlApp  # FireCrawlLoader をインポート

url = "https://about.fb.com/news/2024/04/introducing-our-open-mixed-reality-ecosystem/"

firecrawl = FirecrawlApp(
    api_key="fc-YOUR_FIRECRAWL_API_KEY",
)
page_content = firecrawl.scrape_url(url=url,  # クロール対象のURL
    params={
        "pageOptions":{
            "onlyMainContent": True # ナビゲーションやフッターなどを除外
        }
    })
print(page_content)
```

完璧です。これでサイトからクリーンなデータが用意できました。LLMに渡してデータ抽出する準備は万端です。

<div id="extraction-and-generation">
  ## 抽出と生成
</div>

ウェブサイトのデータが揃ったので、必要な情報を抽出するために Groq を使いましょう。Groq の Llama 3 モデルを JSONモード で用い、ページコンテンツから特定のフィールドを抽出します。

この例では Llama 3 8B モデルを使用しています。より良い結果が必要であれば、より大きなモデルを使ってください。

```python
import json
from groq import Groq

client = Groq(
    api_key="gsk_YOUR_GROQ_API_KEY",  # 注意: 'API_KEY' を実際の Groq の API キーに置き換えてください
)

# ページのコンテンツから抽出したいフィールドを定義します
extract = ["summary","date","companies_building_with_quest","title_of_the_article","people_testimonials"]

completion = client.chat.completions.create(
    model="llama3-8b-8192",
    messages=[
        {
            "role": "system",
            "content": "あなたは JSON 形式で文書から情報を抽出する法務アドバイザーです。"
        },
        {
            "role": "user",
            # ページのコンテンツと抽出対象のフィールドを渡します
            "content": f"提供されたドキュメントから次の情報を抽出してください：\\Page content:\n\n{page_content}\n\nInformation to extract: {extract}"
        }
    ],
    temperature=0,
    max_tokens=1024,
    top_p=1,
    stream=False,
    stop=None,
    # レスポンスのフォーマットを JSON オブジェクトに設定します
    response_format={"type": "json_object"}
)


# JSON レスポンスを見やすく整形して出力します
dataExtracted = json.dumps(str(completion.choices[0].message.content), indent=4)

print(dataExtracted)
```

<div id="and-voila">
  ## 完成です！
</div>

Groq と Firecrawl を使ってデータ抽出ボットを作成できました。これで、このボットを使って任意のウェブサイトから構造化データを抽出できます。

ご質問やサポートが必要な場合は、[Firecrawl](https://firecrawl.dev) までお気軽にお問い合わせください。