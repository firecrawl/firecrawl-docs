---
title: 'LLM抽出'
description: 'LLMでページから構造化データを抽出'
icon: 'file-export'
og:title: "抽出 | Firecrawl"
og:description: "LLMでページから構造化データを抽出"
---

<div id="scrape-and-extract-structured-data-with-firecrawl">
  ## Firecrawlで構造化データをスクレイプして抽出する
</div>

FirecrawlはLarge Language Models（LLMs）を活用し、ウェブページから構造化データを効率よく抽出します。手順は次のとおりです。

1. **スキーマ定義:**
   JSON Schema（OpenAIのツールスキーマに準拠）を使い、スクレイプするURLと取得したいデータのスキーマを定義します。このスキーマで、ページから抽出したいデータ構造を指定します。

2. **/scrape エンドポイント:**
   URLとスキーマを /scrape エンドポイントに渡します。エンドポイントのドキュメントはこちら:
   [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

3. **構造化データの取得:**
   スキーマで定義した構造に従い、スクレイプ結果を構造化フォーマットで受け取ります。その後、このデータをアプリケーションで利用したり、追加処理に回せます。

この方法により、データ抽出を簡素化し、手作業を削減して効率を高められます。

<div id="extract-structured-data">
  ## 構造化データの抽出
</div>

<div id="scrape-with-extract-endpoint">
  ### /scrape（extract付き）エンドポイント
</div>

スクレイプしたページから構造化データを抽出するために使用します。

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "extractorOptions": {
        "mode": "llm-extraction",
        "extractionPrompt": "ページの情報に基づいて、スキーマに従って情報を抽出してください。",
        "extractionSchema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
```

```json
{
    "success": true,
    "data": {
      "content": "Raw Content",
      "metadata": {
        "title": "Mendable",
        "description": "Mendable は、AI チャットアプリケーションを簡単に構築できます。データを取り込み、カスタマイズし、1 行のコードでどこにでもデプロイ可能。SideGuide 提供。",
        "robots": "follow, index",
        "ogTitle": "Mendable",
        "ogDescription": "Mendable は、AI チャットアプリケーションを簡単に構築できます。データを取り込み、カスタマイズし、1 行のコードでどこにでもデプロイ可能。SideGuide 提供。",
        "ogUrl": "https://docs.firecrawl.dev/",
        "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
        "ogLocaleAlternate": [],
        "ogSiteName": "Mendable",
        "sourceURL": "https://docs.firecrawl.dev/"
      },
      "llm_extraction": {
        "company_mission": "技術リソースを基に安全な AI を訓練し、顧客や従業員からの質問に回答して、チームの負担を軽減します",
        "supports_sso": true,
        "is_open_source": false,
        "is_in_yc": true
      }
    }
}

```

<div id="using-python-sdk">
  ### Python SDK を使う
</div>

```python
from firecrawl import FirecrawlApp

# Initialize the FirecrawlApp with your API key
app = FirecrawlApp(api_key='your_api_key', version='v0')

class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="上位5件の記事")

data = app.scrape_url('https://news.ycombinator.com', {
    'extractorOptions': {
        'extractionSchema': TopArticlesSchema.model_json_schema(),
        'mode': 'llm-extraction'
    },
    'pageOptions':{
        'onlyMainContent': True
    }
})
print(data["llm_extraction"])
```

<div id="with-javascript-sdk">
  ### JavaScript SDK の利用
</div>

```js
import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY",
  version: "v0"
});

// コンテンツを抽出するスキーマを定義
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Top 5 stories on Hacker News"),
});

const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
  extractorOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["llm_extraction"]);
```

<div id="with-go-sdk">
  ### Go SDK を使用する
</div>

```go Go
import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
      log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
  }

  jsonSchema := map[string]any{
    "type": "object",
    "properties": map[string]any{
      "top": map[string]any{
        "type": "array",
        "items": map[string]any{
          "type": "object",
          "properties": map[string]any{
            "title":       map[string]string{"type": "string"},
            "points":      map[string]string{"type": "number"},
            "by":          map[string]string{"type": "string"},
            "commentsURL": map[string]string{"type": "string"},
          },
          "required": []string{"title", "points", "by", "commentsURL"},
        },
        "minItems":    5,
        "maxItems":    5,
        "description": "Hacker Newsのトップ5記事",
      },
    },
    "required": []string{"top"},
  }

  llmExtractionParams := map[string]any{
    "extractorOptions": firecrawl.ExtractorOptions{
      ExtractionSchema: jsonSchema,
    },
  }

  scrapeResult, err := app.ScrapeURL("https://news.ycombinator.com", llmExtractionParams)
  if err != nil {
    log.Fatalf("Failed to perform LLM extraction: %v", err)
  }
  fmt.Println(scrapeResult)
}
```

<div id="with-rust-sdk">
  ### Rust SDK を使用する
</div>

```rust Rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
    // APIキーでFirecrawlAppを初期化
    let api_key = "YOUR_API_KEY";
    let api_url = "https://api.firecrawl.dev";
    let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

    // 抽出するコンテンツのスキーマを定義
    let json_schema = json!({
        "type": "object",
        "properties": {
            "top": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "title": {"type": "string"},
                        "points": {"type": "number"},
                        "by": {"type": "string"},
                        "commentsURL": {"type": "string"}
                    },
                    "required": ["title", "points", "by", "commentsURL"]
                },
                "minItems": 5,
                "maxItems": 5,
                "description": "Hacker Newsのトップ5記事"
            }
        },
        "required": ["top"]
    });

    let llm_extraction_params = json!({
        "extractorOptions": {
            "extractionSchema": json_schema,
            "mode": "llm-extraction"
        },
        "pageOptions": {
            "onlyMainContent": true
        }
    });

    let llm_extraction_result = app
        .scrape_url("https://news.ycombinator.com", Some(llm_extraction_params))
        .await;
    match llm_extraction_result {
        Ok(data) => println!("LLM Extraction Result:\n{}", data["llm_extraction"]),
        Err(e) => eprintln!("LLM Extraction failed: {}", e),
    }
}
```
