---
title: 'Node'
description: 'Firecrawl Node SDK は、Firecrawl API のラッパーで、ウェブサイトを簡単に Markdown に変換できます。'
icon: 'node'
og:title: "Node SDK | Firecrawl"
og:description: "Firecrawl Node SDK は、Firecrawl API のラッパーで、ウェブサイトを簡単に Markdown に変換できます。"
---

> 注意: これは廃止予定の [Firecrawl API v0](/ja/v0/introduction) を使用しています。[v1](/ja/sdks/node) への移行を推奨します。

<div id="installation">
  ## インストール
</div>

Firecrawl の Node SDK をインストールするには、npm を使用します。

```bash
npm install @mendable/firecrawl-js@0.0.36
```

<div id="usage">
  ## 使い方
</div>

1. [firecrawl.dev](https://firecrawl.dev) から API キーを取得します。
2. 環境変数 `FIRECRAWL_API_KEY` に API キーを設定するか、`FirecrawlApp` クラスにパラメータとして渡します。

以下はエラーハンドリングを含む SDK の使用例です：

```js
import FirecrawlApp from '@mendable/firecrawl-js';

// APIキーで FirecrawlApp を初期化する
const app = new FirecrawlApp({ apiKey: "YOUR_API_KEY" });

// 単一のURLをスクレイピングする
const url = 'https://docs.firecrawl.dev';
const scrapedData = await app.scrapeUrl(url);

// サイト全体をクロールする
const crawlUrl = 'https://docs.firecrawl.dev';
const params = {
  crawlerOptions: {
    excludes: ['blog/'],
    includes: [], // すべてのページを対象にする場合は空のままにする
    limit: 1000,
  },
  pageOptions: {
      onlyMainContent: true
  }
};

const crawlResult = await app.crawlUrl(crawlUrl, params);
```

<div id="scraping-a-url">
  ### URLのスクレイピング
</div>

単一のURLをエラー処理付きでスクレイピングするには、`scrapeUrl` メソッドを使用します。URLを引数に取り、スクレイプしたデータをディクショナリ（連想配列）として返します。

```js
const url = 'https://example.com';
const scrapedData = await app.scrapeUrl(url);
```

<div id="crawling-a-website">
  ### ウェブサイトのクロール
</div>

エラー処理付きでウェブサイトをクロールするには、`crawlUrl` メソッドを使用します。開始URLと任意のパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可するドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。

```js
const crawlUrl = 'https://example.com';

const params = {
  crawlerOptions: {
    excludes: ['blog/'],
    includes: [], // 全ページを対象にする場合は空のままにします
    limit: 1000,
  },
  pageOptions: {
    onlyMainContent: true
  }
};

const waitUntilDone = true;
const pollInterval = 5;

const crawlResult = await app.crawlUrl(
  crawlUrl,
  params,
  waitUntilDone,
  pollInterval
);
```

<div id="checking-crawl-status">
  ### クロールステータスの確認
</div>

エラー処理込みでクロールジョブのステータスを確認するには、`checkCrawlStatus` メソッドを使用します。ジョブ ID を引数に取り、クロールジョブの現在のステータスを返します。

```js
const status = await app.checkCrawlStatus(jobId);
```

<div id="extracting-structured-data-from-a-url">
  ### URL から構造化データを抽出する
</div>

LLM による抽出を使えば、任意の URL から構造化データを簡単に取り出せます。より手軽に扱えるよう、zod スキーマにも対応しています。使い方は次のとおりです：

```js
import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY",
});

// 抽出した内容を格納するスキーマを定義
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Hacker News のトップ5件の記事"),
});

const scrapeResult = await app.scrapeUrl("https://firecrawl.dev", {
  extractorOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["llm_extraction"]);
```

<div id="search-for-a-query">
  ### クエリを検索する
</div>

`search` メソッドを使うと、検索エンジンでクエリを実行し、各結果のページ内容とともに上位結果を取得できます。メソッドはクエリをパラメータとして受け取り、検索結果を返します。

```js
const query = 'Mendable とは？';
const searchResults = await app.search(query, {
  pageOptions: {
    fetchPageContent: true // 各検索結果のページコンテンツを取得する
  }
});
```

<div id="error-handling">
  ## エラー処理
</div>

SDK は Firecrawl API から返されるエラーを処理し、適切な例外を送出します。リクエスト中にエラーが発生した場合は、内容を説明するエラーメッセージ付きで例外が送出されます。上記の例では、`try/catch` ブロックでこれらのエラーを扱う方法を示しています。