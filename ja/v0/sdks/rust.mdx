---
title: 'Rust'
description: 'Firecrawl Rust SDK は、ウェブサイトのスクレイピングやクロールを簡単に行い、言語モデル（LLM）でそのまま使えるフォーマットでデータを出力するためのライブラリです。'
icon: 'rust'
og:title: "Rust SDK | Firecrawl"
og:description: "Firecrawl Rust SDK は、ウェブサイトのスクレイピングやクロールを簡単に行い、言語モデル（LLM）でそのまま使えるフォーマットでデータを出力するためのライブラリです。"
---

> 注意: これは [Firecrawl API の v0 バージョン](/ja/v0/introduction)を使用しており、非推奨となります。[v1](/ja/sdks/rust) への移行を推奨します。

<div id="installation">
  ## インストール
</div>

Firecrawl の Rust SDK をインストールするには、`Cargo.toml` に次を追加します:

```toml
[dependencies]
firecrawl = "^0.1"
tokio = { version = "^1", features = ["full"] }
serde = { version = "^1.0", features = ["derive"] }
serde_json = "^1.0"
uuid = { version = "^1.10", features = ["v4"] }

[build-dependencies]
tokio = { version = "1", features = ["full"] }
```

<div id="usage">
  ## 使い方
</div>

1. [firecrawl.dev](https://firecrawl.dev) から API キーを取得します
2. 環境変数 `FIRECRAWL_API_KEY` に API キーを設定するか、`FirecrawlApp` 構造体のパラメータとして渡します。

以下は、Rust で SDK を使用する例です。

```rust
use firecrawl::FirecrawlApp;

#[tokio::main]
async fn main() {
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("FirecrawlApp の初期化に失敗しました")

  // 単一の URL をスクレイピング
  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("スクレイピング結果: {}", data),
    Err(e) => eprintln!("スクレイピング中にエラーが発生しました: {}", e),
  }
  // ウェブサイトをクロール
  let crawl_params = json!({
    "pageOptions": {
      "onlyMainContent": true
    }
  });

  let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;
  
  match crawl_result {
    Ok(data) => println!("クロール結果: {}", data),
    Err(e) => eprintln!("クロール中にエラーが発生しました: {}", e),
  }
}
```

<div id="scraping-a-url">
  ### URLのスクレイピング
</div>

エラーハンドリング付きで単一のURLをスクレイピングするには、`scrape_url`メソッドを使用します。URLを引数に取り、スクレイプしたデータを`serde_json::Value`として返します。

```rust
let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;

match scrape_result {
  Ok(data) => println!("取得したデータ: {}", data),
  Err(e) => eprintln!("URLのスクレイプに失敗しました: {}", e),
}
```

<div id="crawling-a-website">
  ### ウェブサイトのクロール
</div>

ウェブサイトをクロールするには、`crawl_url` メソッドを使用します。開始URLと任意のパラメータを引数に取ります。`params` 引数では、クロール対象ページ数の上限、許可ドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。

```rust
let crawl_params = json!({
  "crawlerOptions": {
    "excludes": ["blog/"],
    "includes": [], // すべてのページを対象にするには空のままにする
    "limit": 1000
  },
  "pageOptions": {
    "onlyMainContent": true
  }
});
let crawl_result = app.crawl_url("https://docs.firecrawl.dev", Some(crawl_params)).await;

match crawl_result {
  Ok(data) => println!("クロール結果: {}", data),
  Err(e) => eprintln!("URLのクロールに失敗しました: {}", e),
}
```

<div id="checking-crawl-status">
  ### クロールステータスの確認
</div>

クロールジョブのステータスを確認するには、`check_crawl_status` メソッドを使用します。ジョブIDを引数に取り、クロールジョブの現在のステータスを返します。

```rust
let job_id = "your_job_id_here";
let status = app.check_crawl_status(job_id).await;

match status {
  Ok(data) => println!("クロール状況: {}", data),
  Err(e) => eprintln!("クロール状況の確認に失敗しました: {}", e),
}
```

<div id="canceling-a-crawl-job">
  ### クロールジョブのキャンセル
</div>

クロールジョブをキャンセルするには、`cancel_crawl_job` メソッドを使用します。ジョブIDを引数に取り、当該クロールジョブのキャンセル状況を返します。

```rust
let job_id = "your_job_id_here";
let canceled = app.cancel_crawl_job(job_id).await;

match canceled {
  Ok(status) => println!("キャンセルステータス: {}", status),
  Err(e) => eprintln!("クロールジョブのキャンセルに失敗しました: {}", e),
}
```

<div id="extracting-structured-data-from-a-url">
  ### URL から構造化データを抽出する
</div>

LLM による抽出を使えば、任意の URL から構造化データを簡単に取得できます。使い方は次のとおりです:

```rust
let json_schema = json!({
  "type": "object",
  "properties": {
    "top": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
        "title": {"type": "string"},
        "points": {"type": "number"},
        "by": {"type": "string"},
        "commentsURL": {"type": "string"}
      },
      "required": ["title", "points", "by", "commentsURL"]
      },
      "minItems": 5,
      "maxItems": 5,
      "description": "Hacker News のトップ 5 件の記事"
    }
  },
  "required": ["top"]
});

let llm_extraction_params = json!({
  "extractorOptions": {
    "extractionSchema": json_schema
  }
});

let scrape_result = app.scrape_url("https://news.ycombinator.com", Some(llm_extraction_params)).await;

match scrape_result {
  Ok(data) => println!("LLM 抽出結果: {}", data),
  Err(e) => eprintln!("LLM 抽出の実行に失敗しました: {}", e),
}
```

<div id="search-for-a-query">
  ### クエリを検索する
</div>

ウェブを検索して最も関連性の高い結果を取得し、各ページをスクレイピングしてMarkdownを返すには、`search` メソッドを使用します。このメソッドはクエリをパラメーターとして受け取り、検索結果を返します。

```rust
let query = "Firecrawl とは何ですか？";
let search_result = app.search(query).await;

match search_result {
  Ok(data) => println!("検索結果: {}", data),
  Err(e) => eprintln!("検索に失敗しました: {}", e),
}
```

<div id="error-handling">
  ## エラーハンドリング
</div>

SDK は Firecrawl API から返されるエラーを処理し、適切な例外を送出します。リクエスト中にエラーが発生した場合は、わかりやすいエラーメッセージを添えて例外を送出します。