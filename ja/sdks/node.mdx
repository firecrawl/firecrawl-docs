---
title: 'Node'
description: 'Firecrawl Node SDK は、Firecrawl API を扱いやすくするラッパーで、ウェブサイトを手早く Markdown に変換できます。'
icon: 'node'
og:title: "Node SDK | Firecrawl"
og:description: "Firecrawl Node SDK は、Firecrawl API を扱いやすくするラッパーで、ウェブサイトを手早く Markdown に変換できます。"
---

import InstallationNode from '/snippets/ja/v2/installation/js.mdx'
import ScrapeAndCrawlExampleNode from '/snippets/ja/v2/scrape-and-crawl/js.mdx'
import ScrapeNodeShort from '/snippets/ja/v2/scrape/short/js.mdx'
import CrawlNodeShort from '/snippets/ja/v2/crawl/short/js.mdx'
import CrawlSitemapOnlyNode from '/snippets/ja/v2/crawl/sitemap-only/js.mdx'
import StartCrawlNodeShort from '/snippets/ja/v2/start-crawl/short/js.mdx'
import CheckCrawlStatusNodeShort from '/snippets/ja/v2/crawl-status/short/js.mdx'
import CancelCrawlNodeShort from '/snippets/ja/v2/crawl-delete/short/js.mdx'
import MapNodeShort from '/snippets/ja/v2/map/short/js.mdx'
import ExtractNodeShort from '/snippets/v2/extract/short/js.mdx'
import CrawlWebSocketNodeBase from '/snippets/ja/v2/crawl-websocket/base/js.mdx'


<div id="installation">
  ## インストール
</div>

Firecrawl の Node SDK をインストールするには、npm を使用します。

<InstallationNode />

<div id="usage">
  ## 使い方
</div>

1. [firecrawl.dev](https://firecrawl.dev) から API キーを取得します。
2. 環境変数 `FIRECRAWL_API_KEY` に API キーを設定するか、`FirecrawlApp` クラスにパラメータとして渡します。

エラーハンドリング付きで SDK を使用する例は次のとおりです:

<ScrapeAndCrawlExampleNode />

<div id="scraping-a-url">
  ### URLをスクレイピングする
</div>

エラー処理付きで単一のURLをスクレイプするには、`scrapeUrl` メソッドを使用します。URLを引数に取り、スクレイプしたデータをディクショナリ（辞書）として返します。

<ScrapeNodeShort />

<div id="crawling-a-website">
  ### ウェブサイトのクロール
</div>

エラーハンドリング込みでウェブサイトをクロールするには、`crawlUrl` メソッドを使用します。開始URLと任意のパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可ドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。自動／手動のページネーションや上限設定については [Pagination](#pagination) を参照してください。

<CrawlNodeShort />

<div id="sitemap-only-crawl">
  ### サイトマップのみクロール
</div>

`sitemap: "only"` を使用すると、サイトマップ内の URL のみをクロールします（開始URLは常に対象に含まれ、HTML リンクの探索は行われません）。

<CrawlSitemapOnlyNode />

<div id="start-a-crawl">
  ### クローリングを開始
</div>

`startCrawl` を使うと待機せずにジョブを開始できます。ステータス確認に使えるジョブの `ID` が返されます。完了まで処理をブロックするウェイターが必要な場合は `crawl` を使用してください。ページングの挙動と制限については [Pagination](#pagination) を参照してください。

<StartCrawlNodeShort />

<div id="checking-crawl-status">
  ### クロールのステータス確認
</div>

エラー処理付きでクロールジョブのステータスを確認するには、`checkCrawlStatus` メソッドを使用します。`ID` を引数に取り、クロールジョブの現在のステータスを返します。

<CheckCrawlStatusNodeShort />

<div id="cancelling-a-crawl">
  ### クロールのキャンセル
</div>

クロールジョブをキャンセルするには、`cancelCrawl` メソッドを使用します。`startCrawl` のジョブIDを引数に渡すと、キャンセル結果のステータスが返されます。

<CancelCrawlNodeShort />

<div id="mapping-a-website">
  ### ウェブサイトのマッピング
</div>

エラー処理込みでウェブサイトをマッピングするには、`mapUrl` メソッドを使用します。開始 URL を引数に取り、マッピング結果をディクショナリとして返します。

<MapNodeShort />

{/* ### ウェブサイトからの構造化データ抽出

  エラー処理込みでウェブサイトから構造化データを抽出するには、`extractUrl` メソッドを使用します。開始 URL を引数に取り、抽出結果をディクショナリとして返します。

  <ExtractNodeShort /> */}

<div id="crawling-a-website-with-websockets">
  ### WebSocket を使ったサイトのクロール
</div>

WebSocket を使ってサイトをクロールするには、`crawlUrlAndWatch` メソッドを使用します。開始 URL と任意のパラメータを引数に取ります。`params` 引数では、クロールする最大ページ数、許可ドメイン、出力フォーマットなど、クロールジョブの追加オプションを指定できます。

<CrawlWebSocketNodeBase />

<div id="pagination">
  ### ページネーション
</div>

Firecrawl の /crawl と batch の各エンドポイントは、追加のデータがある場合に `next` URL を返します。Node SDK はデフォルトで自動ページネーションを行い、すべてのドキュメントを集約します。その場合は `next` が `null` になります。自動ページネーションを無効にしたり、上限を設定したりできます。

<div id="crawl">
  #### クロール
</div>

最も手軽なのはウェイター方式の `crawl` を使うことです。あるいはジョブを開始して、ページングを手動で行ってください。

<div id="simple-crawl-auto-pagination-default">
  ##### シンプルなクロール（自動ページ送り、デフォルト）
</div>

* 既定のフローは[ウェブサイトのクロール](#crawling-a-website)を参照してください。

<div id="manual-crawl-with-pagination-control-single-page">
  ##### ページネーション制御付きの手動クロール（単一ページ）
</div>

* ジョブを開始し、`autoPaginate: false` を指定して1ページずつ取得します。

```js Node
const crawlStart = await firecrawl.startCrawl('https://docs.firecrawl.dev', { limit: 5 });
const crawlJobId = crawlStart.id;

const crawlSingle = await firecrawl.getCrawlStatus(crawlJobId, { autoPaginate: false });
console.log('単一ページのクロール:', crawlSingle.status, 'ドキュメント数:', crawlSingle.data.length, '次:', crawlSingle.next);
```

<div id="manual-crawl-with-limits-auto-pagination-early-stop">
  ##### 制限付きの手動クロール（自動ページネーション + 早期停止）
</div>

* 自動ページネーションはオンのまま、`maxPages`、`maxResults`、または `maxWaitTime` で早めに停止します。

```js Node
const crawlLimited = await firecrawl.getCrawlStatus(crawlJobId, {
  autoPaginate: true,
  maxPages: 2,
  maxResults: 50,
  maxWaitTime: 15,
});
console.log('クロール制限:', crawlLimited.status, 'ドキュメント数:', crawlLimited.data.length, '次:', crawlLimited.next);
```

<div id="batch-scrape">
  #### バッチスクレイプ
</div>

waiter メソッド `batchScrape` を使うか、ジョブを開始して手動でページングします。

<div id="simple-batch-scrape-auto-pagination-default">
  ##### シンプルなバッチスクレイプ（自動ページネーション、デフォルト）
</div>

* 既定のフローは [Batch Scrape](/ja/features/batch-scrape) を参照してください。

<div id="manual-batch-scrape-with-pagination-control-single-page">
  ##### ページネーション制御による手動バッチスクレイプ（単一ページ）
</div>

* ジョブを開始し、`autoPaginate: false` を指定して1ページずつ取得します。

```js Node
const batchStart = await firecrawl.startBatchScrape([
  'https://docs.firecrawl.dev',
  'https://firecrawl.dev',
], { options: { formats: ['markdown'] } });
const batchJobId = batchStart.id;

const batchSingle = await firecrawl.getBatchScrapeStatus(batchJobId, { autoPaginate: false });
console.log('バッチ単一ページ:', batchSingle.status, 'ドキュメント数:', batchSingle.data.length, '次:', batchSingle.next);
```

<div id="manual-batch-scrape-with-limits-auto-pagination-early-stop">
  ##### 制限付きの手動バッチスクレイプ（自動ページネーション＋早期停止）
</div>

* 自動ページネーションは有効のまま、`maxPages`、`maxResults`、または `maxWaitTime` で早期停止します。

```js Node
const batchLimited = await firecrawl.getBatchScrapeStatus(batchJobId, {
  autoPaginate: true,
  maxPages: 2,
  maxResults: 100,
  maxWaitTime: 20,
});
console.log('バッチ制限:', batchLimited.status, 'ドキュメント:', batchLimited.data.length, '次:', batchLimited.next);
```

<div id="browser">
  ## ブラウザ
</div>

クラウドブラウザセッションを起動し、リモートでコードを実行します。

<div id="create-a-session">
  ### セッションを作成する
</div>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: "fc-YOUR-API-KEY" });

const session = await firecrawl.browser({ ttl: 300 });
console.log(session.id);          // セッションID
console.log(session.cdpUrl);      // wss://cdp-proxy.firecrawl.dev/cdp/...
console.log(session.liveViewUrl); // https://liveview.firecrawl.dev/...
```


<div id="execute-code">
  ### コードの実行
</div>

```js Node
const result = await firecrawl.browserExecute(session.id, {
  code: 'await page.goto("https://news.ycombinator.com")\ntitle = await page.title()\nprint(title)',
});
console.log(result.result); // "Hacker News"
```

Python の代わりに JavaScript を実行する:

```js Node
const result = await firecrawl.browserExecute(session.id, {
  code: 'await page.goto("https://example.com"); const t = await page.title(); console.log(t);',
  language: "node",
});
```

agent-browser 経由で Bash を実行する:

```js Node
const result = await firecrawl.browserExecute(session.id, {
  code: "agent-browser open https://example.com && agent-browser snapshot",
  language: "bash",
});
```


<div id="connect-via-cdp">
  ### CDP 経由で接続する
</div>

Playwright をフルに制御するには、CDP URL を使用して直接接続します。

```js Node
import { chromium } from "playwright";

const browser = await chromium.connectOverCDP(session.cdpUrl);
const context = browser.contexts()[0];
const page = context.pages()[0] || await context.newPage();

await page.goto("https://example.com");
console.log(await page.title());

await browser.close();
```


<div id="list-close-sessions">
  ### セッションの一覧表示とクローズ
</div>

```js Node
// アクティブなセッションを一覧表示
const { sessions } = await firecrawl.listBrowsers({ status: "active" });
for (const s of sessions) {
  console.log(s.id, s.status, s.createdAt);
}

// Close a session
await firecrawl.deleteBrowser(session.id);
```


<div id="error-handling">
  ## エラーハンドリング
</div>

この SDK は Firecrawl API から返されるエラーを処理し、適切な例外を送出します。リクエスト中にエラーが発生した場合は、わかりやすいエラーメッセージ付きの例外が送出されます。上記の例では、`try/catch` ブロックを使ってこれらのエラーを扱う方法を示しています。