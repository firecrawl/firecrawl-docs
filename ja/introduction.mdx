---
title: クイックスタート
description: "Firecrawl はウェブサイト全体を LLM 向けのMarkdownに変換できます"
og:title: "クイックスタート | Firecrawl"
og:description: "Firecrawl はウェブサイト全体を LLM 向けのMarkdownに変換できます"
---

import InstallationPython from "/snippets/ja/v2/installation/python.mdx";
import InstallationNode from "/snippets/ja/v2/installation/js.mdx";
import ScrapePython from "/snippets/v2/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v2/scrape/base/js.mdx";
import ScrapeCURL from "/snippets/v2/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v2/scrape/base/output.mdx";
import CrawlPython from "/snippets/ja/v2/crawl/base/python.mdx";
import CrawlNode from "/snippets/ja/v2/crawl/base/js.mdx";
import CrawlCURL from "/snippets/ja/v2/crawl/base/curl.mdx";
import CrawlAsyncOutput from "/snippets/v2/start-crawl/base/output.mdx";
import GetCrawlJobPython from "/snippets/ja/v2/crawl-status/short/python.mdx";
import GetCrawlJobNode from "/snippets/ja/v2/crawl-status/short/js.mdx";
import GetCrawlJobCURL from "/snippets/ja/v2/crawl-status/short/curl.mdx";
import GetCrawlJobOutputScraping from "/snippets/ja/v2/crawl-status/base/output-scraping.mdx";
import GetCrawlJobOutputCompleted from "/snippets/ja/v2/crawl-status/base/output-completed.mdx";
import ScrapeJsonCURL from "/snippets/v2/scrape/json/base/curl.mdx";
import ScrapeJsonPython from "/snippets/v2/scrape/json/base/python.mdx";
import ScrapeJsonNode from "/snippets/v2/scrape/json/base/js.mdx";
import ScrapeJsonOutput from "/snippets/v2/scrape/json/base/output.mdx";
import ScrapeJsonNoSchemaCURL from "/snippets/v2/scrape/json/no-schema/curl.mdx";
import ScrapeJsonNoSchemaPython from "/snippets/v2/scrape/json/no-schema/python.mdx";
import ScrapeJsonNoSchemaNode from "/snippets/v2/scrape/json/no-schema/js.mdx";
import ScrapeJsonNoSchemaOutput from "/snippets/v2/scrape/json/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/v2/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/v2/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/v2/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/v2/scrape/actions/output.mdx";
import SearchPython from "/snippets/v2/search/base/python.mdx";
import SearchNode from "/snippets/v2/search/base/js.mdx";
import SearchCURL from "/snippets/v2/search/base/curl.mdx";
import SearchResponse from "/snippets/v2/search/base/output.mdx";

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.png" alt="ヒーロー（ライト）" />

<div id="welcome-to-firecrawl">
  ## Firecrawlへようこそ
</div>

[Firecrawl](https://firecrawl.dev?ref=github) は、URLを受け取り、クロールしてクリーンなMarkdownに変換するAPIサービスです。アクセス可能なすべてのサブページをクロールし、それぞれにクリーンなMarkdownを提供します。サイトマップは不要です。

<div id="how-to-use-it">
  ## どう使えばいいですか？
</div>

ホスティング版では使いやすいAPIを提供しています。プレイグラウンドとドキュメントは[こちら](https://firecrawl.dev/playground)から参照できます。必要に応じてバックエンドをセルフホストすることも可能です。

まずは次のリソースをご確認ください:

* [x] **API**: [ドキュメント](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node)
* [x] **LLMフレームワーク**: [Langchain (Python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (JS)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [LlamaIndex](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **ローコードフレームワーク**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **コミュニティSDK**: [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust) (v1)
* [x] **その他**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] SDKやインテグレーションが必要ですか？Issueを作成してお知らせください。

**セルフホスト:** セルフホストする場合は[こちら](/ja/contributing/self-host)のガイドをご参照ください。

<div id="api-key">
  ### API Key
</div>

API を使用するには、[Firecrawl](https://firecrawl.dev) に登録して API キーを取得してください。

<div id="features">
  ### 機能
</div>

* [**Scrape**](#scraping): URLをスクレイピングし、LLM向けのフォーマット（Markdown、要約、[JSONモード](#json-mode)による構造化データ、スクリーンショット、HTML）でコンテンツを取得
* [**Crawl**](#crawling): ウェブページ内のすべてのURLをスクレイピングし、LLM向けのフォーマットでコンテンツを返す
* [**Map**](/ja/features/map): ウェブサイトを入力し、サイト内のすべてのURLを高速で取得
* [**Search**](/ja/features/search): ウェブを検索し、結果からコンテンツ全文を取得
* [**Extract**](/ja/features/extract): 単一ページ、複数ページ、またはサイト全体からAIで構造化データを抽出

<div id="powerful-capabilities">
  ### 強力な機能
</div>

* **LLM対応フォーマット**: Markdown、要約、構造化データ、スクリーンショット、HTML、リンク、メタデータ
* **難所もお任せ**: プロキシ、ボット対策、動的コンテンツ（JSレンダリング）、出力パース、オーケストレーション
* **超高速**: 数秒で結果を返却—スピードと高スループットのユースケース向けに設計。
* **カスタマイズ性**: タグの除外、カスタムヘッダーで認証壁の背後をクロール、最大クロール深度など
* **メディア解析**: PDF、DOCX、画像
* **信頼性重視**: 必要なデータを、どれだけ難しくても確実に取得
* **アクション**: 抽出前に click、scroll、input、wait などを実行

Firecrawlのすべての機能と使い方は、[ドキュメント](https://docs.firecrawl.dev/api-reference/v2-introduction)で確認できます

<div id="installing-firecrawl">
  ## Firecrawl のインストール
</div>

<CodeGroup>
  <InstallationPython />

  <InstallationNode />
</CodeGroup>

<div id="scraping">
  ## スクレイピング
</div>

単一のURLをスクレイプするには、`scrape` メソッドを使用します。URLを引数に取り、スクレイプしたデータをディクショナリとして返します。

<CodeGroup>
  <ScrapePython />

  <ScrapeNode />

  <ScrapeCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

SDKはデータオブジェクトを直接返します。cURLは以下のとおり、ペイロードをそのまま返します。

<ScrapeResponse />

<div id="crawling">
  ## クローリング
</div>

クローリング機能を使うと、指定したURLと、そのURLからアクセス可能なすべてのサブページからコンテンツを自動的に検出・抽出できます。SDKでは `crawl` メソッドを呼ぶだけでクローリングジョブを送信し、完了まで待機して、サイト全体の結果をまとめて返します。

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <CrawlPython />

  <CrawlNode />

  <CrawlCURL />
</CodeGroup>

API を直接利用する場合や、cURL、SDK の `start crawl` 関数を使う場合は、クロールのステータス確認に使用できる `ID` が返されます。

<CrawlAsyncOutput />

<div id="get-crawl-status">
  ### クロールのステータスを取得
</div>

クロールジョブの進行状況を確認し、結果を取得します。

<CodeGroup>
  <GetCrawlJobPython />

  <GetCrawlJobNode />

  <GetCrawlJobCURL />
</CodeGroup>

<div id="response">
  #### レスポンス
</div>

レスポンスはクロールのステータスによって異なります。未完了の場合や、10MBを超える大きなレスポンスの場合は、`next` URLパラメータが付与されます。次の10MBのデータを取得するには、このURLにリクエストしてください。`next` パラメータがない場合は、クロールデータの末尾であることを示します。

<CodeGroup>
  <GetCrawlJobOutputScraping />

  <GetCrawlJobOutputCompleted />
</CodeGroup>

<div id="json-mode">
  ## JSONモード
</div>

JSONモードを使うと、あらゆるURLから構造化データを簡単に抽出できます。pydanticのスキーマにも対応しているため、より手軽に利用できます。使い方は次のとおりです：

<CodeGroup>
  <ScrapeJsonPython />

  <ScrapeJsonNode />

  <ScrapeJsonCURL />
</CodeGroup>

出力：

<ScrapeJsonOutput />

<div id="search">
  ## Search
</div>

Firecrawl の検索APIを使うと、ウェブ検索と、必要に応じた検索結果のスクレイピングを1回の操作で実行できます。

* 出力フォーマット（markdown、HTML、links、screenshots）を選択
* 取得元のソース（web、news、images）を選択
* カスタマイズ可能なパラメータ（location など）でウェブを検索

詳細は [Search Endpoint API Reference](/ja/api-reference/endpoint/search) を参照してください。

<CodeGroup>
  <SearchPython />

  <SearchNode />

  <SearchCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

SDK はデータオブジェクトを直接返します。cURL は完全なペイロードを返します。

<SearchResponse />

<div id="extracting-without-schema">
  ### スキーマなしで抽出
</div>

エンドポイントに`prompt`を渡すだけで、スキーマを用いずに抽出できます。LLMがデータの構造を決定します。

<CodeGroup>
  <ScrapeJsonNoSchemaPython />

  <ScrapeJsonNoSchemaNode />

  <ScrapeJsonNoSchemaCURL />
</CodeGroup>

出力:

<ScrapeJsonNoSchemaOutput />

<div id="interacting-with-the-page-with-actions">
  ## アクションでページを操作する
</div>

Firecrawl では、コンテンツをスクレイピングする前に、ウェブページ上でさまざまなアクションを実行できます。これは、動的コンテンツの操作、ページ遷移、ユーザー操作が必要なコンテンツへのアクセスに特に有用です。

以下は、アクションを使って google.com に移動し、Firecrawl を検索し、最初の結果をクリックしてスクリーンショットを取得する例です。

ページの読み込みに十分な時間を確保するため、他のアクションの実行前後には、ほぼ常に `wait` アクションを使用することが重要です。

<div id="example">
  ### 例
</div>

<CodeGroup>
  <ScrapeActionsPython />

  <ScrapeActionsNode />

  <ScrapeActionsCURL />
</CodeGroup>

<div id="output">
  ### 出力
</div>

<CodeGroup>
  <ScrapeActionsOutput />
</CodeGroup>

<div id="open-source-vs-cloud">
  ## オープンソース vs クラウド
</div>

Firecrawl は [AGPL-3.0 ライセンス](https://github.com/mendableai/firecrawl/blob/main/LICENSE) の下で公開されているオープンソースです。

最良のプロダクトを提供するため、オープンソース版に加えてホスト型の Firecrawl も提供しています。クラウドソリューションにより、すべてのユーザーに対して継続的な機能改善と、高品質で持続可能なサービスを提供できます。

Firecrawl Cloud は [firecrawl.dev](https://firecrawl.dev) で利用でき、オープンソース版にはない多様な機能を備えています。

![Firecrawl Cloud とオープンソースの比較](./images/open-source-cloud.png)

<div id="contributing">
  ## コントリビューション
</div>

貢献を歓迎しています！プルリクエストを送信する前に、[貢献ガイド](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md)をお読みください。