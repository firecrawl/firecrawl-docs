---
title: "高度なスクレイピングガイド"
description: "高度なオプションで Firecrawl のスクレイピングを強化する方法を学びます。"
og:title: "高度なスクレイピングガイド | Firecrawl"
og:description: "高度なオプションで Firecrawl のスクレイピングを強化する方法を学びます。"
---

このガイドでは、Firecrawl の各エンドポイントと、用意されたすべてのパラメータを使いこなす方法を順を追って解説します。

<div id="basic-scraping-with-firecrawl">
  ## Firecrawl で行う基本的なスクレイピング
</div>

単一のページをスクレイピングしてクリーンなMarkdownコンテンツを取得するには、`/scrape` エンドポイントを使用します。

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

doc = firecrawl.scrape("https://firecrawl.dev")

print(doc.markdown)
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://firecrawl.dev');

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## PDFのスクレイピング
</div>

FirecrawlはPDFに対応しています。PDFを確実に解析したい場合は、`parsers` オプション（例: `parsers: ["pdf"]`）を使用してください。

<div id="scrape-options">
  ## スクレイピングのオプション
</div>

`/scrape` エンドポイントを使用する際は、以下のオプションでスクレイピングをカスタマイズできます。

<div id="formats-formats">
  ### フォーマット (`formats`)
</div>

- **型**: `array`
- **文字列**: `["markdown", "links", "html", "rawHtml", "summary", "images"]`
- **オブジェクト形式**:
  - JSON: `{ type: "json", prompt, schema }`
  - スクリーンショット: `{ type: "screenshot", fullPage?, quality?, viewport? }`
  - changeTracking（変更追跡）: `{ type: "changeTracking", modes?, prompt?, schema?, tag? }`（`markdown` が必要）
- **デフォルト**: `["markdown"]`

<div id="full-page-content-vs-main-content-onlymaincontent">
  ### ページ全体のコンテンツとメインコンテンツ（`onlyMainContent`）
</div>

- **タイプ**: `boolean`
- **説明**: 既定ではスクレイパーはメインコンテンツのみを返します。ページ全体のコンテンツを返すには `false` に設定してください。
- **デフォルト**: `true`

<div id="include-tags-includetags">
  ### 含めるタグ（`includeTags`）
</div>

- **Type**: `array`
- **Description**: スクレイプに含める HTML のタグ／クラス／ID。

<div id="exclude-tags-excludetags">
  ### 除外タグ（`excludeTags`）
</div>

- **型**: `array`
- **説明**: スクレイプ対象から除外する HTML のタグ・クラス・ID。

<div id="wait-for-page-readiness-waitfor">
  ### ページの準備完了を待つ（`waitFor`）
</div>

- **型**: `integer`
- **説明**: スクレイピング開始前に待機する時間（ミリ秒）。必要な場合のみ最小限の使用を推奨。
- **デフォルト**: `0`

<div id="freshness-and-cache-maxage">
  ### 鮮度とキャッシュ（`maxAge`）
</div>

- **タイプ**: `integer`（ミリ秒）
- **説明**: ページのキャッシュが `maxAge` 以内に更新されたものであれば、Firecrawl は即座にそれを返し、そうでなければ新規にスクレイプしてキャッシュを更新します。常に最新を取得するには `0` を設定します。
- **デフォルト**: `172800000`（2日）

<div id="request-timeout-timeout">
  ### リクエストのタイムアウト (`timeout`)
</div>

- **型**: `integer`
- **説明**: 中止までの最大時間（ミリ秒）。
- **デフォルト**: `30000`（30秒）

<div id="pdf-parsing-parsers">
  ### PDF 解析（`parsers`）
</div>

- **型**: `array`
- **説明**: 解析動作を制御します。PDF を解析するには、`parsers: ["pdf"]` を設定します。

<div id="actions-actions">
  ### アクション (`actions`)
</div>

/scrape エンドポイントを使用する場合、Firecrawl はスクレイピング前にウェブページ上でさまざまなアクションを実行できます。これは、動的コンテンツとの対話、ページ間の移動、ユーザー操作が必要なコンテンツへのアクセスに特に有用です。

- **型**: `array`
- **説明**: スクレイピング前に実行するブラウザ操作のシーケンス。
- **サポートされるアクション**:
    - `wait` `{ milliseconds }`
    - `click` `{ selector }`
    - `write` `{ selector, text }`
    - `press` `{ key }`
    - `scroll` `{ direction: "up" | "down" }`
    - `scrape` `{ selector }`（サブ要素をスクレイプ）
    - `executeJavascript` `{ script }`
    - `pdf`（一部のフローで PDF レンダリングを起動）

<CodeGroup>

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

doc = firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
})

print(doc.markdown)
```

```js Node
import { Firecrawl } from 'firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

const doc = await firecrawl.scrape('https://example.com', {
  actions: [
    { type: 'wait', milliseconds: 1000 },
    { type: 'click', selector: '#accept' },
    { type: 'scroll', direction: 'down' },
    { type: 'write', selector: '#q', text: 'firecrawl' },
    { type: 'press', key: 'Enter' }
  ],
  formats: ['markdown']
});

console.log(doc.markdown);
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://example.com",
    "actions": [
      { "type": "wait", "milliseconds": 1000 },
      { "type": "click", "selector": "#accept" },
      { "type": "scroll", "direction": "down" },
      { "type": "write", "selector": "#q", "text": "firecrawl" },
      { "type": "press", "key": "Enter" }
    ],
    "formats": ["markdown"]
  }'
```

</CodeGroup>

<div id="example-usage">
  ### 使い方の例
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": [
        "markdown",
        "links",
        "html",
        "rawHtml",
        { "type": "screenshot", "fullPage": true, "quality": 80 }
      ],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsers": ["pdf"]
    }'
```

この例では、スクレイパーは次を行います:

* ページ全体のコンテンツをMarkdownで返します。
* レスポンスにMarkdown、raw HTML、HTML、リンク、スクリーンショットを含めます。
* HTMLタグの `<h1>`、`<p>`、`<a>` と、クラス `.main-content` を持つ要素のみを含め、IDが `#ad` と `#footer` の要素は除外します。
* ページの読み込みのため、スクレイピング前に1000ミリ秒（1秒）待機します。
* スクレイプリクエストの最大実行時間を15000ミリ秒（15秒）に設定します。
* `parsers: ["pdf"]` を指定してPDFを明示的に解析します。

APIリファレンスはこちら: [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


<div id="json-extraction-via-formats">
  ## フォーマットによるJSON抽出
</div>

1回の処理で構造化データを抽出するには、`formats` 内の JSON フォーマットオブジェクトを使用します。

```bash
curl -X POST https://api.firecrawl.dev/v2/scrape \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://firecrawl.dev",
    "formats": [{
      "type": "json",
      "prompt": "製品の機能を抽出せよ",
      "schema": {"type": "object", "properties": {"features": {"type": "object"}}, "required": ["features"]}
    }]
  }'
```


<div id="extract-endpoint">
  ## Extract エンドポイント
</div>

ステータスのポーリングを伴う非同期抽出が必要な場合は、専用の抽出ジョブ API を使用します。

<CodeGroup>

```js Node
import Firecrawl from '@mendable/firecrawl-js';

const firecrawl = new Firecrawl({ apiKey: 'fc-YOUR-API-KEY' });

// 抽出ジョブを開始
const started = await firecrawl.startExtract({
  urls: ['https://docs.firecrawl.dev'],
  prompt: 'Extract title',
  schema: { type: 'object', properties: { title: { type: 'string' } }, required: ['title'] }
});

// ステータスをポーリング
const status = await firecrawl.getExtractStatus(started.id);
console.log(status.status, status.data);
```

```python Python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key='fc-YOUR-API-KEY')

started = firecrawl.start_extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract title",
    schema={"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
)
status = firecrawl.get_extract_status(started.id)
print(status.get("status"), status.get("data"))
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/extract \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "urls": ["https://docs.firecrawl.dev"],
    "prompt": "Extract title",
    "schema": {"type": "object", "properties": {"title": {"type": "string"}}, "required": ["title"]}
  }'
```
</CodeGroup>

<div id="crawling-multiple-pages">
  ## 複数ページのクロール
</div>

複数のページをクロールするには、`/v2/crawl` エンドポイントを使用します。

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-あなたのAPIキー' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

IDを返します

```json
{ "id": "1234-5678-9101" }
```


<div id="check-crawl-job">
  ### クローラー ジョブの確認
</div>

クロールジョブのステータスを確認し、結果を取得します。

```bash cURL
curl -X GET https://api.firecrawl.dev/v2/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY'
```


<div id="paginationnext-url">
  #### ページネーション／次のURL
</div>

コンテンツが10MBを超える場合、またはクロールジョブがまだ実行中の場合、レスポンスに `next` パラメータ（次の結果ページへのURL）が含まれることがあります。

<div id="crawl-prompt-and-params-preview">
  ### クロール用プロンプトとパラメータのプレビュー
</div>

自然言語の `prompt` を指定すると、Firecrawl がクロール設定を自動で推定します。まずはプレビューしてください：

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl/params-preview \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fc-YOUR-API-KEY' \
  -d '{
    "url": "https://docs.firecrawl.dev",
    "prompt": "ドキュメントとブログを抽出する"
  }'
```


<div id="crawler-options">
  ### クローラーのオプション
</div>

`/v2/crawl` エンドポイントを使用する際は、以下のオプションでクロールの挙動をカスタマイズできます:

<div id="includepaths">
  #### includePaths
</div>

- **型**: `array`
- **説明**: インクルード対象とする正規表現パターン。
- **例**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### excludePaths
</div>

- **型**: `array`
- **説明**: 除外対象を指定する正規表現パターン。
- **例**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdiscoverydepth">
  #### maxDiscoveryDepth
</div>

- **Type**: `integer`
- **Description**: 新規URL発見のための最大探索深度。

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: クロールするページ数の上限。
- **Default**: `10000`

<div id="crawlentiredomain">
  #### crawlEntireDomain
</div>

- **型**: `boolean`
- **説明**: 兄弟ページや親ページにも探索を拡げ、ドメイン全体をカバーします。
- **デフォルト**: `false`

<div id="allowexternallinks">
  #### allowExternalLinks
</div>

- **Type**: `boolean`
- **Description**: 外部ドメインへのリンクを追跡します。
- **Default**: `false`

<div id="allowsubdomains">
  #### allowSubdomains
</div>

- **型**: `boolean`
- **説明**: メインドメインのサブドメインもクロールします。
- **既定値**: `false`

<div id="delay">
  #### delay
</div>

- **Type**: `number`
- **Description**: スクレイピング間の遅延（秒）。
- **Default**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

- **Type**: `object`
- **Description**: スクレイパーのオプション（上記のフォーマット参照）。
- **Example**: `{ "formats": ["markdown", "links", {"type": "screenshot", "fullPage": true}], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **Defaults**: `formats: ["markdown"]`、既定でキャッシュ有効（maxAge 約2日）

<div id="example-usage">
  ### 使い方の例
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDiscoveryDepth": 2,
      "limit": 1000
    }'
```


<div id="mapping-website-links">
  ## ウェブサイトのリンクのマッピング
</div>

`/v2/map` エンドポイントは、指定したウェブサイトに関連するURLを特定します。

<div id="usage">
  ### 使い方
</div>

```bash cURL
curl -X POST https://api.firecrawl.dev/v2/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR-API-KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```


<div id="map-options">
  ### マップオプション
</div>

<div id="search">
  #### search
</div>

- **Type**: `string`
- **Description**: 指定したテキストを含むリンクをフィルタします。

<div id="limit">
  #### limit
</div>

- **Type**: `integer`
- **Description**: 返すリンクの最大数
- **Default**: `100`

<div id="sitemap">
  #### sitemap
</div>

- **Type**: `"only" | "include" | "skip"`
- **Description**: マッピング時のsitemapの利用方法を制御します。
- **Default**: `"include"`

<div id="includesubdomains">
  #### includeSubdomains
</div>

- **Type**: `boolean`
- **Description**: ウェブサイトのサブドメインを含めるかどうか。
- **Default**: `true`

該当するAPIリファレンスはこちら: [Map Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/map)

お読みいただきありがとうございました。