---
title: "Agent"
description: "Web 上のあらゆる場所に存在するデータを収集します。欲しい内容を伝えれば、あとは /agent がすべて処理します。"
og:title: "Agent | Firecrawl"
og:description: "Web 上のあらゆる場所に存在するデータを収集します。欲しい内容を伝えれば、あとは /agent がすべて処理します。"
icon: "magic"
sidebarTitle: "Agent"
---

import AgentPython from "/snippets/ja/v2/agent/base/python.mdx";
import AgentJS from "/snippets/ja/v2/agent/base/js.mdx";
import AgentCURL from "/snippets/ja/v2/agent/base/curl.mdx";
import AgentOutput from "/snippets/ja/v2/agent/base/output.mdx";
import AgentWithSchemaPython from "/snippets/ja/v2/agent/with-schema/python.mdx";
import AgentWithSchemaJS from "/snippets/ja/v2/agent/with-schema/js.mdx";
import AgentWithSchemaCURL from "/snippets/ja/v2/agent/with-schema/curl.mdx";
import AgentWithSchemaOutput from "/snippets/ja/v2/agent/with-schema/output.mdx";
import AgentWithURLsPython from "/snippets/ja/v2/agent/with-urls/python.mdx";
import AgentWithURLsJS from "/snippets/ja/v2/agent/with-urls/js.mdx";
import AgentWithURLsCURL from "/snippets/ja/v2/agent/with-urls/curl.mdx";
import AgentStatusPython from "/snippets/ja/v2/agent/status/python.mdx";
import AgentStatusJS from "/snippets/ja/v2/agent/status/js.mdx";
import AgentStatusCURL from "/snippets/ja/v2/agent/status/curl.mdx";
import AgentStatusPending from "/snippets/ja/v2/agent/status/pending.mdx";
import AgentStatusCompleted from "/snippets/ja/v2/agent/status/completed.mdx";

Firecrawl の `/agent` は、検索・ナビゲーション・データ収集を自動で行い、非常に複雑な Web サイトからでも、通常はアクセスしづらい場所のデータやインターネット上のあらゆる場所にあるデータを見つけ出す魔法のような API です。人間なら何時間もかかる作業を数分でこなし、従来の Web スクレイピングを過去のものにします。

**欲しいデータを文章で指定するだけで、あとはすべて `/agent` が処理します。**

<Info>
  **Research Preview（研究プレビュー）**: Agent はアーリーアクセス段階です。動作が荒削りな部分がありますが、今後大きく改善されていきます。[フィードバックを共有する →](mailto:product@firecrawl.com)
</Info>

Agent は `/extract` の優れた点をすべて引き継ぎつつ、さらに強化しています:

* **URL 不要**: 必要な内容を `prompt` パラメータで記述するだけでよく、URL は任意です。
* **ディープ Web 検索**: サイト内を自律的に検索・巡回し、必要なデータを深部まで探索
* **高い信頼性と正確性**: 幅広い種類のクエリやユースケースで安定して動作
* **高速**: 複数ソースを並列処理して結果を素早く取得
* **低コスト**: Agent は `/extract` よりもコスト効率に優れています

<div id="using-agent">
  ## `/agent` の使用
</div>

必須パラメータは `prompt` のみです。どのようなデータを抽出したいかを記述してください。構造化された出力を得るには、JSON スキーマを指定してください。各 SDK は、型安全なスキーマ定義のために Pydantic（Python）と Zod（Node）をサポートしています：

<CodeGroup>
  <AgentWithSchemaPython />

  <AgentWithSchemaJS />

  <AgentWithSchemaCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

<AgentWithSchemaOutput />

<div id="providing-urls-optional">
  ## URL を指定する場合（任意）
</div>

エージェントの対象を特定のページに絞り込むために、任意で URL を指定できます。

<CodeGroup>
  <AgentWithURLsPython />

  <AgentWithURLsJS />

  <AgentWithURLsCURL />
</CodeGroup>

<div id="job-status-and-completion">
  ## ジョブのステータスと完了
</div>

Agent ジョブは非同期で実行されます。ジョブの実行を開始すると、ステータス確認に使える Job ID が返されます：

* **デフォルトの方法**: `agent()` が完了まで待機し、最終結果を返します
* **開始してポーリング**: `start_agent`（Python）または `startAgent`（Node）で即座に Job ID を取得し、その後 `get_agent_status` / `getAgentStatus` でポーリングします

<Note>ジョブ結果は完了後 24 時間利用可能です。</Note>

<CodeGroup>
  <AgentStatusPython />

  <AgentStatusJS />

  <AgentStatusCURL />
</CodeGroup>

<div id="possible-states">
  ### 考えられるステータス
</div>

| ステータス | 説明 |
|--------|-------------|
| `processing` | エージェントがリクエストを処理中です |
| `completed` | 抽出が正常に完了しました |
| `failed` | 抽出中にエラーが発生しました |

<div id="pending-example">
  #### 保留状態の例
</div>

<AgentStatusPending />

<div id="completed-example">
  #### 完成例
</div>

<AgentStatusCompleted />

<div id="parameters">
  ## パラメータ
</div>

| パラメータ | 型 | 必須 | 説明 |
|-----------|------|----------|-------------|
| `prompt` | string | **Yes** | 抽出したいデータを自然言語で記述した文字列（最大 10,000 文字） |
| `urls` | array | No | 抽出対象を絞り込むためのオプションの URL リスト |
| `schema` | object | No | 構造化出力のためのオプションの JSON スキーマ |

<div id="agent-vs-extract-whats-improved">
  ## Agent と Extract：何が改善されたか
</div>

| 項目 | Agent（新） | Extract |
|------|-------------|---------|
| URL の指定 | 不要 | 必要 |
| 速度 | 高速 | 標準 |
| コスト | 低コスト | 標準 |
| 信頼性 | 高い | 標準 |
| クエリの柔軟性 | 高い | 中程度 |

<div id="example-use-cases">
  ## 利用例
</div>

* **リサーチ**: 「有望なAIスタートアップ上位5社とその資金調達額を調べる」
* **競合分析**: 「SlackとMicrosoft Teamsの料金プランを比較する」
* **データ収集**: 「企業のWebサイトから連絡先情報を抽出する」
* **コンテンツ要約**: 「Webスクレイピングに関する最新のブログ記事を要約する」

<div id="api-reference">
  ## APIリファレンス
</div>

詳しくは、[Agent API Reference](/ja/api-reference/endpoint/agent) を参照してください。

フィードバックやサポートが必要な場合は、[help@firecrawl.com](mailto:help@firecrawl.com) までメールでご連絡ください。

<div id="pricing">
  ## 料金
</div>

Firecrawl Agent は、データ抽出リクエストの複雑さに応じてスケールする **従量課金制** を採用しています。実際に Agent が行った処理内容に基づいて支払う仕組みのため、単純なデータポイントの抽出でも、複数のソースからの複雑な構造化情報の抽出でも、公平な料金になります。

<div id="how-agent-pricing-works">
  ### Agentの料金の仕組み
</div>

Research Preview期間中、Agentの料金は**動的でトークンベース**です：

* **シンプルな抽出**（1ページからの連絡先情報など）は、通常必要なクレジット数が少なく、コストも低くなります
* **複雑なリサーチタスク**（複数ドメインにわたる競合分析など）は、より多くのクレジットを使用しますが、必要な総工数を反映します
* **透明な利用状況**により、各リクエストで消費されたクレジット数を正確に確認できます
* **クレジット変換**により、Agentのトークン使用量が自動的にクレジットへ変換され、請求処理が容易になります

<Info>
  トークン使用量は、プロンプトの複雑さ、処理されるデータ量、および要求された出力構造に応じて変動します。
</Info>

<div id="getting-started">
  ### はじめに
</div>

**すべてのユーザー**は、Agent の機能を無料で試せるように、**1 日あたり 5 回の無料実行**が付与されます。

それ以上の利用分は、トークン消費量に応じて課金され、その分がクレジットに換算されます。各クレジットは 15 クレジットとして扱われ、他の Firecrawl エンドポイントと同じレートです。

<div id="managing-costs">
  ### コスト管理
</div>

Agent のコストをコントロールしましょう:

* **無料実行から始める**: 毎日 5 回の無料リクエストを使って料金イメージをつかむ
* **`maxCredits` パラメータを設定する**: 消費するクレジット数の上限を設定してコストを制限する
* **プロンプトを最適化する**: 具体的なプロンプトほど必要なクレジットが少なくなることが多い
* **利用状況を確認する**: ダッシュボードで利用量を追跡する
* **期待値を調整する**: 複数ドメインにまたがる複雑なリサーチは、単純な単一ページの抽出より多くのクレジットを使用する

[firecrawl.dev/app/agent](/ja/app/agent) で今すぐ Agent を試して、あなたの具体的なユースケースでトークン使用量がどのようにスケールするかを確認してください。

<Note>
  料金は Research Preview から一般提供へ移行する際に変更される可能性があります。現在のユーザーには、料金変更がある場合は事前に通知されます。
</Note>