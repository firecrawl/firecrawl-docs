---
title: 'バッチスクレイピング'
description: '複数のURLをバッチでスクレイピングする'
og:title: 'バッチスクレイピング | Firecrawl'
og:description: '複数のURLをバッチでスクレイピングする'
---

import BatchScrapePython from '/snippets/ja/v2/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/ja/v2/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/ja/v2/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/ja/v2/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/ja/v2/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/ja/v2/batch-scrape/json/python.mdx';
import BatchScrapeExtractNode from '/snippets/ja/v2/batch-scrape/json/js.mdx';
import BatchScrapeExtractCURL from '/snippets/ja/v2/batch-scrape/json/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/ja/v2/batch-scrape/json/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/ja/v2/batch-scrape/json/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/ja/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## 複数のURLを一括スクレイピング
</div>

複数のURLを同時に一括スクレイピングできます。開始URLと任意のパラメータを引数に取ります。params 引数では、出力フォーマットなど、一括スクレイピングジョブの追加オプションを指定できます。

<div id="how-it-works">
  ### 仕組み
</div>

`/crawl` エンドポイントの動作とほぼ同じです。バッチを開始して完了まで待つことも、開始して完了処理を自分で行うこともできます。

* `batchScrape`（JS）/ `batch_scrape`（Python）：バッチジョブを開始し、完了まで待って結果を返します。
* `startBatchScrape`（JS）/ `start_batch_scrape`（Python）：バッチジョブを開始し、ポーリングやウェブフックに使えるジョブIDを返します。

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

`batchScrape`/`batch_scrape` を呼び出すと、バッチ完了時に完全な結果が返されます。

<BatchScrapeOutput />

`startBatchScrape`/`start_batch_scrape` を呼び出すと、`getBatchScrapeStatus`/`get_batch_scrape_status`、API エンドポイント `/batch/scrape/{id}`、または Webhook を使って追跡できるジョブ ID が返されます。ジョブの結果は、完了後 24 時間まで API 経由で取得できます。この期間を過ぎても、[activity logs](https://www.firecrawl.dev/app/logs) からバッチスクレイプの履歴と結果を確認できます。

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-structured-extraction">
  ## 構造化抽出を伴うバッチスクレイプ
</div>

バッチスクレイプのエンドポイントを使って、ページから構造化データを抽出することもできます。これは、複数のURLから同一の構造化データを取得したい場合に便利です。

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### レスポンス
</div>

`batchScrape`/`batch_scrape` は完全な結果を返します：

<BatchScrapeExtractOutput />

`startBatchScrape`/`start_batch_scrape` はジョブ ID を返します：

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Webhooks を使ったバッチスクレイプ
</div>

バッチ内の各 URL がスクレイプされるたびにリアルタイムで通知を受け取れるよう、webhook を設定できます。これにより、バッチ全体の完了を待たずに結果を即時に処理できます。

<BatchScrapeWebhookCURL />

<div id="quick-reference">
  ### クイックリファレンス
</div>

**イベントタイプ:**

* `batch_scrape.started` - バッチスクレイプが開始されたとき
* `batch_scrape.page` - 各URLのスクレイプに成功したとき
* `batch_scrape.completed` - すべてのURLの処理が完了したとき
* `batch_scrape.failed` - バッチスクレイプでエラーが発生した場合

**基本ペイロード:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // 'page'イベントのページデータ
  "metadata": {}, // Your custom metadata
  "error": null
}
```

<div id="security-verifying-webhook-signatures">
  ### セキュリティ: Webhook シグネチャの検証
</div>

Firecrawl から送信されるすべての webhook リクエストには、HMAC-SHA256 シグネチャを含む `X-Firecrawl-Signature` ヘッダーが含まれます。Webhook が正当なものであり、改ざんされていないことを確認するために、**必ずこのシグネチャを検証してください**。

**仕組み:**

1. アカウント設定の [Advanced タブ](https://www.firecrawl.dev/app/settings?tab=advanced) から webhook secret を取得する
2. `X-Firecrawl-Signature` ヘッダーからシグネチャを取り出す
3. secret を使って、生のリクエストボディに対して HMAC-SHA256 を計算する
4. タイミング攻撃耐性のある（タイミングセーフな）関数を用いて、計算結果とシグネチャヘッダーを比較する

<Warning>
  シグネチャを事前に検証せずに webhook を処理しないでください。`X-Firecrawl-Signature` ヘッダーには、`sha256=abc123def456...` という形式でシグネチャが含まれています。
</Warning>

JavaScript と Python による実装の完全な例については、[Webhook セキュリティのドキュメント](/ja/webhooks/security) を参照してください。

<div id="full-documentation">
  ### 詳細なドキュメント
</div>

イベントペイロードの詳細、高度な設定、トラブルシューティングなどを含む webhook の包括的なドキュメントは、[Webhooks ドキュメント](/ja/webhooks/overview)を参照してください。