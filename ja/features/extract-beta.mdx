---
title: 'データ抽出'
description: 'LLM を用いてページから構造化データを抽出する'
og:title: "データ抽出 | Firecrawl"
og:description: "LLM を用いてページから構造化データを抽出する"
---

import ExtractCURL from "/snippets/ja/v1/extract/base/curl.mdx";
import ExtractPython from "/snippets/ja/v1/extract/base/python.mdx";
import ExtractNode from "/snippets/ja/v1/extract/base/js.mdx";
import ExtractOutput from "/snippets/ja/v1/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/ja/v1/extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/ja/v1/extract/no-schema/output.mdx";
import CheckExtractJobCURL from "/snippets/ja/v1/extract/status/curl.mdx";
import ExtractStatusPending from "/snippets/ja/v1/extract/status/pending.mdx";
import ExtractStatusAsync from "/snippets/ja/v1/extract/async-response/async.mdx";
import ExtractStatusDone from "/snippets/ja/v1/extract/status/completed.mdx";

<div id="introducing-extract-beta">
  ## /extract の紹介（ベータ）
</div>

<Warning>
  [新しい /extract オープンベータのドキュメントはこちら 🔥](/ja/features/extract)
</Warning>

Large Language Models（LLM）を用いて、単一または複数のURL、さらにはサイト全体から構造化データを抽出できます。新しい `/extract` エンドポイントでは次のことが可能です:

* ウェブサイト全体から構造化データを一括抽出
* ウェブサイト由来の構造化データを必要とするデータエンリッチメントアプリを接続・構築
* 複数サイトからのクリーンなデータを必要とするAIアプリを開発

<div id="considerations">
  ## 考慮事項
</div>

`/extract` エンドポイントは、カスタマイズ可能なスキーマにより柔軟にデータを抽出できます。プロンプトの調整によって結果の精度を高められます。現在ベータ版のため、フィードバックをお待ちしています。

<div id="extracting-data">
  ## データ抽出
</div>

<div id="extract-endpoint">
  ### /extract エンドポイント
</div>

ウェブサイト全体から構造化データを抽出するために使用します。

URL を指定する際に、単一ページではなくサイト内のパス全体から情報を抽出したい場合は、URL に `/*` を付与できます。

たとえば、`https://firecrawl.dev/*` は firecrawl.dev ドメイン上のすべてのページからのデータ抽出を試みます。`/*` はまだテスト中の機能のため、問題があれば help@firecrawl.com までメールでご連絡ください。

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <ExtractPython />

  <ExtractNode />

  <ExtractCURL />
</CodeGroup>

パラメータの詳細は、[APIリファレンス](https://docs.firecrawl.dev/api-reference/endpoint/extract)をご覧ください。

<div id="response-sdks">
  ### レスポンス（SDK）
</div>

<ExtractOutput />

<div id="response-async-or-not-using-sdks">
  ### レスポンス（非同期またはSDKを使わない場合）
</div>

<ExtractStatusAsync />

<div id="checking-extract-status">
  ### 抽出ステータスの確認
</div>

`/extract/ID` エンドポイントを使って、抽出ジョブのステータスを確認できます。

<Note>このエンドポイントは、進行中の抽出ジョブ、または直近24時間以内に完了した抽出ジョブにのみ利用できます。</Note>

<CodeGroup>
  <CheckExtractJobCURL />
</CodeGroup>

<div id="pending-response">
  #### 保留中の応答
</div>

抽出ジョブは次のいずれかの状態になります：

* `completed`: 抽出ジョブは正常に完了しました。
* `processing`: 抽出ジョブは処理中です。
* `failed`: 抽出ジョブでエラーが発生し、完了しませんでした。
* `cancelled`: 抽出ジョブはユーザーによってキャンセルされました。

<ExtractStatusPending />

<div id="completed-response">
  #### 完了した応答
</div>

<ExtractStatusDone />

<div id="extracting-without-schema">
  ### スキーマなしでの抽出
</div>

エンドポイントに `prompt` を渡すだけで、スキーマを指定せずに抽出できます。LLM がデータ構造を自動で決定します。

<CodeGroup>
  <ExtractNoSchemaCURL />
</CodeGroup>

<div id="improving-results-with-web-search-external-links">
  ### ウェブ検索と外部リンクで結果を向上させる
</div>

抽出結果をさらに良くしたい場合は、エンドポイントに `enableWebSearch` パラメータを渡せます。これにより、指定したURLの範囲外にある外部リンクからもデータを探索できるようになります。

<div id="billing">
  ### 請求
</div>

`/extract` はベータ版の間、最終的なレスポンスの生成に使用されたスクレイプ済みの各URLにつき5クレジットを課金します。これは不正利用防止のためで、将来的に変更される可能性があります。