---
title: "スクレイピング"
description: "あらゆるURLをクリーンなデータに変換"
og:title: "スクレイピング | Firecrawl"
og:description: "あらゆるURLをクリーンなデータに変換"
---

import InstallationPython from "/snippets/ja/v2/installation/python.mdx";
import InstallationNode from "/snippets/ja/v2/installation/js.mdx";
import InstallationCLI from "/snippets/ja/v2/installation/cli.mdx";
import ScrapePython from "/snippets/ja/v2/scrape/base/python.mdx";
import ScrapeNode from "/snippets/ja/v2/scrape/base/js.mdx";
import ScrapeCURL from "/snippets/ja/v2/scrape/base/curl.mdx";
import ScrapeCLI from "/snippets/ja/v2/scrape/base/cli.mdx";
import ScrapeResponse from "/snippets/ja/v2/scrape/base/output.mdx";
import ExtractCURL from "/snippets/ja/v2/scrape/json/base/curl.mdx";
import ExtractPython from "/snippets/ja/v2/scrape/json/base/python.mdx";
import ExtractNode from "/snippets/ja/v2/scrape/json/base/js.mdx";
import ExtractOutput from "/snippets/ja/v2/scrape/json/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/ja/v2/scrape/json/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/ja/v2/scrape/json/no-schema/python.mdx";
import ExtractNoSchemaNode from "/snippets/ja/v2/scrape/json/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/ja/v2/scrape/json/no-schema/output.mdx";
import ScrapeActionsPython from "/snippets/ja/v2/scrape/actions/python.mdx";
import ScrapeActionsNode from "/snippets/ja/v2/scrape/actions/js.mdx";
import ScrapeActionsCURL from "/snippets/ja/v2/scrape/actions/curl.mdx";
import ScrapeActionsOutput from "/snippets/ja/v2/scrape/actions/output.mdx";
import BatchScrapePython from "/snippets/ja/v2/batch-scrape/short/python.mdx";
import BatchScrapeNode from "/snippets/ja/v2/batch-scrape/short/js.mdx";
import BatchScrapeCURL from "/snippets/ja/v2/batch-scrape/short/curl.mdx";
import BatchScrapeOutput from "/snippets/ja/v2/batch-scrape/base/output.mdx";
import BatchScrapeAsyncOutput from "/snippets/ja/v2/batch-scrape/base/async-output.mdx";
import ScrapeLocationPython from "/snippets/ja/v2/scrape/location/python.mdx";
import ScrapeLocationNode from "/snippets/ja/v2/scrape/location/js.mdx";
import ScrapeLocationCURL from "/snippets/ja/v2/scrape/location/curl.mdx";
import ScrapeBrandingPython from "/snippets/ja/v2/scrape/branding/base/python.mdx";
import ScrapeBrandingNode from "/snippets/ja/v2/scrape/branding/base/js.mdx";
import ScrapeBrandingCURL from "/snippets/ja/v2/scrape/branding/base/curl.mdx";
import ScrapeBrandingOutput from "/snippets/ja/v2/scrape/branding/base/output.mdx";
import ScrapeBrandingCombinedPython from "/snippets/ja/v2/scrape/branding/combined/python.mdx";
import ScrapeBrandingCombinedNode from "/snippets/ja/v2/scrape/branding/combined/js.mdx";
import ScrapeBrandingCombinedCURL from "/snippets/ja/v2/scrape/branding/combined/curl.mdx";

Firecrawl はウェブページをMarkdownに変換し、LLMアプリケーションに最適です。

* 複雑な処理を代行：プロキシ、キャッシュ、レート制限、JSでブロックされたコンテンツ
* 動的コンテンツに対応：動的サイト、JSレンダリングサイト、PDF、画像
* クリーンなMarkdown、構造化データ、スクリーンショット、またはHTMLを出力

詳細は、[Scrape Endpoint API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape)を参照してください。

<div id="scraping-a-url-with-firecrawl">
  ## FirecrawlでURLをスクレイピングする
</div>

<div id="scrape-endpoint">
  ### /scrape エンドポイント
</div>

URL をスクレイピングして、その内容を取得するために使用します。

<div id="installation">
  ### インストール
</div>

<CodeGroup>
  <InstallationPython />

  <InstallationNode />

  <InstallationCLI />
</CodeGroup>

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <ScrapePython />

  <ScrapeNode />

  <ScrapeCURL />

  <ScrapeCLI />
</CodeGroup>

パラメータの詳細は、[APIリファレンス](https://docs.firecrawl.dev/api-reference/endpoint/scrape)を参照してください。

### レスポンス

SDK はデータオブジェクトを直接返します。cURL は以下のとおり、ペイロードをそのまま返します。

<ScrapeResponse />

<div id="scrape-formats">
  ## スクレイプのフォーマット
</div>

出力のフォーマットを選択できます。複数の出力フォーマットを指定することも可能です。サポートされているフォーマットは次のとおりです:

* Markdown (`markdown`)
* Summary (`summary`)
* HTML (`html`)
* Raw HTML (`rawHtml`)（変更なし）
* Screenshot (`screenshot`、`fullPage`、`quality`、`viewport` などのオプションあり）
* Links (`links`)
* JSON (`json`) - 構造化された出力
* Images (`images`) - ページ内のすべての画像URLを抽出
* Branding (`branding`) - ブランドアイデンティティとデザインシステムを抽出

出力のキーは、選択したフォーマットに対応します。

<div id="extract-structured-data">
  ## 構造化データの抽出
</div>

<div id="scrape-with-json-endpoint">
  ### /scrape（json あり）エンドポイント
</div>

スクレイピングしたページから構造化データを抽出するために使用します。

<CodeGroup>
  <ExtractPython />

  <ExtractNode />

  <ExtractCURL />
</CodeGroup>

出力:

<ExtractOutput />

<div id="extracting-without-schema">
  ### スキーマなしでの抽出
</div>

エンドポイントに `prompt` を渡すだけで、スキーマなしで抽出できます。LLM がデータ構造を決定します。

<CodeGroup>
  <ExtractNoSchemaPython />

  <ExtractNoSchemaNode />

  <ExtractNoSchemaCURL />
</CodeGroup>

出力:

<ExtractNoSchemaOutput />

<div id="json-format-options">
  ### JSON フォーマットのオプション
</div>

`json` フォーマットを使用する場合は、`formats` 内に以下のパラメータを含むオブジェクトを渡します:

* `schema`: 構造化出力のための JSON Schema。
* `prompt`: スキーマがある場合や、軽い指示で十分な場合に抽出を補助する任意のプロンプト。

<div id="extract-brand-identity">
  ## ブランドアイデンティティの抽出
</div>

<div id="scrape-with-branding-endpoint">
  ### /scrape（ブランディング付き）エンドポイント
</div>

ブランディングフォーマットは、色、フォント、タイポグラフィ、余白・間隔、UIコンポーネントなど、ウェブページからブランドアイデンティティに関する包括的な情報を抽出します。デザインシステムの分析やブランド監視、ウェブサイトのビジュアルアイデンティティを把握する必要があるツールの構築に有用です。

<CodeGroup>
  <ScrapeBrandingPython />

  <ScrapeBrandingNode />

  <ScrapeBrandingCURL />
</CodeGroup>

### レスポンス

ブランディングフォーマットは、以下の構造を持つ包括的な `BrandingProfile` オブジェクトを返します。

<ScrapeBrandingOutput />

<div id="branding-profile-structure">
  ### ブランディングプロファイルの構造
</div>

`branding` オブジェクトには次のプロパティが含まれます:

* `colorScheme`: 検出された配色（`"light"` または `"dark"`）
* `logo`: メインロゴの URL
* `colors`: ブランドカラーを含むオブジェクト:
  * `primary`, `secondary`, `accent`: 主要なブランドカラー
  * `background`, `textPrimary`, `textSecondary`: UI カラー
  * `link`, `success`, `warning`, `error`: セマンティックカラー
* `fonts`: ページで使用されているフォントファミリーの配列
* `typography`: タイポグラフィの詳細情報:
  * `fontFamilies`: 基本、見出し、コード用のフォントファミリー
  * `fontSizes`: 見出しと本文のサイズ定義
  * `fontWeights`: ウェイトの定義（light、regular、medium、bold）
  * `lineHeights`: テキスト種別ごとの行の高さ
* `spacing`: 余白とレイアウト情報:
  * `baseUnit`: 基準となるスペーシング単位（px）
  * `borderRadius`: 既定の角丸半径
  * `padding`, `margins`: スペーシング値
* `components`: UI コンポーネントのスタイル:
  * `buttonPrimary`, `buttonSecondary`: ボタンスタイル
  * `input`: 入力フィールドのスタイル
* `icons`: アイコンのスタイル情報
* `images`: ブランド画像（ロゴ、favicon、og:image）
* `animations`: アニメーションおよびトランジション設定
* `layout`: レイアウト構成（グリッド、ヘッダー／フッターの高さ）
* `personality`: ブランドの特性（トーン、エネルギー、対象ユーザー）

<div id="combining-with-other-formats">
  ### 他のフォーマットとの併用
</div>

ブランディング用フォーマットを他のフォーマットと組み合わせることで、ページの包括的なデータを取得できます:

<CodeGroup>
  <ScrapeBrandingCombinedPython />

  <ScrapeBrandingCombinedNode />

  <ScrapeBrandingCombinedCURL />
</CodeGroup>

<div id="interacting-with-the-page-with-actions">
  ## アクションを使ってページとやり取りする
</div>

Firecrawl を使うと、スクレイピングの前に Web ページ上でさまざまなアクションを実行できます。これは、動的コンテンツとのインタラクション、ページ遷移、ユーザー操作が必要なコンテンツへのアクセスに特に有効です。

以下は、アクションを使って google.com に移動し、Firecrawl を検索し、最初の結果をクリックしてスクリーンショットを取得する例です。

ページの読み込み時間を確保するため、他のアクションの前後には基本的に `wait` アクションを使用することが重要です。

<div id="example">
  ### 例
</div>

<CodeGroup>
  <ScrapeActionsPython />

  <ScrapeActionsNode />

  <ScrapeActionsCURL />
</CodeGroup>

<div id="output">
  ### 出力
</div>

<CodeGroup>
  <ScrapeActionsOutput />
</CodeGroup>

アクションのパラメーターの詳細は、[APIリファレンス](https://docs.firecrawl.dev/api-reference/endpoint/scrape)を参照してください。

<div id="location-and-language">
  ## ロケーションと言語
</div>

ターゲットの地域と言語設定に基づいて関連性の高いコンテンツを得るため、国と言語の優先順を指定します。

<div id="how-it-works">
  ### 仕組み
</div>

ロケーション設定を指定すると、Firecrawl は利用可能な場合は適切なプロキシを使用し、対応する言語とタイムゾーンをエミュレートします。指定がない場合、ロケーションのデフォルトは「US」です。

<div id="usage">
  ### 使い方
</div>

場所と言語の設定を使うには、リクエストボディに `location` オブジェクトを含め、次のプロパティを指定します:

* `country`: ISO 3166-1 alpha-2 の国コード（例: &#39;US&#39;, &#39;AU&#39;, &#39;DE&#39;, &#39;JP&#39;）。既定値は &#39;US&#39;。
* `languages`: 優先度順に並べた、リクエストで使用する希望言語およびロケールの配列。既定値は指定した location の言語。

<CodeGroup>
  <ScrapeLocationPython />

  <ScrapeLocationNode />

  <ScrapeLocationCURL />
</CodeGroup>

対応している地域の詳細は、[Proxies ドキュメント](/ja/features/proxies)を参照してください。

<div id="caching-and-maxage">
  ## キャッシュと maxAge
</div>

リクエストを高速化するため、Firecrawl は最近のコピーがある場合、デフォルトでキャッシュから結果を返します。

* **デフォルトの鮮度ウィンドウ**: `maxAge = 172800000` ms（2日）。キャッシュされたページがこの値より新しければ即時に返し、そうでなければスクレイプしてからキャッシュします。
* **パフォーマンス**: データが厳密な最新性を要さない場合、スクレイプを最大5倍高速化できます。
* **常に最新を取得**: `maxAge` を `0` に設定します。
* **保存しない**: このリクエストの結果を Firecrawl にキャッシュ/保存させたくない場合は、`storeInCache` を `false` に設定します。
* **変更トラッキング**: `changeTracking` を含むリクエストはキャッシュをバイパスするため、`maxAge` は無視されます。

例（常に最新コンテンツを取得）:

<CodeGroup>
  ```python Python
  from firecrawl import Firecrawl
  firecrawl = Firecrawl(api_key='fc-YOUR_API_KEY')

  doc = firecrawl.scrape(url='https://example.com', maxAge=0, formats=['markdown'])
  print(doc)
  ```

  ```js Node
  import Firecrawl from '@mendable/firecrawl-js';

  const firecrawl = new Firecrawl({ apiKey: "fc-YOUR-API-KEY" });

  const doc = await firecrawl.scrape('https://example.com', { maxAge: 0, formats: ['markdown'] });
  console.log(doc);
  ```

  ```bash cURL
  curl -s -X POST "https://api.firecrawl.dev/v2/scrape" \
    -H "Authorization: Bearer $FIRECRAWL_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "url": "https://example.com",
      "maxAge": 0,
      "formats": ["markdown"]
    }'
  ```
</CodeGroup>

例（10分のキャッシュウィンドウを使用）:

<CodeGroup>
  ```python Python
  from firecrawl import Firecrawl
  firecrawl = Firecrawl(api_key='fc-YOUR_API_KEY')

  doc = firecrawl.scrape(url='https://example.com', maxAge=600000, formats=['markdown', 'html'])
  print(doc)
  ```

  ```js Node
  import Firecrawl from '@mendable/firecrawl-js';

  const firecrawl = new Firecrawl({ apiKey: "fc-YOUR-API-KEY" });

  const doc = await firecrawl.scrape('https://example.com', { maxAge: 600000, formats: ['markdown', 'html'] });
  console.log(doc);
  ```

  ```bash cURL
  curl -s -X POST "https://api.firecrawl.dev/v2/scrape" \
    -H "Authorization: Bearer $FIRECRAWL_API_KEY" \
    -H "Content-Type: application/json" \
    -d '{
      "url": "https://example.com",
      "maxAge": 600000,
      "formats": ["markdown", "html"]
    }'
  ```
</CodeGroup>

<div id="batch-scraping-multiple-urls">
  ## 複数のURLのバッチスクレイピング
</div>

複数のURLを同時にバッチスクレイピングできるようになりました。開始URLと任意のパラメータを引数として受け取ります。params引数では、出力フォーマットなど、バッチスクレイピングジョブの追加オプションを指定できます。

<div id="how-it-works">
  ### 仕組み
</div>

これは `/crawl` エンドポイントの動作に非常によく似ています。バッチスクレイプのジョブを送信し、進行状況を確認するためのジョブIDを返します。

SDK は同期型と非同期型の2つのメソッドを提供します。同期型はバッチスクレイプジョブの結果を返し、非同期型はバッチスクレイプのステータス確認に使えるジョブIDを返します。

<div id="usage">
  ### 使い方
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Response
</div>

SDK の同期メソッドを使用している場合は、バッチスクレイプジョブの結果が返ります。同期メソッド以外では、バッチスクレイプのステータス確認に使用できるジョブ ID が返ります。

<div id="synchronous">
  #### 同期処理
</div>

<BatchScrapeOutput />

<div id="asynchronous">
  #### 非同期
</div>

その後、ジョブIDを使って `/batch/scrape/{id}` エンドポイントを呼び出し、バッチスクレイプのステータスを確認できます。 このエンドポイントは、ジョブの実行中、または完了直後に使用することを想定しています。**バッチスクレイプのジョブは24時間で有効期限が切れるため**です。

<BatchScrapeAsyncOutput />

<div id="enhanced-mode">
  ## 強化モード
</div>

複雑なウェブサイト向けに、Firecrawl はプライバシーを保護しながら成功率を向上させる強化モードを提供しています。

[強化モード](/ja/features/enhanced-mode)について詳しくはこちら。