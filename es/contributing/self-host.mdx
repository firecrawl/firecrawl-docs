---
title: "Alojamiento propio"
description: "Aprende a alojar Firecrawl por tu cuenta y contribuir al proyecto."
og:title: "Alojamiento propio | Firecrawl"
og:description: "Aprende a alojar Firecrawl por tu cuenta y contribuir al proyecto."
---

<div id="contributor">
  #### ¬øQuieres contribuir?
</div>

¬°Bienvenido a [Firecrawl](https://firecrawl.dev) üî•! Aqu√≠ tienes instrucciones para obtener el proyecto en local, ejecutarlo por tu cuenta y contribuir.

Si vas a contribuir, ten en cuenta que el proceso es similar al de otros repositorios de c√≥digo abierto: haz un fork de Firecrawl, realiza cambios, ejecuta las pruebas y abre un PR.

Si tienes preguntas o necesitas ayuda para empezar, √∫nete a nuestra comunidad de Discord [aqu√≠](https://discord.gg/gSmWdAkdwd) para m√°s informaci√≥n o crea un issue en GitHub [aqu√≠](https://github.com/mendableai/firecrawl/issues/new/choose).

<div id="self-hosting-firecrawl">
  ## Autohospedar Firecrawl
</div>

Consulta [SELF_HOST.md](https://github.com/mendableai/firecrawl/blob/main/SELF_HOST.md) para obtener instrucciones sobre c√≥mo ejecutarlo localmente.

<div id="why">
  ## ¬øPor qu√©?
</div>

Alojar Firecrawl por tu cuenta es especialmente √∫til para organizaciones con pol√≠ticas de seguridad estrictas que requieren mantener los datos en entornos controlados. Estas son algunas razones clave para considerar el autoalojamiento:

- **Mayor seguridad y cumplimiento:** Al autoalojar, garantizas que el manejo y procesamiento de datos cumplan con normativas internas y externas, manteniendo la informaci√≥n sensible dentro de tu infraestructura segura. Ten en cuenta que Firecrawl es un producto de Mendable y cuenta con certificaci√≥n SOC 2 Type II, lo que significa que la plataforma cumple con altos est√°ndares del sector para la gesti√≥n de la seguridad de los datos.
- **Servicios personalizables:** El autoalojamiento permite adaptar servicios como Playwright a necesidades espec√≠ficas o a casos de uso particulares que quiz√° no est√©n cubiertos por la oferta est√°ndar en la nube.
- **Aprendizaje y contribuci√≥n a la comunidad:** Al configurar y mantener tu propia instancia, obtienes una comprensi√≥n m√°s profunda de c√≥mo funciona Firecrawl, lo que tambi√©n puede traducirse en contribuciones m√°s valiosas al proyecto.

<div id="considerations">
  ### Consideraciones
</div>

Sin embargo, hay algunas limitaciones y responsabilidades adicionales que debes tener en cuenta:

1. **Acceso limitado a Fire-engine:** Actualmente, las instancias autoalojadas de Firecrawl no tienen acceso a Fire-engine, que incluye funciones avanzadas para manejar bloqueos de IP, mecanismos de detecci√≥n de bots y m√°s. Esto significa que, aunque puedes gestionar tareas b√°sicas de scraping, los escenarios m√°s complejos podr√≠an requerir configuraci√≥n adicional o puede que no est√©n admitidos.
2. **Se requiere configuraci√≥n manual:** Si necesitas usar m√©todos de scraping m√°s all√° de las opciones b√°sicas de `fetch` y Playwright, deber√°s configurarlos manualmente en el archivo `.env`. Esto requiere un conocimiento m√°s profundo de las tecnolog√≠as y podr√≠a implicar m√°s tiempo de configuraci√≥n.

Autoalojar Firecrawl es ideal para quienes necesitan control total sobre sus entornos de scraping y procesamiento de datos, pero conlleva el coste de un mantenimiento y una configuraci√≥n adicionales.

<div id="steps">
  ## Pasos
</div>

1. Primero, instala las dependencias

* [Instrucciones de Docker](https://docs.docker.com/get-docker/)

2. Configura las variables de entorno

Crea un archivo `.env` en el directorio ra√≠z; puedes copiar la plantilla desde `apps/api/.env.example`

Para empezar, no configuraremos la autenticaci√≥n ni ning√∫n servicio opcional (an√°lisis de PDF, bloqueo de JS, funciones de IA)

```
# .env

# ===== ENVS Requeridas ======
PORT=3002
HOST=0.0.0.0

# Nota: PORT es utilizado tanto por el servidor API principal como por el endpoint de verificaci√≥n de actividad del worker

# Para activar la autenticaci√≥n de BD, necesitas configurar Supabase.
USE_DB_AUTHENTICATION=false

# ===== ENVS Opcionales ======

## === Funcionalidades de IA (formato JSON en scrape, API /extract) ===
# Proporciona tu clave API de OpenAI aqu√≠ para habilitar las funcionalidades de IA
# OPENAI_API_KEY=

# Experimental: Usar Ollama
# OLLAMA_BASE_URL=http://localhost:11434/api
# MODEL_NAME=deepseek-r1:7b
# MODEL_EMBEDDING_NAME=nomic-embed-text

# Experimental: Usar cualquier API compatible con OpenAI
# OPENAI_BASE_URL=https://example.com/v1
# OPENAI_API_KEY=

## === Proxy ===
# PROXY_SERVER puede ser una URL completa (ej. http://0.1.2.3:1234) o solo una combinaci√≥n de IP y puerto (ej. 0.1.2.3:1234)
# No descomentes PROXY_USERNAME y PROXY_PASSWORD si tu proxy no requiere autenticaci√≥n
# PROXY_SERVER=
# PROXY_USERNAME=
# PROXY_PASSWORD=

## === API /search ===
# Por defecto, la API /search utilizar√° la b√∫squeda de Google.

# Puedes especificar un servidor SearXNG con el formato JSON habilitado, si prefieres usarlo en lugar de Google directo.
# Tambi√©n puedes personalizar los par√°metros de engines y categories, pero los valores predeterminados tambi√©n deber√≠an funcionar bien.
# SEARXNG_ENDPOINT=http://your.searxng.server
# SEARXNG_ENGINES=
# SEARXNG_CATEGORIES=

## === Otros ===

# Configuraci√≥n de Supabase (utilizado para soportar autenticaci√≥n de BD, registro avanzado, etc.)
# SUPABASE_ANON_TOKEN=
# SUPABASE_URL=
# SUPABASE_SERVICE_TOKEN=

# Usa esto si has configurado autenticaci√≥n y quieres probar con una clave API real
# TEST_API_KEY=

# Esta clave te permite acceder al panel de administraci√≥n de colas. C√°mbiala si tu despliegue es accesible p√∫blicamente.
BULL_AUTH_KEY=CHANGEME

# Esto ahora se autoconfigura mediante el docker-compose.yaml. No deber√≠as necesitar configurarlo.
# PLAYWRIGHT_MICROSERVICE_URL=http://playwright-service:3000/scrape
# REDIS_URL=redis://redis:6379
# REDIS_RATE_LIMIT_URL=redis://redis:6379

# Configura esto si tienes una clave de llamaparse que te gustar√≠a usar para analizar PDFs
# LLAMAPARSE_API_KEY=

# Configura esto si te gustar√≠a enviar mensajes de estado de salud del servidor a Slack
# SLACK_WEBHOOK_URL=

# Configura esto si te gustar√≠a enviar eventos de posthog como registros de trabajos
# POSTHOG_API_KEY=
# POSTHOG_HOST=

## === Configuraci√≥n de Recursos del Sistema ===
# Umbral m√°ximo de uso de CPU (0.0-1.0). El worker rechazar√° nuevos trabajos cuando el uso de CPU exceda este valor.
# Predeterminado: 0.8 (80%)
# MAX_CPU=0.8

# Umbral m√°ximo de uso de RAM (0.0-1.0). El worker rechazar√° nuevos trabajos cuando el uso de memoria exceda este valor.
# Predeterminado: 0.8 (80%)
# MAX_RAM=0.8

# Configura esto si te gustar√≠a permitir que se env√≠en webhooks locales a tu instancia autohospedada
# ALLOW_LOCAL_WEBHOOKS=true
```

3. *(Opcional) Ejecutar con el servicio de Playwright en TypeScript*

   * Actualiza el archivo `docker-compose.yml` para cambiar el servicio de Playwright:

     ```plaintext
         build: apps/playwright-service
     ```

     A

     ```plaintext
         build: apps/playwright-service-ts
     ```

   * Define `PLAYWRIGHT_MICROSERVICE_URL` en tu archivo `.env`:

     ```plaintext
     PLAYWRIGHT_MICROSERVICE_URL=http://localhost:3000/scrape
     ```

   * No olvides configurar el servidor proxy en tu archivo `.env` seg√∫n sea necesario.

4. Compila y ejecuta los contenedores de Docker:

   ```bash
   docker compose build
   docker compose up
   ```

Esto iniciar√° una instancia local de Firecrawl accesible en `http://localhost:3002`.

Deber√≠as poder ver la interfaz de Bull Queue Manager en `http://localhost:3002/admin/@/queues`.

5. *(Opcional)* Prueba la API

Si quieres probar el endpoint de crawl, puedes ejecutar lo siguiente:

```bash
  curl -X POST http://localhost:3002/v2/crawl \
      -H 'Content-Type: application/json' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
```

<div id="troubleshooting">
  ## Soluci√≥n de problemas
</div>

Esta secci√≥n ofrece soluciones a problemas comunes que puedes encontrar al configurar o ejecutar tu instancia autoalojada de Firecrawl.

<div id="supabase-client-is-not-configured">
  ### El cliente de Supabase no est√° configurado
</div>

**S√≠ntoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Se intent√≥ acceder al cliente de Supabase cuando no est√° configurado.
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Error al insertar el evento de scraping: Error: el cliente de Supabase no est√° configurado.
```

**Explicaci√≥n:**
Este error ocurre porque la configuraci√≥n del cliente de Supabase no est√° completa. Deber√≠as poder hacer scraping y crawling sin problemas. Actualmente no es posible configurar Supabase en instancias autogestionadas.

<div id="youre-bypassing-authentication">
  ### Est√°s eludiendo la autenticaci√≥n
</div>

**S√≠ntoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]WARN - Est√°s eludiendo la autenticaci√≥n
```

**Explicaci√≥n:**
Este error se debe a que la configuraci√≥n del cliente de Supabase no est√° completa. Deber√≠as poder realizar scraping y crawling sin problemas. Por ahora, no es posible configurar Supabase en instancias autogestionadas.

<div id="docker-containers-fail-to-start">
  ### Los contenedores de Docker no arrancan
</div>

**S√≠ntoma:**
Los contenedores de Docker se detienen inesperadamente o no llegan a iniciarse.

**Soluci√≥n:**
Consulta los registros de Docker para ver si hay mensajes de error usando el siguiente comando:

```bash
docker logs [nombre_del_contenedor]
```

* Aseg√∫rate de que todas las variables de entorno necesarias est√©n correctamente definidas en el archivo .env.
* Verifica que todos los servicios de Docker definidos en docker-compose.yml est√©n correctamente configurados y que las im√°genes necesarias est√©n disponibles.

<div id="connection-issues-with-redis">
  ### Problemas de conexi√≥n con Redis
</div>

**S√≠ntoma:**
Errores al conectarse a Redis, como tiempos de espera o ‚ÄúConnection refused‚Äù.

**Soluci√≥n:**

- Aseg√∫rate de que el servicio de Redis est√© en ejecuci√≥n en tu entorno Docker.
- Verifica que REDIS_URL y REDIS_RATE_LIMIT_URL en tu archivo .env apunten a la instancia correcta de Redis.
- Revisa la configuraci√≥n de red y las reglas del firewall que puedan bloquear la conexi√≥n al puerto de Redis.

<div id="api-endpoint-does-not-respond">
  ### El punto de conexi√≥n de la API no responde
</div>

**S√≠ntoma:**
Las solicitudes a la API de la instancia de Firecrawl se agotan por tiempo de espera o no devuelven respuesta.

**Soluci√≥n:**

- Aseg√∫rate de que el servicio de Firecrawl est√© en ejecuci√≥n comprobando el estado del contenedor de Docker.
- Verifica que las variables PORT y HOST en tu archivo .env sean correctas y que ning√∫n otro servicio est√© usando el mismo puerto.
- Revisa la configuraci√≥n de red para garantizar que el host sea accesible desde el cliente que realiza la solicitud a la API.

Al resolver estos problemas comunes, podr√°s lograr una configuraci√≥n y operaci√≥n m√°s fluidas de tu instancia autogestionada de Firecrawl.

<div id="install-firecrawl-on-a-kubernetes-cluster-simple-version">
  ## Instalar Firecrawl en un cl√∫ster de Kubernetes (versi√≥n simple)
</div>

Consulta el [examples/kubernetes-cluster-install/README.md](https://github.com/firecrawl/firecrawl/tree/main/examples/kubernetes/cluster-install#readme) para ver las instrucciones de instalaci√≥n de Firecrawl en un cl√∫ster de Kubernetes.