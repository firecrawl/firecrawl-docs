---
title: "Alojamiento propio"
description: "Aprende a alojar Firecrawl por tu cuenta y contribuir al proyecto."
og:title: "Alojamiento propio | Firecrawl"
og:description: "Aprende a alojar Firecrawl por tu cuenta y contribuir al proyecto."
---

<div id="contributor">
  #### 쯈uieres contribuir?
</div>

춰Bienvenido a [Firecrawl](https://firecrawl.dev) 游댠! Aqu칤 tienes instrucciones para obtener el proyecto en local, ejecutarlo por tu cuenta y contribuir.

Si vas a contribuir, ten en cuenta que el proceso es similar al de otros repositorios de c칩digo abierto: haz un fork de Firecrawl, realiza cambios, ejecuta las pruebas y abre un PR.

Si tienes preguntas o necesitas ayuda para empezar, 칰nete a nuestra comunidad de Discord [aqu칤](https://discord.gg/gSmWdAkdwd) para m치s informaci칩n o crea un issue en GitHub [aqu칤](https://github.com/mendableai/firecrawl/issues/new/choose).

<div id="self-hosting-firecrawl">
  ## Autohospedar Firecrawl
</div>

Consulta [SELF_HOST.md](https://github.com/mendableai/firecrawl/blob/main/SELF_HOST.md) para obtener instrucciones sobre c칩mo ejecutarlo localmente.

<div id="why">
  ## 쯇or qu칠?
</div>

Alojar Firecrawl por tu cuenta es especialmente 칰til para organizaciones con pol칤ticas de seguridad estrictas que requieren mantener los datos en entornos controlados. Estas son algunas razones clave para considerar el autoalojamiento:

- **Mayor seguridad y cumplimiento:** Al autoalojar, garantizas que el manejo y procesamiento de datos cumplan con normativas internas y externas, manteniendo la informaci칩n sensible dentro de tu infraestructura segura. Ten en cuenta que Firecrawl es un producto de Mendable y cuenta con certificaci칩n SOC 2 Type II, lo que significa que la plataforma cumple con altos est치ndares del sector para la gesti칩n de la seguridad de los datos.
- **Servicios personalizables:** El autoalojamiento permite adaptar servicios como Playwright a necesidades espec칤ficas o a casos de uso particulares que quiz치 no est칠n cubiertos por la oferta est치ndar en la nube.
- **Aprendizaje y contribuci칩n a la comunidad:** Al configurar y mantener tu propia instancia, obtienes una comprensi칩n m치s profunda de c칩mo funciona Firecrawl, lo que tambi칠n puede traducirse en contribuciones m치s valiosas al proyecto.

<div id="considerations">
  ### Consideraciones
</div>

Sin embargo, hay algunas limitaciones y responsabilidades adicionales que debes tener en cuenta:

1. **Acceso limitado a Fire-engine:** Actualmente, las instancias autoalojadas de Firecrawl no tienen acceso a Fire-engine, que incluye funciones avanzadas para manejar bloqueos de IP, mecanismos de detecci칩n de bots y m치s. Esto significa que, aunque puedes gestionar tareas b치sicas de scraping, los escenarios m치s complejos podr칤an requerir configuraci칩n adicional o puede que no est칠n admitidos.
2. **Se requiere configuraci칩n manual:** Si necesitas usar m칠todos de scraping m치s all치 de las opciones b치sicas de `fetch` y Playwright, deber치s configurarlos manualmente en el archivo `.env`. Esto requiere un conocimiento m치s profundo de las tecnolog칤as y podr칤a implicar m치s tiempo de configuraci칩n.

| Capacidad | Cloud | Autoalojado |
| --- | --- | --- |
| Todos los endpoints de la API admitidos | S칤 | No siempre; `/agent` no es compatible en autoalojado |
| Compatibilidad con capturas de pantalla | S칤 | S칤, cuando el servicio de Playwright est치 en ejecuci칩n |
| LLM locales (p. ej., Ollama) | No compatible | Compatible mediante `OLLAMA_BASE_URL` (experimental) |

Autoalojar Firecrawl es ideal para quienes necesitan control total sobre sus entornos de scraping y procesamiento de datos, pero conlleva el coste de un mantenimiento y una configuraci칩n adicionales.

<div id="steps">
  ## Pasos
</div>

1. Primero, instala las dependencias

* Docker [instrucciones](https://docs.docker.com/get-docker/)

2. Configura las variables de entorno

Crea un archivo `.env` en el directorio ra칤z; puedes copiar la plantilla desde `apps/api/.env.example`

Para empezar, no configuraremos la autenticaci칩n ni ning칰n servicio opcional (an치lisis de PDF, bloqueo de JS, funcionalidades de IA)

```
# .env

# ===== Required ENVS ======
PORT=3002
HOST=0.0.0.0

# Note: PORT is used by both the main API server and worker liveness check endpoint

# To turn on DB authentication, you need to set up Supabase.
USE_DB_AUTHENTICATION=false

# ===== Optional ENVS ======

## === AI features (JSON format on scrape, /extract API) ===
# Provide your OpenAI API key here to enable AI features
# OPENAI_API_KEY=

# Experimental: Use Ollama
# OLLAMA_BASE_URL=http://localhost:11434/api
# MODEL_NAME=deepseek-r1:7b
# MODEL_EMBEDDING_NAME=nomic-embed-text

# Experimental: Use any OpenAI-compatible API
# OPENAI_BASE_URL=https://example.com/v1
# OPENAI_API_KEY=

## === Proxy ===
# PROXY_SERVER can be a full URL (e.g. http://0.1.2.3:1234) or just an IP and port combo (e.g. 0.1.2.3:1234)
# Do not uncomment PROXY_USERNAME and PROXY_PASSWORD if your proxy is unauthenticated
# PROXY_SERVER=
# PROXY_USERNAME=
# PROXY_PASSWORD=

## === /search API ===

# Puedes especificar un servidor SearXNG con el formato JSON habilitado, si prefieres usarlo en lugar de Google directo.
# Tambi칠n puedes personalizar los par치metros de engines y categories, pero los valores predeterminados tambi칠n deber칤an funcionar bien.
# SEARXNG_ENDPOINT=http://your.searxng.server
# SEARXNG_ENGINES=
# SEARXNG_CATEGORIES=

## === Other ===

# Supabase Setup (used to support DB authentication, advanced logging, etc.)
# SUPABASE_ANON_TOKEN=
# SUPABASE_URL=
# SUPABASE_SERVICE_TOKEN=

# Use if you've set up authentication and want to test with a real API key
# TEST_API_KEY=

# This key lets you access the queue admin panel. Change this if your deployment is publicly accessible.
BULL_AUTH_KEY=CHANGEME

# This is now autoconfigured by the docker-compose.yaml. You shouldn't need to set it.
# PLAYWRIGHT_MICROSERVICE_URL=http://playwright-service:3000/scrape
# REDIS_URL=redis://redis:6379
# REDIS_RATE_LIMIT_URL=redis://redis:6379

# Set if you have a llamaparse key you'd like to use to parse pdfs
# LLAMAPARSE_API_KEY=

# Set if you'd like to send server health status messages to Slack
# SLACK_WEBHOOK_URL=

# Set if you'd like to send posthog events like job logs
# POSTHOG_API_KEY=
# POSTHOG_HOST=

## === System Resource Configuration ===
# Maximum CPU usage threshold (0.0-1.0). Worker will reject new jobs when CPU usage exceeds this value.
# Default: 0.8 (80%)
# MAX_CPU=0.8

# Maximum RAM usage threshold (0.0-1.0). Worker will reject new jobs when memory usage exceeds this value.
# Default: 0.8 (80%)
# MAX_RAM=0.8

# Set if you'd like to allow local webhooks to be sent to your self-hosted instance
# ALLOW_LOCAL_WEBHOOKS=true
```

<Note>
  Las siguientes funcionalidades de IA requieren un proveedor de LLM configurado (por ejemplo, `OPENAI_API_KEY` o alternativas en la secci칩n de funcionalidades de IA anterior):

  * Formato JSON en el scraping
  * API /extract
  * Formato de resumen
  * Formato de branding
  * Formato de seguimiento de cambios
</Note>

3. *(Opcional) Ejecutar con el servicio de Playwright en TypeScript*

   * Actualiza el archivo `docker-compose.yml` para cambiar el servicio de Playwright:

     ```plaintext
         build: apps/playwright-service
     ```

     A

     ```plaintext
         build: apps/playwright-service-ts
     ```

   * Define `PLAYWRIGHT_MICROSERVICE_URL` en tu archivo `.env`:

     ```plaintext
     PLAYWRIGHT_MICROSERVICE_URL=http://localhost:3000/scrape
     ```

   * No olvides configurar el servidor proxy en tu archivo `.env` seg칰n sea necesario.

4. Compila y ejecuta los contenedores de Docker:

   ```bash
   docker compose build
   docker compose up
   ```

Esto iniciar치 una instancia local de Firecrawl accesible en `http://localhost:3002`.

Deber칤as poder ver la interfaz de Bull Queue Manager en `http://localhost:3002/admin/{BULL_AUTH_KEY}/queues`.

5. *(Opcional)* Prueba la API

Si quieres probar el endpoint de rastreo, puedes ejecutar lo siguiente:

```bash
  curl -X POST http://localhost:3002/v2/crawl \
      -H 'Content-Type: application/json' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
```


<div id="troubleshooting">
  ## Resoluci칩n de problemas
</div>

Esta secci칩n ofrece soluciones a problemas comunes que puedes encontrar al configurar o ejecutar tu instancia autohospedada de Firecrawl.

<div id="supabase-client-is-not-configured">
  ### El cliente de Supabase no est치 configurado
</div>

**S칤ntoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Se intent칩 acceder al cliente de Supabase cuando no est치 configurado.
[YYYY-MM-DDTHH:MM:SS.SSSz]ERROR - Error al insertar el evento de scraping: Error: el cliente de Supabase no est치 configurado.
```

**Explicaci칩n:**
Este error ocurre porque la configuraci칩n del cliente de Supabase no est치 completa. Deber칤as poder hacer scraping y crawling sin problemas. Actualmente no es posible configurar Supabase en instancias autogestionadas.

<div id="youre-bypassing-authentication">
  ### Se est치 omitiendo la autenticaci칩n
</div>

**S칤ntoma:**

```bash
[YYYY-MM-DDTHH:MM:SS.SSSz]WARN - You're bypassing authentication
```

**Explicaci칩n:**
Este error ocurre porque la configuraci칩n del cliente de Supabase no se ha completado. Deber칤as poder hacer scraping y rastreo sin problemas. Actualmente no es posible configurar Supabase en instancias autoalojadas.


<div id="docker-containers-fail-to-start">
  ### Los contenedores de Docker no se inician
</div>

**S칤ntoma:**
Los contenedores de Docker terminan inesperadamente o fallan al iniciarse.

**Soluci칩n:**
Consulta los registros de Docker para ver si hay mensajes de error usando el comando:

```bash
docker logs [container_name]
```

* Aseg칰rate de que todas las variables de entorno necesarias est칠n definidas correctamente en el archivo .env.
* Verifica que todos los servicios de Docker definidos en docker-compose.yml est칠n correctamente configurados y que las im치genes necesarias est칠n disponibles.


<div id="connection-issues-with-redis">
  ### Problemas de conexi칩n con Redis
</div>

**S칤ntoma:**
Errores relacionados con la conexi칩n a Redis, como timeouts o "Connection refused".

**Soluci칩n:**

- Aseg칰rate de que el servicio de Redis est칠 activo y en ejecuci칩n en tu entorno Docker.
- Verifica que `REDIS_URL` y `REDIS_RATE_LIMIT_URL` en tu archivo `.env` apunten a la instancia correcta de Redis.
- Revisa la configuraci칩n de red y las reglas de firewall que puedan estar bloqueando la conexi칩n al puerto de Redis.

<div id="api-endpoint-does-not-respond">
  ### El punto de conexi칩n de la API no responde
</div>

**S칤ntoma:**
Las solicitudes a la API de la instancia de Firecrawl se agotan por tiempo de espera o no devuelven respuesta.

**Soluci칩n:**

- Aseg칰rate de que el servicio de Firecrawl est칠 en ejecuci칩n comprobando el estado del contenedor de Docker.
- Verifica que las variables PORT y HOST en tu archivo .env sean correctas y que ning칰n otro servicio est칠 usando el mismo puerto.
- Revisa la configuraci칩n de red para garantizar que el host sea accesible desde el cliente que realiza la solicitud a la API.

Al resolver estos problemas comunes, podr치s lograr una configuraci칩n y operaci칩n m치s fluidas de tu instancia autogestionada de Firecrawl.

<div id="install-firecrawl-on-a-kubernetes-cluster-simple-version">
  ## Instalar Firecrawl en un cl칰ster de Kubernetes (versi칩n simple)
</div>

Consulta el [examples/kubernetes-cluster-install/README.md](https://github.com/firecrawl/firecrawl/tree/main/examples/kubernetes/cluster-install#readme) para ver las instrucciones de instalaci칩n de Firecrawl en un cl칰ster de Kubernetes.