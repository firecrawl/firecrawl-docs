---
title: 'Llamaindex'
description: 'Firecrawl se integra con LlamaIndex como lector de documentos.'
og:title: "Llamaindex | Firecrawl"
og:description: "Firecrawl se integra con LlamaIndex como lector de documentos."
---

> Nota: esta integración aún usa la [versión v0 de la API de Firecrawl](/es/v0/introduction). Puedes instalar la versión 0.0.20 del SDK de Python o la 0.0.36 del SDK de Node.

<div id="installation">
  ## Instalación
</div>

```bash
pip install firecrawl-py==0.0.20 llama_index llama-index llama-index-readers-web

```

<div id="usage">
  ## Uso
</div>

<div id="using-firecrawl-to-gather-an-entire-website">
  ### Usar Firecrawl para recopilar todo un sitio web
</div>

```python
from llama_index.readers.web import FireCrawlWebReader
from llama_index.core import SummaryIndex
import os


# Inicializa FireCrawlWebReader para rastrear un sitio web
firecrawl_reader = FireCrawlWebReader(
    api_key="<your_api_key>",  # Sustituye por tu clave de API real de https://www.firecrawl.dev/
    mode="scrape",  # Elige entre "crawl" y "scrape" para extraer una sola página
    params={"additional": "parameters"}  # Parámetros adicionales opcionales
)

# Establece la variable de entorno para la clave de OpenAI
os.environ["OPENAI_API_KEY"] = "<OPENAI_API_KEY>"

# Carga documentos desde una URL de una sola página
documents = firecrawl_reader.load_data(url="http://paulgraham.com/")
index = SummaryIndex.from_documents(documents)

# Configura el nivel de registro en DEBUG para obtener salidas más detalladas
query_engine = index.as_query_engine()
response = query_engine.query("¿Qué hacía el autor cuando crecía?")
display(Markdown(f"<b>{response}</b>"))
```

<div id="using-firecrawl-to-gather-a-single-page">
  ### Usar Firecrawl para recopilar una sola página
</div>

```python
from llama_index.readers.web import FireCrawlWebReader

# Inicializa FireCrawlWebReader con tu clave de API y el modo deseado
firecrawl_reader = FireCrawlWebReader(
    api_key="<your_api_key>",  # Reemplaza con tu clave de API real de https://www.firecrawl.dev/
    mode="scrape",  # Elige entre "crawl" y "scrape"
    params={"additional": "parameters"}  # Parámetros adicionales opcionales
)

# Carga documentos desde una URL específica
documents = firecrawl_reader.load_data(url="http://paulgraham.com/worked.html")
index = SummaryIndex.from_documents(documents)

# Configura el logging en DEBUG para obtener salidas más detalladas
query_engine = index.as_query_engine()
response = query_engine.query("¿Qué hacía el autor cuando estaba creciendo?")
display(Markdown(f"<b>{response}</b>"))
```
