---
title: 'Raspado en lote'
description: 'Raspar múltiples URL en lote'
og:title: 'Raspado en lote | Firecrawl'
og:description: 'Raspar múltiples URL en lote'
---

import BatchScrapePython from '/snippets/es/v2/batch-scrape/base/python.mdx';
import BatchScrapeNode from '/snippets/es/v2/batch-scrape/base/js.mdx';
import BatchScrapeCURL from '/snippets/es/v2/batch-scrape/base/curl.mdx';
import BatchScrapeOutput from '/snippets/es/v2/batch-scrape/base/output.mdx';
import BatchScrapeAsyncOutput from '/snippets/es/v2/batch-scrape/base/async-output.mdx';
import BatchScrapeExtractPython from '/snippets/es/v2/batch-scrape/json/python.mdx';
import BatchScrapeExtractNode from '/snippets/es/v2/batch-scrape/json/js.mdx';
import BatchScrapeExtractCURL from '/snippets/es/v2/batch-scrape/json/curl.mdx';
import BatchScrapeExtractOutput from '/snippets/es/v2/batch-scrape/json/output.mdx';
import BatchScrapeExtractAsyncOutput from '/snippets/es/v2/batch-scrape/json/async-output.mdx';
import BatchScrapeWebhookCURL from '/snippets/es/v1/batch-scrape-webhook/base/curl.mdx';

<div id="batch-scraping-multiple-urls">
  ## Raspado por lotes de múltiples URL
</div>

Ahora puedes raspar por lotes varias URL al mismo tiempo. Recibe las URL iniciales y parámetros opcionales como argumentos. El argumento params te permite especificar opciones adicionales para el trabajo de raspado por lotes, como los formatos de salida.

<div id="how-it-works">
  ### Cómo funciona
</div>

Es muy similar al funcionamiento del punto de conexión `/crawl`. Puedes iniciar el lote y esperar a que termine, o iniciarlo y gestionar tú mismo su finalización.

* `batchScrape` (JS) / `batch_scrape` (Python): inicia un trabajo por lotes, espera a que finalice y devuelve los resultados.
* `startBatchScrape` (JS) / `start_batch_scrape` (Python): inicia un trabajo por lotes y devuelve el ID del trabajo para que puedas hacer polling o usar webhooks.

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  <BatchScrapePython />

  <BatchScrapeNode />

  <BatchScrapeCURL />
</CodeGroup>

<div id="response">
  ### Respuesta
</div>

Invocar `batchScrape`/`batch_scrape` devuelve los resultados completos cuando el lote finaliza.

<BatchScrapeOutput />

Invocar `startBatchScrape`/`start_batch_scrape` devuelve
un ID de tarea que puedes monitorear mediante `getBatchScrapeStatus`/`get_batch_scrape_status`, usando
el endpoint de la API `/batch/scrape/{id}` o webhooks. Los resultados de la tarea están disponibles a través de la API durante 24 horas después de su finalización. Después de este período, aún puedes ver el historial y los resultados de tus ejecuciones de batch scrape en los [activity logs](https://www.firecrawl.dev/app/logs).

<BatchScrapeAsyncOutput />

<div id="batch-scrape-with-structured-extraction">
  ## Raspado por lotes con extracción estructurada
</div>

También puedes usar el punto de conexión de raspado por lotes para extraer datos estructurados de las páginas. Esto es útil si quieres obtener los mismos datos estructurados de una lista de URL.

<CodeGroup>
  <BatchScrapeExtractPython />

  <BatchScrapeExtractNode />

  <BatchScrapeExtractCURL />
</CodeGroup>

<div id="response">
  ### Respuesta
</div>

`batchScrape`/`batch_scrape` devuelve resultados completos:

<BatchScrapeExtractOutput />

`startBatchScrape`/`start_batch_scrape` devuelve un ID de tarea:

<BatchScrapeExtractAsyncOutput />

<div id="batch-scrape-with-webhooks">
  ## Raspado por lotes con webhooks
</div>

Puedes configurar webhooks para recibir notificaciones en tiempo real a medida que se rastrea cada URL de tu lote. Esto te permite procesar los resultados de inmediato en lugar de esperar a que finalice todo el lote.

<BatchScrapeWebhookCURL />

<div id="quick-reference">
  ### Referencia rápida
</div>

**Tipos de eventos:**

* `batch_scrape.started` - Cuando comienza el scraping por lotes
* `batch_scrape.page` - Para cada URL extraída correctamente
* `batch_scrape.completed` - Cuando se procesan todas las URL
* `batch_scrape.failed` - Si el scraping por lotes presenta un error

**Carga útil básica:**

```json
{
  "success": true,
  "type": "batch_scrape.page",
  "id": "batch-job-id",
  "data": [...], // Datos de página para eventos 'page'
  "metadata": {}, // Your custom metadata
  "error": null
}
```

<div id="security-verifying-webhook-signatures">
  ### Seguridad: Verificación de firmas de webhooks
</div>

Cada solicitud de webhook de Firecrawl incluye un encabezado `X-Firecrawl-Signature` que contiene una firma HMAC-SHA256. **Verifica siempre esta firma** para asegurarte de que el webhook sea auténtico y no haya sido manipulado.

**Cómo funciona:**

1. Obtén tu secreto de webhook en la [pestaña Advanced](https://www.firecrawl.dev/app/settings?tab=advanced) de la configuración de tu cuenta
2. Extrae la firma del encabezado `X-Firecrawl-Signature`
3. Calcula el HMAC-SHA256 del cuerpo sin procesar de la solicitud usando tu secreto
4. Compáralo con el encabezado de firma utilizando una función segura frente a ataques de temporización

<Warning>
  Nunca proceses un webhook sin verificar primero su firma. El encabezado `X-Firecrawl-Signature` contiene la firma en el formato: `sha256=abc123def456...`
</Warning>

Para ejemplos completos de implementación en JavaScript y Python, consulta la [documentación de seguridad de webhooks](/es/webhooks/security).

<div id="full-documentation">
  ### Documentación completa
</div>

Para documentación completa sobre webhooks, incluidos payloads de eventos detallados, configuración avanzada y diagnóstico y resolución de problemas, consulta la [documentación de webhooks](/es/webhooks/overview).