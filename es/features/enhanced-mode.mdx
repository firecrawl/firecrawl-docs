---
title: "Modo avanzado"
description: "Usa proxies mejorados para realizar scraping fiable en sitios complejos manteniendo la privacidad"
og:title: "Modo avanzado | Firecrawl"
og:description: "Usa proxies mejorados para realizar scraping fiable en sitios complejos manteniendo la privacidad"
---

import ProxyPython from "/snippets/es/v2/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/es/v2/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/es/v2/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/es/v2/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/es/v2/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/es/v2/scrape/proxy-retry/curl.mdx";

Firecrawl ofrece distintos tipos de proxy para ayudarte a hacer scraping de sitios web con diferentes niveles de complejidad. El tipo de proxy se puede especificar mediante el parámetro `proxy`.


<div id="proxy-types">
  ### Tipos de proxy
</div>

Firecrawl admite tres tipos de proxies:

- **basic**: Proxies para hacer scraping de la mayoría de los sitios web. Rápidos y que suelen funcionar.
- **enhanced**: Proxies avanzados para hacer scraping de sitios web complejos manteniendo la privacidad. Más lentos, pero más fiables en ciertos sitios.
- **auto**: Firecrawl reintentará automáticamente el scraping con proxies enhanced si el proxy basic falla. Si el reintento con enhanced tiene éxito, se cobrarán 5 créditos por el scraping. Si el primer intento con basic tiene éxito, solo se cobrará el coste estándar.

Si no especificas un proxy, Firecrawl usará auto de forma predeterminada.

<div id="using-enhanced-mode">
  ### Uso del modo mejorado
</div>

Al extraer datos de sitios web complejos, puedes usar el modo mejorado para mejorar tu tasa de éxito mientras mantienes la privacidad.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Nota:** Las solicitudes con proxy mejorado cuestan 5 créditos por solicitud cuando se usan.

<div id="using-enhanced-as-a-retry-mechanism">
  ## Usar Enhanced como mecanismo de reintento
</div>

Un patrón común es intentar primero el scraping con la configuración de proxy predeterminada y luego reintentar con el modo enhanced si encuentras códigos de estado de error específicos (401, 403 o 500) en el campo `metadata.statusCode` de la respuesta. Estos códigos de estado pueden indicar que el sitio web está bloqueando tu solicitud.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Este enfoque te permite optimizar el uso de tus créditos usando el modo enhanced solo cuando sea necesario.