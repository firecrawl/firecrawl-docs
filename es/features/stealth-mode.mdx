---
title: "Modo sigiloso"
description: "Usa proxies sigilosos para realizar scraping fiable en sitios complejos manteniendo la privacidad"
og:title: "Modo sigiloso | Firecrawl"
og:description: "Usa proxies sigilosos para realizar scraping fiable en sitios complejos manteniendo la privacidad"
---

import ProxyPython from "/snippets/es/v2/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/es/v2/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/es/v2/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/es/v2/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/es/v2/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/es/v2/scrape/proxy-retry/curl.mdx";

Firecrawl ofrece distintos tipos de proxy para ayudarte a hacer scraping en sitios web con diversos niveles de complejidad. El tipo de proxy puede especificarse mediante el parámetro `proxy`.


<div id="proxy-types">
  ### Tipos de proxy
</div>

Firecrawl admite tres tipos de proxy:

- **basic**: Proxy para extraer la mayoría de los sitios. Es rápido y suele funcionar.
- **stealth**: Proxy sigiloso para extraer sitios complejos manteniendo la privacidad. Es más lento, pero más confiable en ciertos sitios.
- **auto**: Firecrawl volverá a intentar automáticamente la extracción con un proxy sigiloso si falla el básico. Si el reintento con stealth tiene éxito, se cobrarán 5 créditos por la extracción. Si el primer intento con basic tiene éxito, solo se cobrará el costo regular.

Si no especificas un proxy, Firecrawl usará auto por defecto.

<div id="using-stealth-mode">
  ### Uso del modo stealth
</div>

Al extraer datos de sitios web complejos, puedes usar el modo stealth para mejorar la tasa de éxito mientras mantienes la privacidad.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Nota:** Las solicitudes con proxy stealth cuestan 5 créditos por solicitud cuando se usan.

<div id="using-stealth-as-a-retry-mechanism">
  ## Usar Stealth como mecanismo de reintento
</div>

Un patrón común es intentar primero hacer scraping con la configuración de proxy predeterminada y luego reintentar con el modo Stealth si aparecen códigos de estado de error específicos (401, 403 o 500) en el campo `metadata.statusCode` de la respuesta. Estos códigos pueden indicar que el sitio web está bloqueando tu solicitud.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Este enfoque te permite optimizar el uso de créditos al emplear el modo Stealth solo cuando sea necesario.