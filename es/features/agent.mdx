---
title: "Agent"
description: "Recopila datos dondequiera que se encuentren en la web."
og:title: "Agent | Firecrawl"
og:description: "Recopila datos dondequiera que se encuentren en la web."
sidebarTitle: "Agent"
---

import AgentPython from "/snippets/es/v2/agent/base/python.mdx";
import AgentJS from "/snippets/es/v2/agent/base/js.mdx";
import AgentCURL from "/snippets/es/v2/agent/base/curl.mdx";
import AgentOutput from "/snippets/es/v2/agent/base/output.mdx";
import AgentWithSchemaPython from "/snippets/es/v2/agent/with-schema/python.mdx";
import AgentWithSchemaJS from "/snippets/es/v2/agent/with-schema/js.mdx";
import AgentWithSchemaCURL from "/snippets/es/v2/agent/with-schema/curl.mdx";
import AgentWithSchemaOutput from "/snippets/es/v2/agent/with-schema/output.mdx";
import AgentWithURLsPython from "/snippets/es/v2/agent/with-urls/python.mdx";
import AgentWithURLsJS from "/snippets/es/v2/agent/with-urls/js.mdx";
import AgentWithURLsCURL from "/snippets/es/v2/agent/with-urls/curl.mdx";
import AgentStatusPython from "/snippets/es/v2/agent/status/python.mdx";
import AgentStatusJS from "/snippets/es/v2/agent/status/js.mdx";
import AgentStatusCURL from "/snippets/es/v2/agent/status/curl.mdx";
import AgentStatusPending from "/snippets/es/v2/agent/status/pending.mdx";
import AgentStatusCompleted from "/snippets/es/v2/agent/status/completed.mdx";
import AgentWithModelPython from "/snippets/es/v2/agent/with-model/python.mdx";
import AgentWithModelJS from "/snippets/es/v2/agent/with-model/js.mdx";
import AgentWithModelCURL from "/snippets/es/v2/agent/with-model/curl.mdx";

Firecrawl `/agent` es una API mágica que busca, navega y recopila datos desde la gama más amplia de sitios web, encontrando datos en lugares de difícil acceso y descubriéndolos de formas que ninguna otra API puede. Consigue en pocos minutos lo que a una persona le llevaría muchas horas: recopilación de datos de extremo a extremo, sin necesidad de scripts ni trabajo manual.
Tanto si necesitas un solo dato como conjuntos de datos completos a escala, Firecrawl `/agent` trabaja para obtener tus datos.

**Piensa en `/agent` como una investigación profunda de datos, ¡estén donde estén!**

<Info>
  **Vista previa de investigación**: Agent está en acceso anticipado. Es de esperar que tenga algunos detalles por pulir. Mejorará significativamente con el tiempo. [Comparte tus comentarios →](mailto:product@firecrawl.com)
</Info>

Agent se basa en todo lo bueno de `/extract` y lo lleva más allá:

* **No se requieren URL**: Describe lo que necesitas mediante el parámetro `prompt`. Las URL son opcionales
* **Búsqueda profunda en la web**: Busca y navega de forma autónoma, explorando en profundidad los sitios para encontrar tus datos
* **Fiable y preciso**: Funciona con una amplia variedad de consultas y casos de uso
* **Más rápido**: Procesa múltiples fuentes en paralelo para obtener resultados más rápidos

<div id="using-agent">
  ## Uso de `/agent`
</div>

El único parámetro obligatorio es `prompt`. Describe simplemente qué datos quieres extraer. Para obtener salida estructurada, proporciona un esquema JSON. Los SDK son compatibles con Pydantic (Python) y Zod (Node) para definiciones de esquemas con tipado seguro:

<CodeGroup>
  <AgentWithSchemaPython />

  <AgentWithSchemaJS />

  <AgentWithSchemaCURL />
</CodeGroup>

<div id="response">
  ### Respuesta
</div>

<AgentWithSchemaOutput />

<div id="providing-urls-optional">
  ## Proporcionar URLs (opcional)
</div>

Puedes proporcionar URLs opcionalmente para centrar al agente en páginas específicas:

<CodeGroup>
  <AgentWithURLsPython />

  <AgentWithURLsJS />

  <AgentWithURLsCURL />
</CodeGroup>

<div id="job-status-and-completion">
  ## Estado y finalización de trabajos
</div>

Los trabajos de agente se ejecutan de forma asíncrona. Cuando envíes un trabajo, recibirás un ID de trabajo que podrás usar para comprobar su estado:

* **Método predeterminado**: `agent()` espera y devuelve los resultados finales
* **Iniciar y luego consultar**: Usa `start_agent` (Python) o `startAgent` (Node) para obtener un ID de trabajo de inmediato y luego consulta su estado con `get_agent_status` / `getAgentStatus`

<Note>Los resultados de los trabajos estarán disponibles a través de la API durante 24 horas después de su finalización. Pasado este período, aún puedes ver el historial y los resultados de tu agente en los [registros de actividad](https://www.firecrawl.dev/app/logs).</Note>

<CodeGroup>
  <AgentStatusPython />

  <AgentStatusJS />

  <AgentStatusCURL />
</CodeGroup>

<div id="possible-states">
  ### Posibles estados
</div>

| Estado | Descripción |
|--------|-------------|
| `processing` | El agente todavía está trabajando en tu solicitud |
| `completed` | La extracción finalizó correctamente |
| `failed` | Se produjo un error durante la extracción |

<div id="pending-example">
  #### Ejemplo en estado pendiente
</div>

<AgentStatusPending />

<div id="completed-example">
  #### Ejemplo completado
</div>

<AgentStatusCompleted />

<div id="model-selection">
  ## Selección de modelo
</div>

Firecrawl Agent ofrece dos modelos. **Spark 1 Mini es un 60% más barato** y es el modelo predeterminado — perfecto para la mayoría de los casos de uso. Pásate a Spark 1 Pro cuando necesites la máxima precisión en tareas complejas.

| Modelo | Coste | Precisión | Ideal para |
|--------|-------|-----------|------------|
| `spark-1-mini` | **60% más barato** | Estándar | La mayoría de las tareas (predeterminado) |
| `spark-1-pro` | Estándar | Mayor | Investigación compleja, extracción crítica |

<Tip>
  **Empieza con Spark 1 Mini** (predeterminado) — gestiona bien la mayoría de las tareas de extracción con un coste un 60% menor. Cambia a Pro solo para investigación compleja en múltiples dominios o cuando la precisión sea crítica.
</Tip>

<div id="spark-1-mini-default">
  ### Spark 1 Mini (predeterminado)
</div>

`spark-1-mini` es nuestro modelo eficiente, ideal para tareas sencillas de extracción de datos.

**Usa Mini cuando:**

* Necesites extraer datos simples (información de contacto, precios, etc.)
* Trabajes con sitios web bien estructurados
* La eficiencia de costos sea una prioridad
* Debas ejecutar trabajos de extracción de alto volumen

<div id="spark-1-pro">
  ### Spark 1 Pro
</div>

`spark-1-pro` es nuestro modelo insignia, diseñado para lograr la máxima precisión en tareas de extracción complejas.

**Usa Pro cuando:**

* Realices análisis de la competencia complejos
* Extraigas datos que requieran razonamiento profundo
* La precisión sea crítica para tu caso de uso
* Trates con datos ambiguos o difíciles de encontrar

<div id="specifying-a-model">
  ### Especificar un modelo
</div>

Pasa el parámetro `model` para seleccionar el modelo que quieres usar:

<CodeGroup>
  <AgentWithModelPython />

  <AgentWithModelJS />

  <AgentWithModelCURL />
</CodeGroup>

<div id="parameters">
  ## Parámetros
</div>

| Parámetro | Tipo | Obligatorio | Descripción |
|-----------|------|-------------|-------------|
| `prompt` | string | **Sí** | Descripción en lenguaje natural de los datos que deseas extraer (máx. 10.000 caracteres) |
| `model` | string | No | Modelo a utilizar: `spark-1-mini` (por defecto) o `spark-1-pro` |
| `urls` | array | No | Lista opcional de URLs en las que centrar la extracción |
| `schema` | object | No | Esquema JSON opcional para una salida estructurada |
| `maxCredits` | number | No | Número máximo de créditos que se pueden usar en esta tarea del agente. Si se alcanza el límite, la tarea falla y **no se devuelve ningún dato**, aunque los créditos consumidos por el trabajo realizado se siguen cobrando. |

<div id="agent-vs-extract-whats-improved">
  ## Agent vs Extract: Qué ha mejorado
</div>

| Característica | Agent (nuevo) | Extract |
|---------|-------------|---------|
| URLs necesarias | No | Sí |
| Velocidad | Más rápida | Estándar |
| Costo | Más bajo | Estándar |
| Fiabilidad | Más alta | Estándar |
| Flexibilidad de las consultas | Alta | Moderada |

<div id="example-use-cases">
  ## Ejemplos de casos de uso
</div>

* **Investigación**: &quot;Encuentra las 5 principales startups de IA y sus montos de financiación&quot;
* **Análisis de la competencia**: &quot;Compara los planes de precios entre Slack y Microsoft Teams&quot;
* **Recopilación de datos**: &quot;Extrae información de contacto de sitios web de empresas&quot;
* **Resumen de contenido**: &quot;Resume las últimas entradas de blog sobre web scraping&quot;

<div id="api-reference">
  ## Referencia de la API
</div>

Consulta la [Agent API Reference](/es/api-reference/endpoint/agent) para más detalles.

¿Tienes comentarios o necesitas ayuda? Escríbenos a [help@firecrawl.com](mailto:help@firecrawl.com).

<div id="pricing">
  ## Precios
</div>

Firecrawl Agent usa **facturación dinámica** que se ajusta a la complejidad de tu solicitud de extracción de datos. Pagas según el trabajo real que realiza Agent, lo que garantiza un precio justo tanto si estás extrayendo datos simples como información estructurada compleja de múltiples fuentes.

<div id="how-agent-pricing-works">
  ### Cómo funcionan los precios de Agent
</div>

Los precios de Agent son **dinámicos y basados en créditos** durante la Research Preview:

* **Extracciones simples** (como obtener información de contacto de una sola página) suelen usar menos créditos y cuestan menos
* **Tareas de investigación complejas** (como análisis de la competencia en múltiples dominios) usan más créditos, pero reflejan el esfuerzo total involucrado
* **Uso transparente** te muestra exactamente cuántos créditos consumió cada solicitud
* **Conversión de créditos** convierte automáticamente el uso de créditos del agente en créditos para una facturación sencilla

<Info>
  El uso de créditos varía según la complejidad de tu prompt, la cantidad de datos procesados y la estructura de la salida solicitada.
</Info>

<div id="getting-started">
  ### Primeros pasos
</div>

**Todos los usuarios** reciben **5 ejecuciones gratuitas al día** para explorar las capacidades de Agent sin costo.

El uso adicional se cobra en función del consumo de créditos y se convierte en créditos.

<div id="managing-costs">
  ### Gestión de costos
</div>

Agent puede resultar costoso, pero hay algunas formas de reducir el gasto:

* **Empieza con ejecuciones gratuitas**: Usa tus 5 solicitudes gratuitas diarias para entender los precios
* **Configura el parámetro `maxCredits`**: Limita tu gasto estableciendo un número máximo de créditos que estás dispuesto a usar
* **Optimiza los prompts**: Los prompts más específicos suelen consumir menos créditos
* **Supervisa tu uso**: Haz seguimiento de tu consumo desde el panel
* **Define expectativas**: Las investigaciones complejas en múltiples dominios consumirán más créditos que las extracciones sencillas de una sola página

Prueba Agent ahora en [firecrawl.dev/app/agent](https://www.firecrawl.dev/app/agent) para ver cómo escala el consumo de créditos según tus casos de uso específicos.

<Note>
  Los precios están sujetos a cambios a medida que pasamos de la Research Preview a la disponibilidad general. Los usuarios actuales recibirán aviso previo de cualquier actualización de precios.
</Note>