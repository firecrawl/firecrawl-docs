---
title: "Extracción"
description: "Extrae datos estructurados de páginas usando LLM"
og:title: "Extracción | Firecrawl"
og:description: "Extrae datos estructurados de páginas usando LLM"
icon: "barcode-read"
sidebarTitle: "Extracción"
---

import ExtractCURL from "/snippets/es/v2/extract/base/curl.mdx";
import ExtractPython from "/snippets/es/v2/extract/base/python.mdx";
import ExtractNode from "/snippets/es/v2/extract/base/js.mdx";
import ExtractOutput from "/snippets/es/v2/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/es/v2/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/es/v2/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/es/v2/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/es/v2/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/es/v2/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/es/v2/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/es/v2/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/es/v2/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/es/v2/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/es/v2/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/es/v2/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/es/v2/extract/status/pending.mdx";
import ExtractStatusDone from "/snippets/es/v2/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/es/v2/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/es/v2/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/es/v2/extract/base/curl.mdx";

El endpoint `/extract` simplifica la recopilación de datos estructurados desde cualquier número de URL o dominios completos. Proporciona una lista de URL, opcionalmente con comodines (p. ej., `example.com/*`), y un prompt o un esquema que describa la información que deseas. Firecrawl se encarga de los detalles de rastreo, análisis y compilación de conjuntos de datos grandes o pequeños.

<Info>Hemos simplificado la facturación para que Extract ahora use créditos, igual que los demás endpoints. Cada crédito equivale a 15 tokens.</Info>

<div id="using-extract">
  ## Uso de `/extract`
</div>

Puedes extraer datos estructurados de una o varias URL, incluidos comodines:

- **Página única**  
  Ejemplo: `https://firecrawl.dev/some-page`
- **Múltiples páginas / Dominio completo**  
  Ejemplo: `https://firecrawl.dev/*`

Cuando usas `/*`, Firecrawl rastreará y analizará automáticamente todas las URL que pueda descubrir en ese dominio y luego extraerá los datos solicitados. Esta función es experimental; escribe a [help@firecrawl.com](mailto:help@firecrawl.com) si tienes problemas.

<div id="example-usage">
  ### Ejemplo de uso
</div>

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

**Parámetros clave:**

- **urls**: Una lista de una o más URL. Admite comodines (`/*`) para un rastreo más amplio.
- **prompt** (Opcional salvo que no haya schema): Un prompt en lenguaje natural que describe los datos que quieres o especifica cómo quieres estructurarlos.
- **schema** (Opcional salvo que no haya prompt): Una estructura más rígida si ya conoces el esquema JSON.
- **enableWebSearch** (Opcional): Si es `true`, la extracción puede seguir enlaces fuera del dominio especificado.

Consulta la [Referencia de la API](https://docs.firecrawl.dev/api-reference/endpoint/extract) para más detalles.

<div id="response-sdks">
  ### Respuesta (SDKs)
</div>

<ExtractOutput />

<div id="job-status-and-completion">
  ## Estado del trabajo y finalización
</div>

Cuando envías un trabajo de extracción —ya sea directamente mediante la API o a través de los métodos de inicio— recibirás un ID de trabajo. Puedes usar este ID para:

- Obtener el estado del trabajo: Envía una solicitud al punto de conexión /extract/{ID} para ver si el trabajo sigue en ejecución o ya finalizó.
- Esperar los resultados: Si usas el método predeterminado `extract` (Python/Node), el SDK espera y devuelve los resultados finales.
- Iniciar y luego consultar: Si usas los métodos de inicio —`start_extract` (Python) o `startExtract` (Node)— el SDK devuelve un ID de trabajo de inmediato. Usa `get_extract_status` (Python) o `getExtractStatus` (Node) para consultar el progreso.

<Note>
  Este punto de conexión solo funciona para trabajos en curso o completados recientemente (dentro de 24 horas).
</Note>

A continuación, se muestran ejemplos de código para comprobar el estado de un trabajo de extracción usando Python, Node.js y cURL:

<CodeGroup>

<CheckExtractJobPython />
<CheckExtractJobJS />
<CheckExtractJobCURL />

</CodeGroup>

<div id="possible-states">
  ### Posibles estados
</div>

- **completed**: La extracción se completó correctamente.
- **processing**: Firecrawl aún está procesando tu solicitud.
- **failed**: Ocurrió un error; los datos no se extrajeron por completo.
- **cancelled**: El trabajo fue cancelado por el usuario.

<div id="pending-example">
  #### Ejemplo pendiente
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### Ejemplo completado
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## Extracción sin esquema
</div>

Si prefieres no definir una estructura estricta, puedes simplemente proporcionar un `prompt`. El modelo subyacente elegirá una estructura por ti, lo que puede ser útil para solicitudes más exploratorias o flexibles.

<CodeGroup>

<ExtractNoSchemaPython />
<ExtractNoSchemaJS />
<ExtractNoSchemaCURL />

</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## Mejora de resultados con búsqueda web
</div>

Establecer `enableWebSearch = true` en tu solicitud ampliará el rastreo más allá del conjunto de URL proporcionado. Esto puede capturar información de respaldo o relacionada de páginas enlazadas.

Aquí tienes un ejemplo que extrae información sobre cámaras para tablero (dash cams), enriqueciendo los resultados con datos de páginas relacionadas:

<CodeGroup>

<ExtractWebSearchPython />
<ExtractWebSearchJS />
<ExtractWebSearchCURL />

</CodeGroup>

<div id="example-response-with-web-search">
  ### Respuesta de ejemplo con búsqueda en la web
</div>

<ExtractWebSearchOutput />

La respuesta incluye contexto adicional obtenido de páginas relacionadas, lo que ofrece información más completa y precisa.

<div id="extracting-without-urls">
  ## Extracción sin URLs
</div>

El punto de conexión `/extract` ahora permite extraer datos estructurados con un prompt sin necesidad de URLs específicas. Es útil para investigación o cuando se desconocen las URLs exactas. Actualmente en alfa.

<CodeGroup>

<ExtractWithoutURLsPython />
<ExtractWithoutURLsJS />
<ExtractWithoutURLsCURL />

</CodeGroup>

<div id="known-limitations-beta">
  ## Limitaciones conocidas (Beta)
</div>

1. **Cobertura de sitios a gran escala**  
   Aún no se admite cubrir por completo sitios masivos (p. ej., “todos los productos de Amazon”) en una sola solicitud.

2. **Consultas lógicas complejas**  
   Solicitudes como “encontrar todas las publicaciones de 2025” pueden no devolver de forma fiable todos los datos esperados. Estamos trabajando en capacidades de consulta más avanzadas.

3. **Inconsistencias ocasionales**  
   Los resultados pueden variar entre ejecuciones, especialmente en sitios muy grandes o dinámicos. Por lo general se capturan los detalles clave, pero puede haber cierta variación.

4. **Estado Beta**  
   Dado que `/extract` sigue en Beta, las funciones y el rendimiento continuarán evolucionando. Agradecemos los reportes de errores y comentarios para ayudarnos a mejorar.

<div id="using-fire-1">
  ## Uso de FIRE-1
</div>

FIRE-1 es un agente de IA que amplía las capacidades de scraping de Firecrawl. Puede controlar acciones del navegador y navegar por estructuras web complejas para permitir una extracción de datos más completa que los métodos de scraping tradicionales.

Puedes usar el agente FIRE-1 con el punto de conexión `/extract` para tareas de extracción complejas que requieren navegar por varias páginas o interactuar con elementos.

**Ejemplo (cURL):**

```bash
curl -X POST https://api.firecrawl.dev/v2/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "Extrae todos los comentarios de los usuarios de este hilo del foro.",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> FIRE-1 ya está activo y disponible en versión preliminar.

<div id="billing-and-usage-tracking">
  ## Facturación y seguimiento del uso
</div>

Hemos simplificado la facturación para que Extract ahora use créditos, igual que los demás endpoints. Cada crédito equivale a 15 tokens.

Puedes supervisar el uso de Extract desde el [panel](https://www.firecrawl.dev/app/extract).

¿Tienes comentarios o necesitas ayuda? Escribe a [help@firecrawl.com](mailto:help@firecrawl.com).