---
title: "Guía avanzada de scraping"
description: "Aprende a mejorar tu scraping con Firecrawl usando opciones avanzadas."
og:title: "Guía avanzada de scraping | Firecrawl"
og:description: "Aprende a mejorar tu scraping con Firecrawl usando opciones avanzadas."
---

Esta guía te mostrará los distintos puntos de conexión de Firecrawl y cómo aprovecharlos al máximo con todos sus parámetros.

<div id="basic-scraping-with-firecrawl-scrape">
  ## Extracción básica con Firecrawl (/scrape)
</div>

Para extraer una sola página y obtener contenido limpio en Markdown, puedes usar el punto de conexión `/scrape`.

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR_API_KEY")

content = app.scrape_url("https://docs.firecrawl.dev")
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { FirecrawlApp } from 'firecrawl-js';

const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

const content = await app.scrapeUrl('https://docs.firecrawl.dev');
```

```go Go
// go get github.com/mendableai/firecrawl-go

import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
    log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
  }

  content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
  if err != nil {
    log.Fatalf("Failed")
  }
}
```

```rust Rust
// Instala el crate firecrawl_rs con Cargo

use firecrawl_rs::FirecrawlApp;
#[tokio::main]
async fn main() {
  // Inicializa FirecrawlApp con la clave de API
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
    Err(e) => eprintln!("Scrape failed: {}", e),
  }
}
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## Extracción de PDF
</div>

**Firecrawl admite la extracción de PDF de forma predeterminada.** Puedes usar el punto de conexión `/scrape` para extraer un enlace de PDF y obtener el contenido de texto del PDF. Puedes desactivar esto estableciendo `parsePDF` en `false`.

<div id="scrape-options">
  ## Opciones de scraping
</div>

Al usar el punto de conexión `/scrape`, puedes personalizar el comportamiento del scraping con muchos parámetros. Estas son las opciones disponibles:

<div id="setting-the-content-formats-on-response-with-formats">
  ### Configurar los formatos de contenido en la respuesta con `formats`
</div>

- **Tipo**: `array`
- **Enum**: `["markdown", "links", "html", "rawHtml", "screenshot", "json"]`
- **Descripción**: Especifica los formatos que se incluirán en la respuesta. Las opciones son:
  - `markdown`: Devuelve el contenido extraído en formato Markdown.
  - `links`: Incluye todos los enlaces encontrados en la página.
  - `html`: Proporciona el contenido en formato HTML.
  - `rawHtml`: Entrega el HTML en bruto, sin procesamiento.
  - `screenshot`: Incluye una captura de pantalla de la página tal como se ve en el navegador.
  - `json`: Extrae información estructurada de la página usando el LLM.
- **Valor predeterminado**: `["markdown"]`

<div id="getting-the-full-page-content-as-markdown-with-onlymaincontent">
  ### Obtener todo el contenido de la página como markdown con `onlyMainContent`
</div>

- **Tipo**: `boolean`
- **Descripción**: De forma predeterminada, el scraper devuelve solo el contenido principal de la página, excluyendo encabezados, barras de navegación, pies de página, etc. Establécelo en `false` para devolver todo el contenido de la página.
- **Predeterminado**: `true`

<div id="setting-the-tags-to-include-with-includetags">
  ### Configurar las etiquetas que se incluirán con `includeTags`
</div>

- **Tipo**: `array`
- **Descripción**: Especifica las etiquetas, clases e IDs de HTML que se incluirán en la respuesta.
- **Predeterminado**: undefined

<div id="setting-the-tags-to-exclude-with-excludetags">
  ### Configurar las etiquetas a excluir con `excludeTags`
</div>

- **Tipo**: `array`
- **Descripción**: Especifica las etiquetas HTML, clases e IDs que se excluirán de la respuesta.
- **Predeterminado**: indefinido

<div id="waiting-for-the-page-to-load-with-waitfor">
  ### Esperar a que la página se cargue con `waitFor`
</div>

- **Tipo**: `integer`
- **Descripción**: Usar solo como último recurso. Espera una cantidad específica de milisegundos a que la página se cargue antes de obtener el contenido.
- **Predeterminado**: `0`

<div id="setting-the-maximum-timeout">
  ### Configurar el `timeout` máximo
</div>

- **Tipo**: `integer`
- **Descripción**: Define la duración máxima, en milisegundos, que el scraper esperará a que la página responda antes de abortar la operación.
- **Predeterminado**: `30000` (30 segundos)

<div id="parsing-pdf-files-with-parsepdf">
  ### Análisis de archivos PDF con `parsePDF`
</div>

- **Tipo**: `boolean`
- **Descripción**: Controla cómo se procesan los archivos PDF durante el scraping. Cuando `true`, el contenido del PDF se extrae y se convierte a formato markdown, con facturación basada en la cantidad de páginas (1 crédito por página). Cuando `false`, el archivo PDF se devuelve en base64 con una tarifa fija de 1 crédito en total.
- **Predeterminado**: `true`

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer TU_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats": ["markdown", "links", "html", "rawHtml", "screenshot"],
      "includeTags": ["h1", "p", "a", ".main-content"],
      "excludeTags": ["#ad", "#footer"],
      "onlyMainContent": false,
      "waitFor": 1000,
      "timeout": 15000,
      "parsePDF": false
    }'
```

En este ejemplo, el scraper:

* Devuelve el contenido completo de la página en formato markdown.
* Incluye el markdown, el HTML sin procesar, el HTML, los enlaces y la captura de pantalla en la respuesta.
* La respuesta incluirá solo las etiquetas HTML `<h1>`, `<p>`, `<a>` y los elementos con la clase `.main-content`, mientras excluye cualquier elemento con los ID `#ad` y `#footer`.
* Espera 1000 milisegundos (1 segundo) a que la página cargue antes de obtener el contenido.
* Establece la duración máxima de la solicitud de scraping en 15000 milisegundos (15 segundos).
* Devuelve archivos PDF en formato base64 en lugar de convertirlos a markdown.

Consulta la referencia de la API: [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


<div id="extractor-options">
  ## Opciones del extractor
</div>

Al usar el punto de conexión `/scrape`, puedes especificar opciones para **extraer información estructurada** del contenido de la página mediante el parámetro `extract`. Estas son las opciones disponibles:

<div id="using-the-llm-extraction">
  ### Uso de la extracción con LLM
</div>

<div id="schema">
  ### schema
</div>

- **Tipo**: `object`
- **Obligatorio**: No, si se proporciona un prompt
- **Descripción**: Esquema de los datos a extraer. Define la estructura de los datos extraídos.

<div id="system-prompt">
  ### system prompt
</div>

- **Tipo**: `string`
- **Obligatorio**: No
- **Descripción**: Prompt del sistema para el LLM.

<div id="prompt">
  ### prompt
</div>

- **Tipo**: `string`
- **Obligatorio**: Falso si se proporciona un esquema
- **Descripción**: Un prompt para que el LLM extraiga los datos con la estructura correcta.
- **Ejemplo**: `"Extrae las características del producto"`

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "formats": ["markdown", "json"],
      "json": {
        "prompt": "Extrae las funcionalidades del producto"
      }
    }'
```

```json
{
  "success": true,
  "data": {
    "content": "Contenido sin procesar",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable te permite crear fácilmente aplicaciones de chat con IA. Ingiera, personalice y luego implemente con una sola línea de código donde quieras. Presentado por SideGuide",
      "robots": "seguir, indexar",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable te permite crear fácilmente aplicaciones de chat con IA. Ingiera, personalice y luego implemente con una sola línea de código donde quieras. Presentado por SideGuide",
      "ogUrl": "https://docs.firecrawl.dev/",
      "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://docs.firecrawl.dev/",
      "statusCode": 200
    },
    "extract": {
      "product": "Firecrawl",
      "features": {
        "general": {
          "description": "Convierte sitios web en datos listos para LLM.",
          "openSource": true,
          "freeCredits": 500,
          "useCases": [
            "Aplicaciones de IA",
            "Ciencia de datos",
            "Investigación de mercado",
            "Agregación de contenido",
          ]
        },
        "crawlingAndScraping": {
          "crawlAllAccessiblePages": true,
          "noSitemapRequired": true,
          "dynamicContentHandling": true,
          "dataCleanliness": {
            "process": "Algoritmos avanzados",
            "outputFormat": "Markdown"
          }
        },
        ...
      }
    }
  }
}
```


<div id="actions">
  ## Acciones
</div>

Al usar el punto de conexión `/scrape`, Firecrawl te permite realizar diversas acciones en una página web antes de extraer su contenido. Esto es especialmente útil para interactuar con contenido dinámico, navegar entre páginas o acceder a contenido que requiere interacción del usuario.

<div id="available-actions">
  ### Acciones disponibles
</div>

<div id="wait">
  #### wait
</div>

- **Tipo**: `object`
- **Descripción**: Espera durante una cantidad específica de milisegundos.
- **Propiedades**:
  - `type`: `"wait"`
  - `milliseconds`: Número de milisegundos que se debe esperar.
- **Ejemplo**:
  ```json
  {
    "type": "wait",
    "milliseconds": 2000
  }
  ```

<div id="screenshot">
  #### screenshot
</div>

- **Tipo**: `object`
- **Descripción**: Toma una captura de pantalla.
- **Propiedades**:
  - `type`: `"screenshot"`
  - `fullPage`: ¿La captura debe abarcar toda la página o solo el área visible del viewport? (valor predeterminado: `false`)
- **Ejemplo**:
  ```json
  {
    "type": "screenshot",
    "fullPage": true
  }
  ```

<div id="click">
  #### click
</div>

- **Tipo**: `object`
- **Descripción**: Hacer clic en un elemento.
- **Propiedades**:
  - `type`: `"click"`
  - `selector`: Selector para localizar el elemento.
- **Ejemplo**:
  ```json
  {
    "type": "click",
    "selector": "#load-more-button"
  }
  ```

<div id="write">
  #### write
</div>

- **Tipo**: `object`
- **Descripción**: Escribe texto en un campo de entrada.
- **Propiedades**:
  - `type`: `"write"`
  - `text`: Texto a ingresar.
  - `selector`: Selector para el campo de entrada.
- **Ejemplo**:
  ```json
  {
    "type": "write",
    "text": "Hello, world!",
    "selector": "#search-input"
  }
  ```

<div id="press">
  #### press
</div>

- **Tipo**: `object`
- **Descripción**: Pulsa una tecla en la página.
- **Propiedades**:
  - `type`: `"press"`
  - `key`: Tecla que pulsar.
- **Ejemplo**:
  ```json
  {
    "type": "press",
    "key": "Enter"
  }
  ```

<div id="scroll">
  #### scroll
</div>

- **Tipo**: `object`
- **Descripción**: Desplaza la página.
- **Propiedades**:
  - `type`: `"scroll"`
  - `direction`: Dirección en la que desplazarse (`"up"` o `"down"`).
  - `amount`: Cantidad a desplazar en píxeles.
- **Ejemplo**:
  ```json
  {
    "type": "scroll",
    "direction": "down",
    "amount": 500
  }
  ```

<div id="scrape">
  #### scrape
</div>

- **Tipo**: `object`
- **Descripción**: Raspa el contenido de la página actual y devuelve la URL y el HTML. El contenido raspado se devolverá en el arreglo `actions.scrapes` de la respuesta.
- **Propiedades**:
  - `type`: `"scrape"`
- **Ejemplo**:
  ```json
  {
    "type": "scrape"
  }
  ```

<div id="pdf">
  #### pdf
</div>

- **Tipo**: `object`
- **Descripción**: Genera un PDF de la página actual. El PDF se devolverá en la matriz `actions.pdfs` de la respuesta.
- **Propiedades**:
  - `type`: `"pdf"`
  - `format`: El tamaño de página del PDF resultante (predeterminado: `"Letter"`)
  - `landscape`: Si generar el PDF en orientación horizontal (predeterminado: `false`)
  - `scale`: El factor de escala del PDF resultante (predeterminado: `1`)
- **Ejemplo**:
  ```json
  {
    "type": "pdf",
    "format": "A4",
    "landscape": true,
    "scale": 0.8
  }
  ```

<div id="executejavascript">
  #### executeJavascript
</div>

- **Tipo**: `object`
- **Descripción**: Ejecuta código JavaScript en la página. Los valores devueltos aparecerán en el arreglo `actions.javascriptReturns` de la respuesta.
- **Propiedades**:
  - `type`: `"executeJavascript"`
  - `script`: Código JavaScript a ejecutar.
- **Ejemplo**:
  ```json
  {
    "type": "executeJavascript",
    "script": "document.querySelector('.button').click();"
  }
  ```

Para más detalles sobre los parámetros de las acciones, consulta la [Referencia de la API](https://docs.firecrawl.dev/api-reference/endpoint/scrape).

<div id="crawling-multiple-pages">
  ## Rastreo de múltiples páginas
</div>

Para rastrear múltiples páginas, puedes usar el punto de conexión `/crawl`. Este punto de conexión te permite especificar una URL base que quieras rastrear y rastreará todas las subpáginas accesibles.

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer TU_CLAVE_API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Devuelve un ID

```json
{ "id": "1234-5678-9101" }
```


<div id="check-crawl-job">
  ### Comprobar trabajo de rastreo
</div>

Se usa para verificar el estado de un trabajo de rastreo y obtener su resultado.

```bash
curl -X GET https://api.firecrawl.dev/v1/crawl/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
```


<div id="paginationnext-url">
  #### Paginación/URL siguiente
</div>

Si el contenido supera los 10 MB o si la tarea de rastreo aún está en ejecución, la respuesta incluirá un parámetro `next`. Este parámetro es una URL a la siguiente página de resultados. Puedes usarlo para obtener la página siguiente.

<div id="crawler-options">
  ### Opciones del crawler
</div>

Al usar el punto de conexión `/crawl`, puedes personalizar el comportamiento del rastreo con parámetros en el cuerpo de la solicitud. Estas son las opciones disponibles:

<div id="includepaths">
  #### `includePaths`
</div>

- **Tipo**: `array`
- **Descripción**: Patrones de expresiones regulares para incluir en el rastreo. Solo se rastrearán las URL que coincidan con estos patrones. Por ejemplo, `^/blog/.*` coincidirá con cualquier URL que comience con `/blog/`.
- **Ejemplo**: `["^/blog/.*$", "^/docs/.*$"]`

<div id="excludepaths">
  #### `excludePaths`
</div>

- **Tipo**: `array`
- **Descripción**: Patrones de expresiones regulares para excluir del rastreo. Las URL que coincidan con estos patrones se omitirán. Por ejemplo, `^/admin/.*` excluirá cualquier URL que comience con `/admin/`.
- **Ejemplo**: `["^/admin/.*$", "^/private/.*$"]`

<div id="maxdepth">
  #### `maxDepth`
</div>

- **Tipo**: `integer`
- **Descripción**: Profundidad absoluta máxima a rastrear desde la base de la URL. Por ejemplo, si la ruta de la URL es `/features/feature-1`, no se devolverán resultados a menos que `maxDepth` sea como mínimo 2.
- **Ejemplo**: `2`

<div id="limit">
  #### `limit`
</div>

- **Tipo**: `integer`
- **Descripción**: Número máximo de páginas a rastrear.
- **Valor predeterminado**: `10000`

<div id="allowbackwardlinks">
  #### `allowBackwardLinks`
</div>

- **Tipo**: `boolean`
- **Descripción**: Permite que el rastreador siga enlaces internos a URLs hermanas o superiores (padre), no solo rutas hijas.
  - **false**: Solo rastrea URLs más profundas (hijas).
    - p. ej., /features/feature-1 → /features/feature-1/tips ✅
    - No seguirá /pricing ni / ❌
  - **true**: Rastrea cualquier enlace interno, incluidos hermanos y superiores (padre).
    - p. ej., /features/feature-1 → /pricing, /, etc. ✅
  - Usa true para lograr una cobertura interna más amplia más allá de rutas anidadas.
- **Predeterminado**: `false`

<div id="allowexternallinks">
  ### `allowExternalLinks`
</div>

- **Tipo**: `boolean`
- **Descripción**: Esta opción permite que el rastreador siga enlaces que apuntan a dominios externos. Ten cuidado con esta opción, ya que puede hacer que el rastreo solo se limite por los valores de `limit` y `maxDepth`.
- **Predeterminado**: `false`

<div id="allowsubdomains">
  ### `allowSubdomains`
</div>

- **Tipo**: `boolean`
- **Descripción**: Permite que el rastreador siga enlaces a subdominios del dominio principal. Por ejemplo, si se rastrea `example.com`, esto permitirá seguir enlaces a `blog.example.com` o `api.example.com`.
- **Valor predeterminado**: `false`

<div id="delay">
  ### `delay`
</div>

- **Tipo**: `number`
- **Descripción**: Retraso en segundos entre extracciones. Ayuda a respetar los límites de tasa del sitio y a evitar sobrecargar el sitio de destino. Si no se especifica, el rastreador puede usar el crawl delay de robots.txt si está disponible.
- **Predeterminado**: `undefined`

<div id="scrapeoptions">
  #### scrapeOptions
</div>

Como parte de las opciones del rastreador, también puedes especificar el parámetro `scrapeOptions`. Este parámetro te permite personalizar el comportamiento del scraping para cada página.

- **Type**: `object`
- **Description**: Opciones del scraper.
- **Example**: `{"formats": ["markdown", "links", "html", "rawHtml", "screenshot"], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
- **Default**: `{ "formats": ["markdown"] }`
- **See**: [Opciones de scraping](#setting-the-content-formats-on-response-with-formats)

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer TU_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "includePaths": ["^/blog/.*$", "^/docs/.*$"],
      "excludePaths": ["^/admin/.*$", "^/private/.*$"],
      "maxDepth": 2,
      "limit": 1000
    }'
```

En este ejemplo, el rastreador hará lo siguiente:

* Solo rastreará las URL que coincidan con los patrones `^/blog/.*$` y `^/docs/.*$`.
* Omitirá las URL que coincidan con los patrones `^/admin/.*$` y `^/private/.*$`.
* Devolverá los datos completos del documento de cada página.
* Rastreará hasta una profundidad máxima de 2.
* Rastreará como máximo 1000 páginas.


<div id="mapping-website-links-with-map">
  ## Mapeo de enlaces del sitio web con `/map`
</div>

El punto de conexión `/map` destaca en identificar URL contextualmente relacionadas con un sitio web determinado. Esta función es clave para comprender el entorno de enlaces contextuales de un sitio, lo que puede ayudar significativamente en el análisis estratégico y la planificación de la navegación.

<div id="usage">
  ### Uso
</div>

Para utilizar el punto de conexión `/map`, debes enviar una solicitud GET con la URL de la página que deseas mapear. Aquí tienes un ejemplo con `curl`:

```bash
curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Esto devolverá un objeto JSON con enlaces relacionados contextualmente con la URL.


<div id="example-response">
  ### Ejemplo de respuesta
</div>

```json
  {
    "success": true,
    "links": [
      "https://docs.firecrawl.dev",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-get",
      "https://docs.firecrawl.dev/api-reference/endpoint/crawl-post",
      "https://docs.firecrawl.dev/api-reference/endpoint/map",
      "https://docs.firecrawl.dev/api-reference/endpoint/scrape",
      "https://docs.firecrawl.dev/api-reference/introduction",
      "https://docs.firecrawl.dev/articles/search-announcement",
      ...
    ]
  }
```


<div id="map-options">
  ### Opciones del mapa
</div>

<div id="search">
  #### `search`
</div>

- **Tipo**: `string`
- **Descripción**: Busca enlaces que contengan un texto específico.
- **Ejemplo**: `"blog"`

<div id="limit">
  #### `limit`
</div>

- **Tipo**: `integer`
- **Descripción**: Número máximo de enlaces a devolver.
- **Valor predeterminado**: `100`

<div id="ignoresitemap">
  #### `ignoreSitemap`
</div>

- **Tipo**: `boolean`
- **Descripción**: Ignora el sitemap del sitio web durante el rastreo
- **Predeterminado**: `true`

<div id="includesubdomains">
  #### `includeSubdomains`
</div>

- **Tipo**: `boolean`
- **Descripción**: Incluir subdominios del sitio web
- **Valor predeterminado**: `true`

Aquí tienes la referencia de la API para esto: [Documentación del punto de conexión /map](https://docs.firecrawl.dev/api-reference/endpoint/map)

¡Gracias por leer!