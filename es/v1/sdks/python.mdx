---
title: 'Python'
description: 'El SDK de Python de Firecrawl es un wrapper de la API de Firecrawl que te ayuda a convertir fácilmente sitios web a Markdown.'
icon: 'python'
og:title: "SDK de Python | Firecrawl"
og:description: "El SDK de Python de Firecrawl es un wrapper de la API de Firecrawl que te ayuda a convertir fácilmente sitios web a Markdown."
---

import InstallationPython from '/snippets/es/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/es/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/es/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/es/v1/crawl-status/short/python.mdx'
import CrawlAsyncPythonShort from '/snippets/es/v1/crawl-async/short/python.mdx'
import CancelCrawlPythonShort from '/snippets/es/v1/crawl-delete/short/python.mdx'
import MapPythonShort from '/snippets/es/v1/map/short/python.mdx'
import ExtractPythonShort from '/snippets/es/v1/extract/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/es/v1/scrape-and-crawl/python.mdx'
import CrawlWebSocketPythonBase from '/snippets/es/v1/crawl-websocket/base/python.mdx'
import AsyncPythonShort from '/snippets/es/v1/async/short/python.mdx'


<div id="installation">
  ## Instalación
</div>

Para instalar el SDK de Python de Firecrawl, puedes usar pip:

<InstallationPython />

<div id="usage">
  ## Uso
</div>

1. Obtén una clave de API en [firecrawl.dev](https://firecrawl.dev)
2. Define la clave de API como una variable de entorno llamada `FIRECRAWL_API_KEY` o pásala como parámetro a la clase `FirecrawlApp`.

Aquí tienes un ejemplo de cómo usar el SDK:

<ScrapeAndCrawlExamplePython />

<div id="scraping-a-url">
  ### Extracción de una URL
</div>

Para extraer una única URL, usa el método `scrape_url`. Recibe la URL como parámetro y devuelve los datos extraídos como un diccionario.

<ScrapePythonShort />

<div id="crawling-a-website">
  ### Rastreo de un sitio web
</div>

Para rastrear un sitio web, usa el método `crawl_url`. Recibe la URL inicial y parámetros opcionales como argumentos. El argumento `params` te permite especificar opciones adicionales para la tarea de rastreo, como el número máximo de páginas a rastrear, los dominios permitidos y el formato de salida.

<CrawlPythonShort />

<div id="asynchronous-crawling">
  ### Rastreo asíncrono
</div>

<Tip>¿Buscas operaciones asíncronas? Revisa la sección [Async Class](#async-class) más abajo.</Tip>

Para rastrear un sitio web de forma asíncrona, usa el método `crawl_url_async`. Devuelve el `ID` del rastreo, que puedes usar para consultar el estado del job de rastreo. Recibe la URL inicial y parámetros opcionales como argumentos. El parámetro `params` te permite especificar opciones adicionales para el job, como el número máximo de páginas a rastrear, los dominios permitidos y el formato de salida.

<CrawlAsyncPythonShort />

<div id="checking-crawl-status">
  ### Consultar el estado del rastreo
</div>

Para consultar el estado de un trabajo de rastreo, usa el método `check_crawl_status`. Recibe el ID del trabajo como parámetro y devuelve el estado actual del rastreo.

<CheckCrawlStatusPythonShort />

<div id="cancelling-a-crawl">
  ### Cancelar un rastreo
</div>

Para cancelar un trabajo de rastreo asíncrono, usa el método `cancel_crawl`. Recibe el ID del trabajo como parámetro y devuelve el estado de la cancelación.

<CancelCrawlPythonShort />

<div id="map-a-website">
  ### Mapear un sitio web
</div>

Usa `map_url` para generar una lista de URL de un sitio web. El argumento `params` te permite personalizar el proceso de mapeo, incluidas opciones para excluir subdominios o usar el sitemap.

<MapPythonShort />

{/* ### Extracción de datos estructurados de sitios web

Para extraer datos estructurados de sitios web, utiliza el método `extract`. Recibe las URL de las que extraer datos, un prompt y un esquema como argumentos. El esquema es un modelo de Pydantic que define la estructura de los datos extraídos.

<ExtractPythonShort /> */}

<div id="crawling-a-website-with-websockets">
  ### Rastreo de un sitio web con WebSockets
</div>

Para rastrear un sitio web con WebSockets, usa el método `crawl_url_and_watch`. Recibe la URL inicial y parámetros opcionales como argumentos. El parámetro `params` te permite especificar opciones adicionales para el trabajo de rastreo, como el número máximo de páginas a rastrear, los dominios permitidos y el formato de salida.

<CrawlWebSocketPythonBase />

<div id="error-handling">
  ## Manejo de errores
</div>

El SDK gestiona los errores que devuelve la API de Firecrawl y lanza las excepciones correspondientes. Si se produce un error durante una solicitud, se lanzará una excepción con un mensaje descriptivo.

<div id="async-class">
  ## Clase Async
</div>

Para operaciones asíncronas, puedes usar la clase `AsyncFirecrawlApp`. Sus métodos son los mismos que los de `FirecrawlApp`, pero no bloquean el hilo principal.

<AsyncPythonShort />