---
title: "Modo sigilo"
description: "Usa proxies en modo sigilo para sitios con soluciones anti-bots avanzadas"
og:title: "Modo sigilo | Firecrawl"
og:description: "Usa proxies en modo sigilo para sitios con soluciones anti-bots avanzadas"
---

import ProxyPython from "/snippets/es/v1/scrape/proxy/python.mdx";
import ProxyNode from "/snippets/es/v1/scrape/proxy/js.mdx";
import ProxyCURL from "/snippets/es/v1/scrape/proxy/curl.mdx";
import ProxyRetryPython from "/snippets/es/v1/scrape/proxy-retry/python.mdx";
import ProxyRetryNode from "/snippets/es/v1/scrape/proxy-retry/js.mdx";
import ProxyRetryCURL from "/snippets/es/v1/scrape/proxy-retry/curl.mdx";

Firecrawl ofrece distintos tipos de proxy para ayudarte a extraer datos de sitios web con diversos niveles de protección antibots. El tipo de proxy puede especificarse con el parámetro `proxy`.

<div id="proxy-types">
  ### Tipos de proxy
</div>

Firecrawl admite tres tipos de proxies:

- **basic**: Proxies para extraer datos de sitios con protección anti‑bot nula o básica. Es rápido y suele funcionar.
- **stealth**: Proxies de modo sigiloso para extraer datos de sitios con protecciones anti‑bot avanzadas. Es más lento, pero más fiable en ciertos sitios.
- **auto**: Firecrawl reintentará automáticamente la extracción con proxies stealth si el proxy basic falla. Si el reintento con stealth tiene éxito, se cobrarán 5 créditos por la extracción. Si el primer intento con basic tiene éxito, solo se cobrará el costo regular.

Si no especificas un proxy, Firecrawl usará basic por defecto.

<div id="using-stealth-mode">
  ### Uso del modo sigiloso
</div>

Al extraer datos de sitios web con protección anti‑bots avanzada, puedes usar el modo de proxy sigiloso para mejorar la tasa de éxito.

<CodeGroup>

<ProxyPython />

<ProxyNode />

<ProxyCURL />

</CodeGroup>

**Nota:** A partir del 8 de mayo, las solicitudes con proxy sigiloso cuestan 5 créditos por solicitud.

<div id="using-stealth-as-a-retry-mechanism">
  ## Usar Stealth como mecanismo de reintento
</div>

Un patrón común es intentar primero hacer scraping con la configuración de proxy predeterminada y luego reintentar con el modo stealth si se encuentran códigos de estado de error específicos (401, 403 o 500) en el campo `metadata.statusCode` de la respuesta. Estos códigos pueden indicar que el sitio web está bloqueando la solicitud.

<CodeGroup>

<ProxyRetryPython />

<ProxyRetryNode />

<ProxyRetryCURL />

</CodeGroup>

Este enfoque permite optimizar el uso de créditos al usar el modo stealth solo cuando sea necesario.