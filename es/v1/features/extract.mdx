---
title: "Extracción"
description: "Extrae datos estructurados de páginas con LLM"
og:title: "Extracción | Firecrawl"
og:description: "Extrae datos estructurados de páginas con LLM"
icon: "barcode-read"
sidebarTitle: "Extracción"
---

import ExtractCURL from "/snippets/es/v1/extract/base/curl.mdx";
import ExtractPython from "/snippets/es/v1/extract/base/python.mdx";
import ExtractNode from "/snippets/es/v1/extract/base/js.mdx";
import ExtractOutput from "/snippets/es/v1/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/es/v1/extract/no-schema/curl.mdx";
import ExtractNoSchemaPython from "/snippets/es/v1/extract/no-schema/python.mdx";
import ExtractNoSchemaJS from "/snippets/es/v1/extract/no-schema/js.mdx";
import ExtractNoSchemaOutput from "/snippets/es/v1/extract/no-schema/output.mdx";
import ExtractWebSearchPython from "/snippets/es/v1/extract/websearch/python.mdx";
import ExtractWebSearchJS from "/snippets/es/v1/extract/websearch/js.mdx";
import ExtractWebSearchCURL from "/snippets/es/v1/extract/websearch/curl.mdx";
import ExtractWebSearchOutput from "/snippets/es/v1/extract/websearch/output.mdx";
import CheckExtractJobCURL from "/snippets/es/v1/extract/status/curl.mdx";
import CheckExtractJobJS from "/snippets/es/v1/extract/status/js.mdx";
import CheckExtractJobPython from "/snippets/es/v1/extract/status/python.mdx";
import ExtractStatusPending from "/snippets/es/v1/extract/status/pending.mdx";
import ExtractStatusAsync from "/snippets/es/v1/extract/async-response/async.mdx";
import ExtractStatusDone from "/snippets/es/v1/extract/status/completed.mdx";
import ExtractWithoutURLsPython from "/snippets/es/v1/extract/without-urls/python.mdx";
import ExtractWithoutURLsJS from "/snippets/es/v1/extract/without-urls/js.mdx";
import ExtractWithoutURLsCURL from "/snippets/es/v1/extract/base/curl.mdx";

El endpoint `/extract` simplifica la recopilación de datos estructurados desde cualquier número de URL o dominios completos. Proporciona una lista de URL, opcionalmente con comodines (por ejemplo, `example.com/*`), y un prompt o un esquema que describa la información que deseas. Firecrawl se encarga de rastrear, analizar y compilar conjuntos de datos, grandes o pequeños.

<Info>Hemos simplificado la facturación para que Extract ahora use créditos, igual que el resto de los endpoints. Cada crédito equivale a 15 tokens.</Info>


<div id="using-extract">
  ## Uso de `/extract`
</div>

Puedes extraer datos estructurados de una o varias URL, incluidos comodines:

- **Página única**  
  Ejemplo: `https://firecrawl.dev/some-page`
- **Múltiples páginas / Dominio completo**  
  Ejemplo: `https://firecrawl.dev/*`

Cuando uses `/*`, Firecrawl rastreará y analizará automáticamente todas las URL que pueda descubrir en ese dominio y luego extraerá los datos solicitados. Esta función es experimental; escribe a [help@firecrawl.com](mailto:help@firecrawl.com) si tienes problemas.

<div id="example-usage">
  ### Ejemplo de uso
</div>

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

**Parámetros clave:**

- **urls**: Un array con una o más URL. Admite comodines (`/*`) para un rastreo más amplio.
- **prompt** (Opcional, salvo que no haya esquema): Un prompt en lenguaje natural que describa los datos que quieres o indique cómo quieres estructurarlos.
- **schema** (Opcional, salvo que no haya prompt): Una estructura más rígida si ya conoces el esquema JSON.
- **enableWebSearch** (Opcional): Cuando `true`, la extracción puede seguir enlaces fuera del dominio especificado.

Consulta la [Referencia de la API](https://docs.firecrawl.dev/api-reference/endpoint/extract) para más detalles.

<div id="response-sdks">
  ### Respuesta (SDKs)
</div>

<ExtractOutput />

<div id="asynchronous-extraction-status-checking">
  ## Extracción asíncrona y comprobación de estado
</div>

Cuando envíes un trabajo de extracción—ya sea directamente a través de la API o mediante los métodos asíncronos del SDK—recibirás un ID de trabajo. Puedes usar este ID para:

- Comprobar el estado del trabajo: Envía una solicitud al punto de conexión /extract/{ID} para ver si el trabajo sigue en ejecución o ya ha finalizado.
- Sondeo automático (comportamiento predeterminado del SDK): Si usas el método extract predeterminado (Python/Node), el SDK sondea automáticamente este punto de conexión por ti y devuelve los resultados finales cuando el trabajo se completa.
- Sondeo manual (métodos asíncronos del SDK): Si usas los métodos asíncronos—async_extract (Python) o asyncExtract (Node)—el SDK devuelve inmediatamente un ID de trabajo que puedes rastrear. Usa get_extract_status (Python) o getExtractStatus (Node) para comprobar el progreso del trabajo según tu propio ritmo.

<Note>
  Este punto de conexión solo funciona para trabajos en curso o recientemente completados (dentro de 24 horas).
</Note>

A continuación se muestran ejemplos de código para comprobar el estado de un trabajo de extracción con Python, Node.js y cURL:

<CodeGroup>

<CheckExtractJobPython />
<CheckExtractJobJS />
<CheckExtractJobCURL />

</CodeGroup>

<div id="possible-states">
  ### Posibles estados
</div>

- **completed**: La extracción se completó correctamente.
- **processing**: Firecrawl aún está procesando tu solicitud.
- **failed**: Se produjo un error; los datos no se extrajeron por completo.
- **cancelled**: El trabajo fue cancelado por el usuario.

<div id="pending-example">
  #### Ejemplo pendiente
</div>

<ExtractStatusPending />

<div id="completed-example">
  #### Ejemplo completado
</div>

<ExtractStatusDone />

<div id="extracting-without-a-schema">
  ## Extracción sin esquema
</div>

Si prefieres no definir una estructura estricta, basta con proporcionar un `prompt`. El modelo subyacente elegirá una estructura por ti, lo que puede ser útil para solicitudes más exploratorias o flexibles.

<CodeGroup>

<ExtractNoSchemaPython />
<ExtractNoSchemaJS />
<ExtractNoSchemaCURL />

</CodeGroup>

<ExtractNoSchemaOutput />

<div id="improving-results-with-web-search">
  ## Mejora de resultados con búsqueda web
</div>

Establecer `enableWebSearch = true` en tu solicitud ampliará el rastreo más allá del conjunto de URL proporcionado. Esto puede incorporar información de soporte o relacionada desde páginas vinculadas.

Aquí tienes un ejemplo que extrae información sobre cámaras para salpicadero, enriqueciendo los resultados con datos de páginas relacionadas:

<CodeGroup>

<ExtractWebSearchPython />
<ExtractWebSearchJS />
<ExtractWebSearchCURL />

</CodeGroup>

<div id="example-response-with-web-search">
  ### Ejemplo de respuesta con búsqueda web
</div>

<ExtractWebSearchOutput />

La respuesta incluye contexto adicional obtenido de páginas relacionadas, lo que aporta información más completa y precisa.

<div id="extracting-without-urls">
  ## Extracción sin URLs
</div>

El punto de conexión `/extract` ahora permite extraer datos estructurados con un prompt sin necesidad de URLs específicas. Esto es útil para la investigación o cuando se desconocen las URLs exactas. Actualmente en fase alfa.

<CodeGroup>

<ExtractWithoutURLsPython />
<ExtractWithoutURLsJS />
<ExtractWithoutURLsCURL />

</CodeGroup>

<div id="known-limitations-beta">
  ## Limitaciones conocidas (Beta)
</div>

1. **Cobertura de sitios a gran escala**  
   La cobertura completa de sitios masivos (p. ej., “todos los productos de Amazon”) en una sola solicitud aún no es compatible.

2. **Consultas lógicas complejas**  
   Solicitudes como “encontrar todas las publicaciones de 2025” pueden no devolver de forma confiable todos los datos esperados. Estamos trabajando en capacidades de consulta más avanzadas.

3. **Inconsistencias ocasionales**  
   Los resultados pueden variar entre ejecuciones, especialmente en sitios muy grandes o dinámicos. Por lo general, captura los detalles principales, pero puede haber cierta variación.

4. **Estado Beta**  
   Dado que `/extract` aún está en Beta, las funciones y el rendimiento seguirán evolucionando. Agradecemos los reportes de errores y los comentarios para ayudarnos a mejorar.

<div id="using-fire-1">
  ## Uso de FIRE-1
</div>

FIRE-1 es un agente de IA que amplía las capacidades de scraping de Firecrawl. Puede controlar acciones del navegador y navegar por estructuras web complejas para permitir una extracción de datos más completa que la del scraping tradicional.

Puedes usar el agente FIRE-1 con el punto de conexión `/v1/extract` para tareas de extracción complejas que requieran navegar por varias páginas o interactuar con elementos.

**Ejemplo (cURL):**

```bash
curl -X POST https://api.firecrawl.dev/v1/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": ["https://example-forum.com/topic/123"],
      "prompt": "Extrae todos los comentarios de los usuarios de este hilo del foro.",
      "schema": {
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      "agent": {
        "model": "FIRE-1"
      }
    }'
```

> FIRE-1 ya está disponible y en fase de vista previa.

<div id="billing-and-usage-tracking">
  ## Facturación y seguimiento del uso
</div>

Hemos simplificado la facturación para que Extract ahora utilice créditos, igual que el resto de endpoints. Cada crédito equivale a 15 tokens.

Puedes supervisar el uso de Extract desde el [panel](https://www.firecrawl.dev/app/extract).

¿Tienes comentarios o necesitas ayuda? Escribe a [help@firecrawl.com](mailto:help@firecrawl.com).