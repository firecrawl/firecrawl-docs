---
title: Guía rápida
description: "Firecrawl te permite convertir sitios web completos en markdown listo para LLM"
og:title: "Guía rápida | Firecrawl"
og:description: "Firecrawl te permite convertir sitios web completos en markdown listo para LLM"
---

<img className="block" src="/images/turn-websites-into-llm-ready-data--firecrawl.jpg" alt="Hero Light" />

<div id="welcome-to-firecrawl">
  ## Bienvenido a Firecrawl
</div>

[Firecrawl](https://firecrawl.dev?ref=github) es un servicio de API que toma una URL, la rastrea y la convierte en markdown limpio. Rastreamos todas las subpáginas accesibles y te entregamos markdown limpio para cada una. No necesitas un sitemap.

<div id="how-to-use-it">
  ## ¿Cómo usarlo?
</div>

Ofrecemos una API fácil de usar con nuestra versión alojada. Puedes encontrar el playground y la documentación [aquí](https://firecrawl.dev/playground). También puedes alojar el backend por tu cuenta si lo prefieres.

Consulta los siguientes recursos para empezar:

* [x] **API**: [Documentación](https://docs.firecrawl.dev/api-reference/introduction)
* [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node), [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)
* [x] **Frameworks de LLM**: [Langchain (python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (js)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
* [x] **Frameworks low‑code**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)
* [x] **Otros**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
* [ ] ¿Quieres un SDK o una integración? Cuéntanos abriendo un issue.

**Autohospedado:** Para alojarlo por tu cuenta, consulta la guía [aquí](/es/contributing/self-host).

<div id="api-key">
  ### Clave de API
</div>

Para usar la API, debes registrarte en [Firecrawl](https://firecrawl.dev) y obtener una clave de API.

<div id="crawling">
  ## Rastreo
</div>

Se utiliza para rastrear una URL y todas las subpáginas accesibles. Esto envía un trabajo de rastreo y devuelve un ID de trabajo para comprobar el estado del rastreo.

<div id="installation">
  ### Instalación
</div>

<CodeGroup>
  ```bash Python
  pip install firecrawl-py
  ```

  ```bash JavaScript
  npm install @mendable/firecrawl-js
  ```

  ```bash Go
  go get github.com/mendableai/firecrawl-go
  ```

  ```toml Rust
  # añade lo siguiente a tu Cargo.toml

  [dependencies]
  firecrawl = "^0.1"
  tokio = { version = "^1", features = ["full"] }
  serde = { version = "^1.0", features = ["derive"] }
  serde_json = "^1.0"
  uuid = { version = "^1.10", features = ["v4"] }

  [build-dependencies]
  tokio = { version = "1", features = ["full"] }
  ```
</CodeGroup>

<div id="usage">
  ### Uso
</div>

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  crawl_result = app.crawl_url('docs.firecrawl.dev', {'crawlerOptions': {'excludes': ['blog/*']}})

  # Obtener el markdown
  for result in crawl_result:
      print(result['markdown'])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";

  // Inicializa FirecrawlApp con tu API key
  const app = new FirecrawlApp({ apiKey: "YOUR_API_KEY" });

  // Rastrea un sitio web
  const crawlResult = await app.crawlUrl("docs.firecrawl.dev", {
    crawlerOptions: { excludes: ["blog/*"] },
  });

  // Registra el markdown
  console.log(crawlResult.map((result) => result.markdown));
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    // Inicializa FirecrawlApp con tu API key
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("No se pudo inicializar FirecrawlApp: %v", err)
    }

    // Rastrea un sitio web
    params := map[string]any{
      "crawlerOptions": map[string]any{
        "excludes": []string{"blog/*"},
      },
    }
    crawlResult, err := app.CrawlURL("docs.firecrawl.dev", params)
    if err != nil {
      log.Fatalf("Error durante el rastreo: %v", err)
    }

    // Obtener el markdown
    for _, result := range crawlResult {
      fmt.Println(result.Markdown)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
    // Inicializa FirecrawlApp con la API key
    let api_key = "YOUR_API_KEY";
    let api_url = "https://api.firecrawl.dev";
    let app = FirecrawlApp::new(api_key, api_url).expect("No se pudo inicializar FirecrawlApp");

    // Rastrea la URL
    let crawl_params = json!({
      "crawlerOptions": {
          "excludes": ["blog/*"]
      }
    });

    let crawl_result = app
        .crawl_url("https://example.com", Some(crawl_params), true, 2, None)
        .await;

    // Imprime el resultado del rastreo
    match crawl_result {
        Ok(data) => println!("Resultado del rastreo:\n{}", data),
        Err(e) => eprintln!("El rastreo falló: {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/crawl \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

Si no usas el SDK o prefieres usar un webhook u otro método de sondeo, puedes establecer `wait_until_done` en `false`.
Esto devolverá un jobId.

En cURL, /crawl siempre devolverá un jobId que puedes usar para consultar el estado del rastreo.

```json
{ "jobId": "1234-5678-9101" }
```

<div id="check-crawl-job">
  ### Consultar estado de un trabajo de rastreo
</div>

Se usa para verificar el estado de un trabajo de rastreo y obtener su resultado.

<CodeGroup>
  ```python Python
  status = app.check_crawl_status(job_id)
  ```

  ```js JavaScript
  const status = await app.checkCrawlStatus(jobId);
  ```

  ```go Go
  status, err := app.CheckCrawlStatus(jobId)
  if err != nil {
    log.Fatalf("Failed to check crawl status: %v", err)
  }
  ```

  ```rust Rust
  let status = match app.check_crawl_status(jobId).await {
      Ok(status) => status,
      Err(e) => panic!("Failed to check crawl status: {:?}", e),
  };

  println!("Crawl Status: {:?}", status);
  ```

  ```bash cURL
  curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY'
  ```
</CodeGroup>

<div id="response">
  #### Respuesta
</div>

```json
{
  "status": "completado",
  "current": 22,
  "total": 22,
  "data": [
    {
      "content": "Contenido sin procesar ",
      "markdown": "# Contenido en Markdown",
      "provider": "web-scraper",
      "metadata": {
        "title": "Firecrawl | Rastrea la web de forma confiable para tus LLM",
        "description": "IA para CX y ventas"
        "language": null,
        "sourceURL": "https://docs.firecrawl.dev/"
      }
    }
  ]
}
```

<div id="scraping">
  ## Scraping
</div>

Para extraer una única URL, usa el método `scrape_url`. Recibe la URL como parámetro y devuelve los datos extraídos como un diccionario.

<CodeGroup>
  ```python Python
  from firecrawl import FirecrawlApp

  app = FirecrawlApp(api_key="YOUR_API_KEY")

  content = app.scrape_url("https://docs.firecrawl.dev")
  ```

  ```JavaScript JavaScript
  import { FirecrawlApp } from 'firecrawl-js';

  const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

  const content = await app.scrapeUrl('https://docs.firecrawl.dev');
  ```

  ```go Go
  import (
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  func main() {
    app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
    if err != nil {
      log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
    }

    content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
    if err != nil {
      log.Fatalf("Failed to scrape URL: %v", err)
    }
  }
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Initialize the FirecrawlApp with the API key
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

      // Scrape the URL
      let scrape_result = app.scrape_url("https://example.com", None).await;

      // Print the scrape result
    match scrape_result {
      Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
      Err(e) => eprintln!("Scrape failed: {}", e),
    }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY' \
      -d '{
        "url": "https://docs.firecrawl.dev"
      }'
  ```
</CodeGroup>

<div id="response">
  ### Respuesta
</div>

```json
{
  "success": true,
  "data": {
    "markdown": "<cadena>",
    "content": "<cadena>",
    "html": "<cadena>",
    "rawHtml": "<cadena>",
    "metadata": {
      "title": "<cadena>",
      "description": "<cadena>",
      "language": "<cadena>",
      "sourceURL": "<cadena>",
      "<cualquier otro metadato>": "<cadena>",
      "pageStatusCode": 123,
      "pageError": "<cadena>"
    },
    "llm_extraction": {},
    "warning": "<cadena>"
  }
}
```

<div id="extraction">
  ## Extracción
</div>

Con la extracción con LLM, puedes extraer fácilmente datos estructurados de cualquier URL. También admitimos esquemas de Pydantic para facilitarte el trabajo. Así es como se usa:

<CodeGroup>
  ```python Python
  class ArticleSchema(BaseModel):
      title: str
      points: int 
      by: str
      commentsURL: str

  class TopArticlesSchema(BaseModel):
  top: List[ArticleSchema] = Field(..., max_items=5, description="Las 5 principales noticias")

  data = app.scrape_url('https://news.ycombinator.com', {
  'extractorOptions': {
  'extractionSchema': TopArticlesSchema.model_json_schema(),
  'mode': 'llm-extraction'
  },
  'pageOptions':{
  'onlyMainContent': True
  }
  })
  print(data["llm_extraction"])
  ```

  ```js JavaScript
  import FirecrawlApp from "@mendable/firecrawl-js";
  import { z } from "zod";

  const app = new FirecrawlApp({
    apiKey: "fc-YOUR_API_KEY",
  });

  // Define el esquema para extraer el contenido
  const schema = z.object({
    top: z
      .array(
        z.object({
          title: z.string(),
          points: z.number(),
          by: z.string(),
          commentsURL: z.string(),
        })
      )
      .length(5)
  .describe("Las 5 principales noticias en Hacker News"),
  });

  const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
    extractorOptions: { extractionSchema: schema },
  });

  console.log(scrapeResult.data["llm_extraction"]);
  ```

  ```go Go
  import (
    "fmt"
    "log"

    "github.com/mendableai/firecrawl-go"
  )

  app, err := NewFirecrawlApp(TEST_API_KEY, API_URL)
  if err != nil {
    log.Fatalf("Error al inicializar FirecrawlApp: %v", err)
  }

  params := map[string]any{
    "extractorOptions": ExtractorOptions{
      Mode:             "llm-extraction",
      ExtractionPrompt: "Según la información de la página, determina cuál es la misión de la empresa, si admite SSO y si es de código abierto",
      ExtractionSchema: map[string]any{
        "type": "object",
        "properties": map[string]any{
          "company_mission": map[string]string{"type": "string"},
          "supports_sso":    map[string]string{"type": "boolean"},
          "is_open_source":  map[string]string{"type": "boolean"},
        },
        "required": []string{"company_mission", "supports_sso", "is_open_source"},
      },
    },
  }

  scrapeResult, err := app.ScrapeURL("https://news.ycombinator.com", params)
  if err != nil {
    log.Fatalf("Error al extraer la URL: %v", err)
  }
  fmt.Println(scrapeResult.LLMExtraction)
  ```

  ```rust Rust
  use firecrawl::FirecrawlApp;

  #[tokio::main]
  async fn main() {
      // Inicializa FirecrawlApp con la clave de la API
      let api_key = "YOUR_API_KEY";
      let api_url = "https://api.firecrawl.dev";
      let app = FirecrawlApp::new(api_key, api_url).expect("No se pudo inicializar FirecrawlApp");

      // Define el esquema en el que se extraerá el contenido
      let json_schema = json!({
          "type": "object",
          "properties": {
              "top": {
                  "type": "array",
                  "items": {
                      "type": "object",
                      "properties": {
                          "title": {"type": "string"},
                          "points": {"type": "number"},
                          "by": {"type": "string"},
                          "commentsURL": {"type": "string"}
                      },
                      "required": ["title", "points", "by", "commentsURL"]
                  },
                  "minItems": 5,
                  "maxItems": 5,
                  "description": "Las 5 mejores noticias en Hacker News"
              }
          },
          "required": ["top"]
      });

      let llm_extraction_params = json!({
          "extractorOptions": {
              "extractionSchema": json_schema,
              "mode": "llm-extraction"
          },
          "pageOptions": {
              "onlyMainContent": true
          }
      });

      let llm_extraction_result = app
          .scrape_url("https://news.ycombinator.com", Some(llm_extraction_params))
          .await;
      match llm_extraction_result {
          Ok(data) => println!("Resultado de la extracción con LLM:\n{}", data["llm_extraction"]),
          Err(e) => eprintln!("Error en la extracción con LLM: {}", e),
      }
  }
  ```

  ```bash cURL
  curl -X POST https://api.firecrawl.dev/v0/scrape \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer TU_CLAVE_DE_API' \
      -d '{
        "url": "https://docs.firecrawl.dev/",
        "extractorOptions": {
          "mode": "llm-extraction",
          "extractionPrompt": "Con base en la información de la página, extrae los datos según el esquema. ",
          "extractionSchema": {
            "type": "object",
            "properties": {
              "company_mission": {
                        "type": "string"
              },
              "supports_sso": {
                        "type": "boolean"
              },
              "is_open_source": {
                        "type": "boolean"
              },
              "is_in_yc": {
                        "type": "boolean"
              }
            },
            "required": [
              "company_mission",
              "supports_sso",
              "is_open_source",
              "is_in_yc"
            ]
          }
        }
      }'
  ```
</CodeGroup>

<div id="contributing">
  ## Contribuciones
</div>

¡Nos encanta recibir contribuciones! Lee nuestra [guía de contribución](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md) antes de enviar un pull request.