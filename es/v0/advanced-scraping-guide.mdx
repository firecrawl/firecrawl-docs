---
title: "Guía avanzada de scraping"
description: "Aprende a mejorar tu scraping en Firecrawl con opciones avanzadas."
og:title: "Guía avanzada de scraping | Firecrawl"
og:description: "Aprende a mejorar tu scraping en Firecrawl con opciones avanzadas."
---

Esta guía te mostrará los distintos puntos de conexión de Firecrawl y cómo aprovecharlos al máximo con todos sus parámetros.

<div id="basic-scraping-with-firecrawl-scrape">
  ## Extracción básica con Firecrawl (/scrape)
</div>

Para extraer una sola página y obtener contenido limpio en Markdown, puedes usar el punto de conexión `/scrape`.

<CodeGroup>

```python Python
# pip install firecrawl-py

from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="YOUR_API_KEY")

content = app.scrape_url("https://docs.firecrawl.dev")
```

```JavaScript JavaScript
// npm install @mendable/firecrawl-js

import { FirecrawlApp } from 'firecrawl-js';

const app = new FirecrawlApp({ apiKey: 'YOUR_API_KEY' });

const content = await app.scrapeUrl('https://docs.firecrawl.dev');
```

```go Go
// go get github.com/mendableai/firecrawl-go

import (
  "fmt"
  "log"

  "github.com/mendableai/firecrawl-go"
)

func main() {
  app, err := firecrawl.NewFirecrawlApp("YOUR_API_KEY")
  if err != nil {
    log.Fatalf("Failed to initialize FirecrawlApp: %v", err)
  }

  content, err := app.ScrapeURL("docs.firecrawl.dev", nil)
  if err != nil {
    log.Fatalf("Failed)
  }
}
```

```rust Rust
// Install the firecrawl_rs crate with Cargo

use firecrawl_rs::FirecrawlApp;
#[tokio::main]
async fn main() {
  // Initialize the FirecrawlApp with the API key
  let api_key = "YOUR_API_KEY";
  let api_url = "https://api.firecrawl.dev";
  let app = FirecrawlApp::new(api_key, api_url).expect("Failed to initialize FirecrawlApp");

  let scrape_result = app.scrape_url("https://docs.firecrawl.dev", None).await;
  match scrape_result {
    Ok(data) => println!("Scrape Result:\n{}", data["markdown"]),
    Err(e) => eprintln!("Scrape failed: {}", e),
  }
}
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

</CodeGroup>

<div id="scraping-pdfs">
  ## Extracción de PDF
</div>

**Firecrawl admite el scraping de PDF de forma predeterminada.** Puedes usar el punto de conexión `/scrape` para extraer un enlace a un PDF y obtener su contenido de texto. Puedes desactivar esto estableciendo `pageOptions.parsePDF` en `false`.

<div id="page-options">
  ## Opciones de página
</div>

Al usar el punto de conexión `/scrape`, puedes personalizar el comportamiento del scraping con el parámetro `pageOptions`. A continuación, las opciones disponibles:

<div id="getting-cleaner-content-with-onlymaincontent">
  ### Obtener contenido más limpio con `onlyMainContent`
</div>

- **Tipo**: `boolean`
- **Descripción**: Devuelve solo el contenido principal de la página y excluye encabezados, barras de navegación, pies de página, etc.
- **Valor predeterminado**: `false`

<div id="getting-the-html-with-includehtml">
  ### Obtener el HTML con `includeHtml`
</div>

- **Tipo**: `boolean`
- **Descripción**: Incluye la versión HTML del contenido de la página. Esto añadirá una clave `html` en la respuesta.
- **Predeterminado**: `false`

<div id="getting-the-raw-html-with-includerawhtml">
  ### Obtener el HTML en bruto con `includeRawHtml`
</div>

- **Tipo**: `boolean`
- **Descripción**: Incluye el contenido HTML en bruto de la página. Esto añadirá una clave `rawHtml` en la respuesta.
- **Predeterminado**: `false`

<div id="getting-a-screenshot-of-the-page-with-screenshot">
  ### Obtener una captura de pantalla de la página con `screenshot`
</div>

- **Tipo**: `boolean`
- **Descripción**: Incluye una captura de la parte superior de la página que estás rastreando.
- **Valor predeterminado**: `false`

<div id="waiting-for-the-page-to-load-with-waitfor">
  ### Esperar a que la página se cargue con `waitFor`
</div>

- **Tipo**: `integer`
- **Descripción**: Usar solo como último recurso. Espera una cantidad específica de milisegundos a que se cargue la página antes de obtener el contenido.
- **Predeterminado**: `0`

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer TU_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "pageOptions": {
        "onlyMainContent": true,
        "includeHtml": true,
        "includeRawHtml":true,
        "screenshot": true,
        "waitFor": 5000
      }
    }'
```

En este ejemplo, el scraper hará lo siguiente:

* Devolver solo el contenido principal de la página.
* Incluir el HTML sin procesar en la respuesta bajo la clave `html`.
* Esperar 5000 milisegundos (5 segundos) a que la página se cargue antes de obtener el contenido.

Consulta la referencia de la API aquí: [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)


<div id="extractor-options">
  ## Opciones del extractor
</div>

Al usar el punto de conexión `/scrape`, puedes especificar opciones para **extraer información estructurada** del contenido de la página mediante el parámetro `extractorOptions`. Estas son las opciones disponibles:

<div id="mode">
  ### mode
</div>

- **Type**: `string`
- **Enum**: `["llm-extraction", "llm-extraction-from-raw-html"]`
- **Description**: El modo de extracción que se utilizará.

  - `llm-extraction`: Extrae información del contenido limpiado y procesado.
  - `llm-extraction-from-raw-html`: Extrae información directamente del HTML sin procesar.

- **Type**: `string`
- **Description**: Un prompt que describe qué información extraer de la página.

<div id="extractionschema">
  ### extractionSchema
</div>

- **Tipo**: `object`
- **Descripción**: Esquema de los datos a extraer. Define la estructura de los datos extraídos.

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "extractorOptions": {
        "mode": "llm-extraction",
        "extractionPrompt": "Con base en la información de la página, extrae los datos según el esquema. ",
        "extractionSchema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
```

```json
{
  "success": true,
  "data": {
    "content": "Contenido sin procesar",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable te permite crear fácilmente aplicaciones de chat con IA. Ingresa, personaliza y luego implementa con una sola línea de código donde quieras. Presentado por SideGuide",
      "robots": "seguir, indexar",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable te permite crear fácilmente aplicaciones de chat con IA. Ingresa, personaliza y luego implementa con una sola línea de código donde quieras. Presentado por SideGuide",
      "ogUrl": "https://docs.firecrawl.dev/",
      "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://docs.firecrawl.dev/"
    },
    "llm_extraction": {
      "company_mission": "Entrena una IA segura con tus recursos técnicos que responda preguntas de clientes y empleados para que tu equipo no tenga que hacerlo"
      "supports_sso": true,
      "is_open_source": false,
      "is_in_yc": true
    }
  }
}
```


<div id="adjusting-timeout">
  ## Ajustar el tiempo de espera
</div>

Puedes ajustar el tiempo de espera del proceso de scraping con el parámetro `timeout`, en milisegundos.

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v0/scrape \
    -H '
    Content-Type: application/json' \
    -H 'Authorization: Bearer TU_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "timeout": 50000
    }'
```


<div id="crawling-multiple-pages">
  ## Rastreo de múltiples páginas
</div>

Para rastrear múltiples páginas, puedes usar el punto de conexión `/crawl`. Este punto de conexión te permite especificar una URL base que deseas rastrear y rastreará todas las subpáginas accesibles.

```bash
curl -X POST https://api.firecrawl.dev/v0/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer TU_CLAVE_API' \
    -d '{
      "url": "https://docs.firecrawl.dev"
    }'
```

Devuelve un jobId

```json
{ "jobId": "1234-5678-9101" }
```


<div id="check-crawl-job">
  ### Consultar trabajo de rastreo
</div>

Sirve para verificar el estado de un trabajo de rastreo y obtener su resultado.

```bash
curl -X GET https://api.firecrawl.dev/v0/crawl/status/1234-5678-9101 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
```


<div id="crawler-options">
  ### Opciones del rastreador
</div>

Al usar el punto de conexión `/crawl`, puedes personalizar el comportamiento de rastreo con el parámetro `crawlerOptions`. Estas son las opciones disponibles:

<div id="includes">
  #### `includes`
</div>

- **Tipo**: `array`
- **Descripción**: Patrones de URL para incluir en el rastreo. Solo se rastrearán las URL que coincidan con estos patrones.
- **Ejemplo**: `["/blog/*", "/products/*"]`

<div id="excludes">
  #### `excludes`
</div>

- **Tipo**: `array`
- **Descripción**: Patrones de URL que se excluirán del rastreo. Las URL que coincidan con estos patrones se omitirán.
- **Ejemplo**: `["/admin/*", "/login/*"]`

<div id="returnonlyurls">
  #### `returnOnlyUrls`
</div>

- **Tipo**: `boolean`
- **Descripción**: Si se establece en `true`, la respuesta incluirá únicamente una lista de URLs en lugar de los datos completos del documento.
- **Predeterminado**: `false`

<div id="maxdepth">
  #### `maxDepth`
</div>

- **Tipo**: `integer`
- **Descripción**: Profundidad máxima de rastreo relativa a la URL indicada. Un maxDepth de 0 solo rastrea la URL indicada. Un maxDepth de 1 rastrea la URL indicada y todas las páginas a un nivel de profundidad. Un maxDepth de 2 rastrea la URL indicada y todas las páginas hasta dos niveles de profundidad. Los valores superiores siguen el mismo patrón.
- **Ejemplo**: `2`

<div id="mode">
  #### `mode`
</div>

- **Tipo**: `string`
- **Valores**: `["default", "fast"]`
- **Descripción**: Modo de rastreo a usar. El modo `fast` rastrea sitios sin sitemap hasta 4 veces más rápido, pero puede ser menos preciso y no se recomienda para sitios con un uso intensivo de JavaScript en el renderizado.
- **Valor predeterminado**: `default`

<div id="limit">
  #### `limit`
</div>

- **Tipo**: `integer`
- **Descripción**: Número máximo de páginas a rastrear.
- **Valor predeterminado**: `10000`

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v0/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "crawlerOptions": {
        "includes": ["/blog/*", "/products/*"],
        "excludes": ["/admin/*", "/login/*"],
        "returnOnlyUrls": false,
        "maxDepth": 2,
        "mode": "fast",
        "limit": 1000
      }
    }'
```

En este ejemplo, el rastreador:

* Solo rastreará URL que coincidan con los patrones `/blog/*` y `/products/*`.
* Omitirá URL que coincidan con los patrones `/admin/*` y `/login/*`.
* Devolverá los datos completos del documento para cada página.
* Rastreará hasta una profundidad máxima de 2.
* Usará el modo de rastreo rápido.
* Rastreará un máximo de 1000 páginas.


<div id="page-options-crawler-options">
  ## Opciones de página + Opciones del rastreador
</div>

Puedes combinar los parámetros `pageOptions` y `crawlerOptions` para personalizar todo el comportamiento del rastreo.

<div id="example-usage">
  ### Ejemplo de uso
</div>

```bash
curl -X POST https://api.firecrawl.dev/v0/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer TU_CLAVE_API' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "pageOptions": {
        "onlyMainContent": true,
        "includeHtml": true,
        "includeRawHtml": true,
        "screenshot": true,
        "waitFor": 5000
      },
      "crawlerOptions": {
        "includes": ["/blog/*", "/products/*"],
        "maxDepth": 2,
        "mode": "fast",
      }
    }'
```

En este ejemplo, el rastreador:

* Devolverá solo el contenido principal de cada página.
* Incluirá el HTML en bruto de cada página.
* Esperará 5000 milisegundos a que cada página cargue antes de obtener su contenido.
* Solo rastreará las URL que coincidan con los patrones `/blog/*` y `/products/*`.
* Rastreará hasta una profundidad máxima de 2.
* Usará el modo de rastreo rápido.


<div id="extractor-options-crawler-options">
  ## Opciones del extractor + Opciones del rastreador
</div>

Próximamente...