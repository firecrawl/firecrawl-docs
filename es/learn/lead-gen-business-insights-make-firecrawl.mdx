---
title: "Uso de la extracción con LLM para obtener insights de clientes"
description: "Uso de la extracción con LLM para obtener insights y generar leads con Make y Firecrawl."
og:title: "Uso de la extracción con LLM para obtener insights de clientes | Firecrawl"
og:description: "Uso de la extracción con LLM para obtener insights y generar leads con Make y Firecrawl."
---

> Nota: este ejemplo usa la [versión v0 de la API de Firecrawl](/es/v0/introduction). Puedes instalar la versión 0.0.20 del SDK de Python o la 0.0.36 del SDK de Node.

<div id="introduction">
  ### Introducción
</div>

Entender a nuestros clientes —no solo quiénes son, sino qué hacen— es crucial para adaptar nuestros productos y servicios de manera efectiva. Al operar un modelo de autoservicio, llegan muchísimos clientes con los que tenemos poco o ningún conocimiento previo. El proceso de entender proactivamente quiénes son estas personas ha sido tradicionalmente muy laborioso, e implicaba recopilar y analizar datos manualmente para obtener información accionable.

Sin embargo, con el poder de los LLM y su capacidad para la extracción avanzada de datos, hemos automatizado este proceso. Mediante la extracción y el análisis de datos de clientes con LLM, hemos reducido significativamente nuestra carga de trabajo, lo que nos permite comprender y atender a nuestra base de clientes de manera más efectiva que nunca.

Si tienes conocimientos técnicos limitados, puedes crear una automatización que obtenga información específica sobre tus clientes con fines de dirección de producto y generación de leads. Aquí te explicamos cómo hacerlo tú mismo con [Make](https://make.com/) y [Firecrawl](https://www.firecrawl.dev/).

***

<div id="overview-of-the-tools">
  ### Descripción general de las herramientas
</div>

**Firecrawl**

Firecrawl es una plataforma de scraping, búsqueda y extracción. Te permite obtener datos de la web y convertirlos en markdown legible por LLM o en datos estructurados.

Cuando necesitamos información sobre nuestros clientes, podemos usar la funcionalidad de extracción con LLM de Firecrawl para especificar exactamente qué información queremos de sus sitios web.

**Make.com (antes Integromat)**

Make es una plataforma de automatización que permite a los usuarios crear flujos de trabajo personalizados para conectar diversas aplicaciones y servicios sin necesidad de conocimientos técnicos profundos. Utiliza una interfaz visual en la que los usuarios pueden arrastrar y soltar elementos para diseñar sus automatizaciones.

Podemos usar Make para conectar una hoja de cálculo con datos de usuarios a Firecrawl, lo que nos permite realizar extracciones con solo un poco de JSON.

<div id="preparing-our-data">
  ### Configuración del escenario
</div>

* Guía paso a paso para configurar el proceso de extracción de datos.
* **Conectar Google Sheets a Make.com**
  * Cómo se recopilan y almacenan inicialmente los datos de los usuarios.
* **Configurar la solicitud HTTP en Make.com**
  * Descripción de cómo configurar solicitudes a la API de Firecrawl.
  * Propósito de estas solicitudes (p. ej., extraer información de la empresa).

### Preparando nuestros datos

Antes de empezar, queremos asegurarnos de dejar nuestros datos listos para Firecrawl. En este caso, creé una hoja de cálculo sencilla con usuarios importados de nuestra base de datos. Queremos tomar los dominios de correo electrónico de nuestros usuarios y convertirlos en enlaces usando el formato https://:

![](https://i.imgur.com/gssynZa.png)

También queremos añadir algunos atributos que nos gustaría conocer sobre estas empresas. En mi caso, quiero entender un poco sobre la empresa, su sector y sus clientes. He definido estos en columnas como:
company&#95;description
company&#95;type
who&#95;they&#95;serve

Ahora que tenemos nuestros datos preparados, podemos empezar a configurar nuestra automatización en Make.

## Configuración de nuestra automatización

Para poner en marcha nuestra automatización, basta con seguir un proceso de tres pasos en Make. Aquí elegiremos tres aplicaciones para nuestro escenario:

Google Sheets - Obtener valores de un rango
HTTP - Realizar una solicitud con autenticación mediante clave de API
Google Sheets - Actualizar una fila

También conviene agregar la herramienta “ignore flow control” por si encontramos errores. Esto mantendrá la automatización en marcha.

![](https://i.imgur.com/MdCWv30.png)

Esta automatización nos permitirá extraer un conjunto de enlaces de nuestra hoja de cálculo, enviarlos a Firecrawl para extraer los datos y luego rellenar de nuevo nuestra hoja de cálculo con la información deseada.

Comencemos configurando nuestra primera aplicación. Nuestro objetivo es exportar todas las URL para poder enviarlas a Firecrawl y extraer los datos. A continuación se muestra la configuración para obtener estas URL:

![](https://i.imgur.com/WHa91kY.png)

**Importante* - queremos asegurarnos de empezar a extraer datos desde la segunda fila. Si incluyes el encabezado, acabarás encontrando un error.

***

¡Genial! Ahora que ya tenemos eso configurado, vamos a preparar nuestra solicitud HTTP. Para ello, ve a https://firecrawl.dev para registrarte y obtener tu clave de API (¡puedes empezar gratis!). Una vez que te registres, ve a https://firecrawl.dev/account para ver tu clave de API.

Usaremos el punto de conexión /scrape de Firecrawl. Este punto de conexión nos permite extraer información de una única URL, convertirla en markdown limpio y usarla para obtener los datos que necesitamos. Completaré todas las condiciones necesarias en nuestra solicitud Make an HTTP request usando la referencia de la API en su documentación.

Ahora, en Make, configuro la llamada a la API siguiendo la documentación de Firecrawl. Usaremos POST como método HTTP y añadiremos dos encabezados.

```
Encabezado 1:
Nombre: Authorization
Valor: Bearer tu clave de API

Encabezado 2:
Nombre: Content-Type
Valor: application/json
```

![](https://i.imgur.com/LJ8g142.png)
También queremos configurar el cuerpo y los tipos de contenido. Aquí haremos:

```
Tipo de cuerpo: Raw
Tipo de contenido: JSON (application/json)
```

También haremos clic en «sí» para procesar nuestra respuesta. Esto la convertirá automáticamente a JSON.

El contenido de la solicitud es el elemento central de lo que queremos lograr. A continuación, el contenido de la solicitud que usaremos para este caso de uso:

```
{
  "url": "1. url(B)",

"pageOptions": {
    "onlyMainContent": true
  },
  "extractorOptions": {
    "mode": "llm-extraction",
    "extractionPrompt": "Extrae la descripción de la empresa (en una sola frase explica qué hace la empresa), el sector de la empresa (software, servicios, IA, etc.) — esto debería ser solo una etiqueta con un par de palabras clave— y a quién atienden (quiénes son sus clientes). Si no hay información clara para responder, escribe 'sin información'.",
    "extractionSchema": {
      "type": "object",
      "properties": {
        "company_description": {
          "type": "string"
        },
        "company_industry": {
          "type": "string"
        },
        "who_they_serve": {
          "type": "string"
        }
      },
      "required": [
        "company_description",
        "company_industry",
        "who_they_serve"
      ]
    }
  }
}
```

![](https://i.imgur.com/DrMc1g2.png)

**Nota:* el campo resaltado en verde en la captura de pantalla es un elemento dinámico que puedes seleccionar en la interfaz de Make. En lugar de `url (B)`, el bloque puede ser la primera URL de tus datos.

![](https://i.imgur.com/D4HCBNe.png)

¡Fantástico! Ya hemos configurado nuestra solicitud HTTP. Probemos para asegurarnos de que todo funcione como debe. Haz clic en “Run once” en Make y deberíamos obtener datos de regreso.

![](https://i.imgur.com/QuQZs0U.png)

Al ejecutar, revisemos nuestra primera operación. En la salida deberíamos obtener un `status code: 200`, lo que indica que la solicitud a la API fue correcta. En la salida, haz clic en data para confirmar que obtuvimos los datos necesarios.

![](https://i.imgur.com/pm614VA.png)

¡Nuestro resultado parece correcto! En llm&#95;extraction vemos los tres atributos de datos que queríamos obtener del sitio web.

**Nota*: si recibes un error `500` en la primera operación y respuestas `200` en las siguientes, puede deberse a que la operación intenta ejecutarse sobre la primera fila de tus datos (la fila de encabezado). ¡Esto causará problemas al volver a importar los datos en las hojas! Asegúrate de empezar desde la segunda fila, como se mencionó antes.

Ahora que sabemos que la solicitud HTTP funciona correctamente, solo queda tomar el JSON generado por Firecrawl y volver a colocarlo en nuestra hoja de cálculo.

***

Ahora debemos tomar los datos extraídos y devolverlos a nuestra hoja de cálculo. Para ello, usaremos el JSON generado por nuestra solicitud HTTP y exportaremos el texto a las tablas correspondientes.

Empecemos conectando la misma hoja de Google y especificando el criterio de número de fila. Aquí simplemente usaremos la interfaz de Make para elegir “row number”.

![](https://i.imgur.com/BYpPabk.png)

Solo queda indicar qué datos extraídos por el LLM van en cada columna. Aquí podemos usar la interfaz de Make para configurarlo.

![](https://i.imgur.com/219tft2.png)

Eso es todo, ¡es hora de probar nuestra automatización!

***

Hagamos clic en “run once” en la interfaz de Make y aseguremos que todo funcione sin problemas. La automatización debería empezar a iterar enlace por enlace y a completar nuestra hoja de cálculo en tiempo real.

![](https://i.imgur.com/vU1CJlt.png)

¡Listo! Con Make y Firecrawl, pudimos extraer información específica sobre nuestros clientes sin tener que visitar manualmente cada uno de sus sitios web.

Al revisar los datos, empezamos a comprender mejor a nuestros clientes. Sin embargo, no estamos limitados a estas características específicas. Si queremos, podemos personalizar nuestro JSON y el prompt de extracción para obtener otra información sobre estas empresas.

<div id="going-a-step-further">
  ### Casos de uso
</div>

La extracción con LLM nos permite obtener rápidamente información específica de la web relevante para nuestro negocio. Podemos usar estas automatizaciones para realizar diversas tareas.

**Producto:**
Especialmente para empresas self‑serve, podemos comprender las tendencias de las industrias que usan nuestro producto. ¿Cuáles son las 2 o 3 industrias principales que utilizan nuestra tecnología y para qué la usan? Esto nos permitirá tomar mejores decisiones de producto, priorizando a los clientes adecuados en los que enfocarnos.

**Desarrollo de negocio:**
Al comprender quiénes son nuestros usuarios, podemos buscar empresas similares que también podrían beneficiarse de nuestro producto. Con una automatización similar, podemos extraer señales positivas de prospectos que se beneficiarían de nuestro producto.

También podemos usar estos datos para generar mejores correos de contacto, más específicos para cada prospecto.

**Investigación de mercado:**
Las firmas de investigación de mercado dedican mucho tiempo a la investigación secundaria, especialmente en sectores de nicho. Podemos agilizar la recopilación de datos automatizando la extracción y organización de información desde fuentes diversas. Esta automatización aumenta la eficiencia y escala con las crecientes necesidades de datos, lo que la convierte en una herramienta valiosa para la toma de decisiones estratégicas en industrias de rápida evolución.

### Dando un paso más

Este fue solo un ejemplo sencillo de cómo podemos usar LLM para extraer datos relevantes de sitios web utilizando una hoja de cálculo estática. Siempre puedes llevarlo más lejos conectándolo de forma dinámica a tus registros de usuarios. Además, puedes integrarlo con otras herramientas para acelerar aún más tu productividad. Por ejemplo, usar el contenido extraído para generar textos más personalizados para la prospección.

Si te resultó útil, ¡no dudes en decírmelo! Me encantaría conocer tus comentarios o saber qué estás construyendo. Puedes contactarme en eric@mendable.ai. ¡Buena suerte y feliz construcción!